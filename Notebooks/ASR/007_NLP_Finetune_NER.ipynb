{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.0 NER Fine-Tuning\n",
    "## (part of Lab 2)\n",
    "\n",
    "In this notebook, you'll use the NVIDIA TAO (Train, Adapt, and Optimize) Toolkit to fine-tune a [BERT](https://arxiv.org/abs/1810.04805)-based model for a named entity recognition (NER) task in a restaurant context using the [MIT Restaurant Corpus](https://groups.csail.mit.edu/sls/downloads/restaurant) dataset. To do so, you will use the [Token Classification](https://docs.nvidia.com/metropolis/TAO/tao-user-guide/text/nlp/token_classification.html) task in TAO.\n",
    "\n",
    "**[7.1 Named Entity Recognition](#7.1-Named-Entity-Recognition)<br>**\n",
    "**[7.2 TAO Toolkit `token_classification` Task](#7.2-TAO-Toolkit-token_classification-Task)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.2.1 Path Setup](#7.2.1-Path-Setup)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.2.2 Specification Files](#7.2.2-Specification-Files)<br>\n",
    "**[7.3 General NER Inference](#7.3-General-NER-Inference)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.3.1 NER Inference with a GMB Context](#7.3.1-NER-Inference-with-a-GMB-Context)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.3.2 Exercise: NER Inference with a Restaurant Context](#7.3.2-Exercise:-NER-Inference-with-a-Restaurant-Context)<br>\n",
    "**[7.4 NER Training](#7.4-NER-Training)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.4.1 Restaurant Data Exploration](#7.4.1-Restaurant-Data-Exploration)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.4.2 `train` Command](#7.4.2-train-Command)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.4.3 Faster Training with AMP](#7.4.3-Faster-Training-with-AMP)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.4.4 Change the Language Model](#7.4.4-Change-the-Language-Model)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.4.5 Evaluate the Trained Model](#7.4.5-Evaluate-the-Trained-Model)<br>\n",
    "**[7.5 NER Fine-Tuning](#7.5-NER-Fine-Tuning)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.5.1 Exercise: Evaluate the Fine-Tuned Model](#7.5.1-Exercise:-Evaluate-the-Fine-Tuned-Model)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.5.2 Inference on the Fine-Tuned Model](#7.5.2-Inference-on-the-Fine-Tuned-Model)<br>\n",
    "**[7.6 Export for Deployment](#7.6-Export-for-Deployment)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[7.6.1 Exercise: NER Model Export to ONNX](#7.6.1-Exercise:-NER-Model-Export-to-ONNX)<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Notebook Dependencies\n",
    "The steps in this notebook assume that you have:\n",
    "\n",
    "1. **NGC Credentials**<br>Be sure you have added your NGC credential as described in the [NGC Setup notebook](003_Intro_NGC_Setup.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "# Check running docker containers. This should be empty.\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"docker kill\" requires at least 1 argument.\n",
      "See 'docker kill --help'.\n",
      "\n",
      "Usage:  docker kill [OPTIONS] CONTAINER [CONTAINER...]\n",
      "\n",
      "Kill one or more running containers\n",
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "# If not empty, clear Docker containers\n",
    "!docker kill $(docker ps -q)\n",
    "# Check for clean environment - this should be empty\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7.1 Named Entity Recognition\n",
    "\n",
    "NER, also referred to as entity chunking, identification, token classification, or extraction, is the task of detecting and classifying key information (entities) in text.  In the general example you used for the Riva Contact app, the entities classified were person, location, organization, time, and miscellaneous. \n",
    "For example, in a sentence: `Mary lives in Santa Clara and works at NVIDIA`, we should detect that `Mary` is a person, `Santa Clara` is a location and `NVIDIA` is an organization.\n",
    "\n",
    "Using TAO, we can train a new model it to recognize different entities, such as cuisine, dish, hours, or restaurant_name for a new domain context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using `tao info`, review the tasks TAO can perform.  In our ASR examples we used the `speech_to_text` task.  For NER, we will use the `token_classification` task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration of the TAO Toolkit Instance\n",
      "\n",
      "dockers: \t\t\n",
      "\tnvidia/tao/tao-toolkit-tf: \t\t\t\n",
      "\t\tdocker_registry: nvcr.io\n",
      "\t\tdocker_tag: v3.21.08-py3\n",
      "\t\ttasks: \n",
      "\t\t\t1. augment\n",
      "\t\t\t2. bpnet\n",
      "\t\t\t3. classification\n",
      "\t\t\t4. detectnet_v2\n",
      "\t\t\t5. dssd\n",
      "\t\t\t6. emotionnet\n",
      "\t\t\t7. faster_rcnn\n",
      "\t\t\t8. fpenet\n",
      "\t\t\t9. gazenet\n",
      "\t\t\t10. gesturenet\n",
      "\t\t\t11. heartratenet\n",
      "\t\t\t12. lprnet\n",
      "\t\t\t13. mask_rcnn\n",
      "\t\t\t14. multitask_classification\n",
      "\t\t\t15. retinanet\n",
      "\t\t\t16. ssd\n",
      "\t\t\t17. unet\n",
      "\t\t\t18. yolo_v3\n",
      "\t\t\t19. yolo_v4\n",
      "\t\t\t20. converter\n",
      "\tnvidia/tao/tao-toolkit-pyt: \t\t\t\n",
      "\t\tdocker_registry: nvcr.io\n",
      "\t\tdocker_tag: v3.21.08-py3\n",
      "\t\ttasks: \n",
      "\t\t\t1. speech_to_text\n",
      "\t\t\t2. speech_to_text_citrinet\n",
      "\t\t\t3. text_classification\n",
      "\t\t\t4. question_answering\n",
      "\t\t\t5. token_classification\n",
      "\t\t\t6. intent_slot_classification\n",
      "\t\t\t7. punctuation_and_capitalization\n",
      "\tnvidia/tao/tao-toolkit-lm: \t\t\t\n",
      "\t\tdocker_registry: nvcr.io\n",
      "\t\tdocker_tag: v3.21.08-py3\n",
      "\t\ttasks: \n",
      "\t\t\t1. n_gram\n",
      "format_version: 1.0\n",
      "toolkit_version: 3.21.08\n",
      "published_date: 08/17/2021\n"
     ]
    }
   ],
   "source": [
    "# Check the token_classification capability in your TAO version\n",
    "!tao info --verbose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7.2 TAO Toolkit `token_classification` Task"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The [token_classification](https://docs.nvidia.com/tao/tao-toolkit/text/nlp/token_classification.html) task provides commands to run data preprocessing, training, fine-tuning, evaluation, inference, and export. All configurations happen through YAML spec files. The `tao token_classification --help` usage information output is as follows:\n",
    "\n",
    "```\n",
    "usage: token_classification [-h] -r RESULTS_DIR [-k KEY]\n",
    "                            [-e EXPERIMENT_SPEC_FILE] [-g GPUS]\n",
    "                            [-m RESUME_MODEL_WEIGHTS] [-o OUTPUT_SPECS_DIR]\n",
    "                            {dataset_convert,evaluate,export,finetune,infer,infer_onnx,train,download_specs}\n",
    "\n",
    "Train Adapt Optimize Toolkit\n",
    "\n",
    "positional arguments:\n",
    "  {dataset_convert,evaluate,export,finetune,infer,infer_onnx,train,download_specs}\n",
    "                        Subtask for a given task/model.\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  -r RESULTS_DIR, --results_dir RESULTS_DIR\n",
    "                        Path to a folder where the experiment outputs should\n",
    "                        be written. (DEFAULT: ./)\n",
    "  -k KEY, --key KEY     User specific encoding key to save or load a .tlt\n",
    "                        model.\n",
    "  -e EXPERIMENT_SPEC_FILE, --experiment_spec_file EXPERIMENT_SPEC_FILE\n",
    "                        Path to the experiment spec file.\n",
    "  -g GPUS, --gpus GPUS  Number of GPUs to use. The default value is 1.\n",
    "  -m RESUME_MODEL_WEIGHTS, --resume_model_weights RESUME_MODEL_WEIGHTS\n",
    "                        Path to a pre-trained model or model to continue\n",
    "                        training.\n",
    "  -o OUTPUT_SPECS_DIR, --output_specs_dir OUTPUT_SPECS_DIR\n",
    "                        Path to a target folder where experiment spec files\n",
    "                        will be downloaded.\n",
    "```                        \n",
    "\n",
    "This should look pretty familiar as it is almost identical in form to the `speech_to_text` task!  As before, additional arguments can be added to the end of the command to override values in the spec file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.1 Path Setup\n",
    "\n",
    "Define some folder locations and an encryption key."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from shutil import rmtree\n",
    "\n",
    "# The source mount is our workspace on the host (this lab instance)\n",
    "source_mount = \"/dli/task/tao\"\n",
    "# The destination mount is our mapped workspace within the TAO docker container's file structure\n",
    "destination_mount = \"/workspace/mount\"\n",
    "\n",
    "# The following paths are set relative to the TAO docker container\n",
    "# The path to the specification yaml files\n",
    "SPECS_DIR=os.path.join(destination_mount, 'specs')\n",
    "\n",
    "# The results are saved at this path by default\n",
    "RESULTS_DIR=os.path.join(destination_mount, 'results')\n",
    "\n",
    "# The data are located at this path by default\n",
    "DATA_DIR=os.path.join(destination_mount, 'data')\n",
    "\n",
    "# The models are located at this path by default\n",
    "MODELS_DIR=os.path.join(destination_mount, 'models')\n",
    "\n",
    "# Set your encryption key, and use the same key for all commands. Please use \"tlt_encode\" if you'd like to deploy the models later with NVIDIA Riva.\n",
    "KEY='tlt_encode'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2.2 Specification Files\n",
    "Fetch the example specification YAML files for the `token_classification` task. We can load example files with the [download_specs subtask](https://docs.nvidia.com/tao/tao-toolkit/text/nlp/token_classification.html#downloading-sample-spec-files), then modify them or override them later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 07:05:30,235 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-04-27 07:05:30,355 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-04-27 07:05:34 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo I 2022-04-27 07:05:36 tlt_logging:20] Experiment configuration:\n",
      "    exp_manager:\n",
      "      task_name: download_specs\n",
      "      explicit_log_dir: /workspace/mount/results\n",
      "    source_data_dir: /opt/conda/lib/python3.8/site-packages/nlp/token_classification/experiment_specs\n",
      "    target_data_dir: /workspace/mount/specs/token_classification\n",
      "    workflow: nlp\n",
      "    \n",
      "[NeMo W 2022-04-27 07:05:36 exp_manager:26] Exp_manager is logging to `/workspace/mount/results``, but it already exists.\n",
      "[NeMo I 2022-04-27 07:05:36 download_specs:73] Default specification files for nlp downloaded to '/workspace/mount/specs/token_classification'\n",
      "[NeMo I 2022-04-27 07:05:36 download_specs:74] Experiment logs saved to '/workspace/mount/results'\n",
      "2022-04-27 07:05:37,583 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n",
      "CPU times: user 209 ms, sys: 47.2 ms, total: 256 ms\n",
      "Wall time: 18.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# The first time, TAO takes about 3 minutes to load and run\n",
    "\n",
    "# Delete the token_classification specification directory if it already exists\n",
    "folder = source_mount + '/specs/token_classification'\n",
    "if os.path.exists(folder):\n",
    "    rmtree(folder)\n",
    "    \n",
    "# Download specification files for token_classification \n",
    "!tao token_classification download_specs \\\n",
    "    -o $SPECS_DIR/token_classification \\\n",
    "    -r $RESULTS_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7.3 General NER Inference\n",
    "\n",
    "For our general model, we will use the [Named Entity Recognition Bert Model](https://ngc.nvidia.com/catalog/models/nvidia:tlt-riva:namedentityrecognition_english_bert), a TAO compatible NER pretrained model available on NGC.\n",
    "\n",
    "The model was trained on the [Groningen Meaning Bank (GMB) corpus](https://gmb.let.rug.nl/) for entity recognition. The GMB dataset is a fairly large corpus with annotations. Note that GMB is not completely human-annotated and it is not considered 100% correct.  The following entity classes appear in the dataset:\n",
    "```\n",
    "LOC = Geographical Entity\n",
    "ORG = Organization\n",
    "PER = Person\n",
    "GPE = Geopolitical Entity\n",
    "TIME = Time indicator\n",
    "ART = Artifact           --|\n",
    "EVE = Event              --|-- combined as MISC\n",
    "NAT = Natural Phenomenon --|\n",
    "\n",
    "```\n",
    "For this model, the classes ART, EVE, and NAT were combined into a MISC class due to the small number of examples for these classes. \n",
    "This NER classifier achieves a 74.21 F1 macro score on the GMB dataset. The macro score computes the F1 score for each label and averages without taking any label imbalance into account. \\begin{array}{rcl} \\text{Macro F1-score} & = & \\frac{1}{N} \\sum_{i=0}^{N} {\\text{F1-score}_i} \\\\ \\end{array} where N the number of labels and i label index.\n",
    "\n",
    "This model is already available in the `tao/models/` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/task/tao/models/namedentityrecognition_english_bert.tlt\n"
     ]
    }
   ],
   "source": [
    "# check model on /tao/models\n",
    "MODEL_DOWNLOAD_DIR=os.path.join(source_mount, 'models')\n",
    "!ls $MODEL_DOWNLOAD_DIR/namedentityrecognition_english_bert.tlt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.1 NER Inference with a GMB Context\n",
    "\n",
    "We need to use the `tao token_classification infer` command for inference.  <br> The corresponding [infer.yaml](tao/specs/token_classification/infer.yaml) file is straightforward and includes some \"simulated\" user input: \n",
    "\n",
    "```yaml\n",
    "input_batch:\n",
    "  - 'We bought four shirts from the Nvidia gear store in Santa Clara.'\n",
    "  - 'Nvidia is a company.'\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try querying the general NER model. Feel free to try out custom inputs as an exercise by changing the data and running the inference command again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 07:16:19,664 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-04-27 07:16:19,786 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-04-27 07:16:23 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-04-27 07:16:26 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-04-27 07:16:27 tlt_logging:20] Experiment configuration:\n",
      "    exp_manager:\n",
      "      task_name: infer\n",
      "      explicit_log_dir: /workspace/mount/results/bert-base/\n",
      "    restore_from: /workspace/mount/models/namedentityrecognition_english_bert.tlt\n",
      "    input_batch:\n",
      "    - Kareem Benzema confident Real Madrid will reach Champions League final\n",
      "    - Vinicius enroute to Manchester City goal post.\n",
      "    encryption_key: '*********'\n",
      "    \n",
      "[NeMo W 2022-04-27 07:16:31 modelPT:193] Using /tmp/tmp44ip5g8d/tokenizer.vocab_file instead of tokenizer.vocab_file.\n",
      "Lock 140031255491200 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100%|██████████████████████████████| 570/570 [00:00<00:00, 488kB/s]\n",
      "Lock 140031255491200 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 140031255490768 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100%|███████████████████████████| 232k/232k [00:00<00:00, 53.6MB/s]\n",
      "Lock 140031255490768 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 140031255890768 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100%|███████████████████████████| 28.0/28.0 [00:00<00:00, 25.4kB/s]\n",
      "Lock 140031255890768 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 140031255664144 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100%|███████████████████████████| 466k/466k [00:00<00:00, 68.9MB/s]\n",
      "Lock 140031255664144 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-04-27 07:16:31 modelPT:1202] World size can only be set by PyTorch Lightning Trainer.\n",
      "Lock 140031255463392 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100%|███████████████████████████| 440M/440M [00:05<00:00, 84.2MB/s]\n",
      "Lock 140031255463392 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo I 2022-04-27 07:16:45 token_classification_dataset:116] Setting Max Seq length to: 15\n",
      "[NeMo I 2022-04-27 07:16:45 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-04-27 07:16:45 data_preprocessing:297] Min: 14 |                  Max: 15 |                  Mean: 14.5 |                  Median: 14.5\n",
      "[NeMo I 2022-04-27 07:16:45 data_preprocessing:303] 75 percentile: 14.75\n",
      "[NeMo I 2022-04-27 07:16:45 data_preprocessing:304] 99 percentile: 14.99\n",
      "[NeMo W 2022-04-27 07:16:45 token_classification_dataset:145] 0 are longer than 15\n",
      "[NeMo I 2022-04-27 07:16:45 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2022-04-27 07:16:45 token_classification_dataset:149] i: 0\n",
      "[NeMo I 2022-04-27 07:16:45 token_classification_dataset:150] subtokens: [CLS] ka ##ree ##m benz ##ema confident real madrid will reach champions league final [SEP]\n",
      "[NeMo I 2022-04-27 07:16:45 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-04-27 07:16:45 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "[NeMo I 2022-04-27 07:16:45 token_classification_dataset:153] subtokens_mask: 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0\n",
      "[NeMo I 2022-04-27 07:16:46 infer:74] Query  : Kareem Benzema confident Real Madrid will reach Champions League final\n",
      "[NeMo I 2022-04-27 07:16:46 infer:75] Results: Kareem[B-PER] Benzema[I-PER] confident Real[B-ORG] Madrid[I-ORG] will reach Champions League final\n",
      "[NeMo I 2022-04-27 07:16:46 infer:74] Query  : Vinicius enroute to Manchester City goal post.\n",
      "[NeMo I 2022-04-27 07:16:46 infer:75] Results: Vinicius[B-PER] enroute to Manchester[B-LOC] City[I-LOC] goal post.\n",
      "[NeMo I 2022-04-27 07:16:46 infer:78] Experiment logs saved to '/workspace/mount/results/bert-base'\n",
      "2022-04-27 07:16:47,691 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# TAO inference NER general model with text in the general domain\n",
    "!tao token_classification infer \\\n",
    "    -e $SPECS_DIR/token_classification/infer.yaml \\\n",
    "    -g 1 \\\n",
    "    -m $MODELS_DIR/namedentityrecognition_english_bert.tlt \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/bert-base/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should find results like the following towards the end of the output.  They are also available in the results log at [tao/results/bert-base/infer.log](tao/results/bert-base/infer.log)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-04-27 07:16:46 infer:75] Results: Kareem[B-PER] Benzema[I-PER] confident Real[B-ORG] Madrid[I-ORG] will reach Champions League final\n",
      "[NeMo I 2022-04-27 07:16:46 infer:75] Results: Vinicius[B-PER] enroute to Manchester[B-LOC] City[I-LOC] goal post.\n"
     ]
    }
   ],
   "source": [
    "!grep Results $source_mount/results/bert-base/infer.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3.2 Exercise: NER Inference with a Restaurant Context\n",
    "Now try querying with sentences we might find in a restaurant context. Execute the following cell to populate a new YAML file,  `infer_restaurant.yaml`.  Then run NER inference as before and check the output.  What do you expect to see?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Writing /dli/task/tao/specs/token_classification/infer_restaurant.yaml\n"
     ]
    }
   ],
   "source": [
    "%%writefile $source_mount/specs/token_classification/infer_restaurant.yaml\n",
    "\n",
    "# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.\n",
    "# TAO Spec file for inference using a previously pretrained BERT model for a text classification task.\n",
    "\n",
    "# \"Simulate\" user input: batch with four samples.\n",
    "input_batch:\n",
    "  - \"I would like to order a pizza for 6pm\"\n",
    "  - \"what sauce is in Pilau.\"\n",
    "  - \"mhh nice Swahili dish.\"\n",
    "  - \"any good cheap kenyan restaurants nearby\"\n",
    "  - \"any good ice cream parlors around\"\n",
    "  - \"any good place to get a pie at an affordable price\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using what you've learned previously, run inference using the new `infer_restaurant.yaml` configuration file. If you get stuck, you can take a look at the [solution](solutions/ex7.3.2.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 07:23:33,480 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-04-27 07:23:33,601 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-04-27 07:23:37 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-04-27 07:23:40 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-04-27 07:23:41 tlt_logging:20] Experiment configuration:\n",
      "    exp_manager:\n",
      "      task_name: infer\n",
      "      explicit_log_dir: /workspace/mount/results/bert-base/\n",
      "    restore_from: /workspace/mount/models/namedentityrecognition_english_bert.tlt\n",
      "    input_batch:\n",
      "    - I would like to order a pizza for 6pm\n",
      "    - what sauce is in Pilau.\n",
      "    - mhh nice Swahili dish.\n",
      "    - any good cheap kenyan restaurants nearby\n",
      "    - any good ice cream parlors around\n",
      "    - any good place to get a pie at an affordable price\n",
      "    encryption_key: '*******'\n",
      "    \n",
      "[NeMo W 2022-04-27 07:23:41 exp_manager:26] Exp_manager is logging to `/workspace/mount/results/bert-base/``, but it already exists.\n",
      "[NeMo W 2022-04-27 07:23:44 modelPT:193] Using /tmp/tmpnf85qkcd/tokenizer.vocab_file instead of tokenizer.vocab_file.\n",
      "Lock 140473124217040 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100%|██████████████████████████████| 570/570 [00:00<00:00, 566kB/s]\n",
      "Lock 140473124217040 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 140473124133664 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100%|███████████████████████████| 232k/232k [00:00<00:00, 51.0MB/s]\n",
      "Lock 140473124133664 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 140473124598448 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100%|███████████████████████████| 28.0/28.0 [00:00<00:00, 25.9kB/s]\n",
      "Lock 140473124598448 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 140473124133088 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100%|███████████████████████████| 466k/466k [00:00<00:00, 70.7MB/s]\n",
      "Lock 140473124133088 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-04-27 07:23:44 modelPT:1202] World size can only be set by PyTorch Lightning Trainer.\n",
      "Lock 140473124260112 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100%|███████████████████████████| 440M/440M [00:04<00:00, 94.7MB/s]\n",
      "Lock 140473124260112 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo I 2022-04-27 07:23:57 token_classification_dataset:116] Setting Max Seq length to: 13\n",
      "[NeMo I 2022-04-27 07:23:57 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-04-27 07:23:57 data_preprocessing:297] Min: 8 |                  Max: 13 |                  Mean: 10.166666666666666 |                  Median: 9.5\n",
      "[NeMo I 2022-04-27 07:23:57 data_preprocessing:303] 75 percentile: 11.50\n",
      "[NeMo I 2022-04-27 07:23:57 data_preprocessing:304] 99 percentile: 12.95\n",
      "[NeMo W 2022-04-27 07:23:57 token_classification_dataset:145] 0 are longer than 13\n",
      "[NeMo I 2022-04-27 07:23:57 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2022-04-27 07:23:57 token_classification_dataset:149] i: 0\n",
      "[NeMo I 2022-04-27 07:23:57 token_classification_dataset:150] subtokens: [CLS] i would like to order a pizza for 6 ##pm [SEP]\n",
      "[NeMo I 2022-04-27 07:23:57 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      "[NeMo I 2022-04-27 07:23:57 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      "[NeMo I 2022-04-27 07:23:57 token_classification_dataset:153] subtokens_mask: 0 1 1 1 1 1 1 1 1 1 0 0 0\n",
      "[NeMo I 2022-04-27 07:23:58 infer:74] Query  : I would like to order a pizza for 6pm\n",
      "[NeMo I 2022-04-27 07:23:58 infer:75] Results: I would like to order a pizza for 6pm[B-TIME]\n",
      "[NeMo I 2022-04-27 07:23:58 infer:74] Query  : what sauce is in Pilau.\n",
      "[NeMo I 2022-04-27 07:23:58 infer:75] Results: what sauce is in Pilau[B-LOC].\n",
      "[NeMo I 2022-04-27 07:23:58 infer:74] Query  : mhh nice Swahili dish.\n",
      "[NeMo I 2022-04-27 07:23:58 infer:75] Results: mhh nice Swahili dish.\n",
      "[NeMo I 2022-04-27 07:23:58 infer:74] Query  : any good cheap kenyan restaurants nearby\n",
      "[NeMo I 2022-04-27 07:23:58 infer:75] Results: any good cheap kenyan[B-GPE] restaurants nearby\n",
      "[NeMo I 2022-04-27 07:23:58 infer:74] Query  : any good ice cream parlors around\n",
      "[NeMo I 2022-04-27 07:23:58 infer:75] Results: any good ice cream parlors around\n",
      "[NeMo I 2022-04-27 07:23:58 infer:74] Query  : any good place to get a pie at an affordable price\n",
      "[NeMo I 2022-04-27 07:23:58 infer:75] Results: any good place to get a pie at an affordable price\n",
      "[NeMo I 2022-04-27 07:23:58 infer:78] Experiment logs saved to '/workspace/mount/results/bert-base'\n",
      "2022-04-27 07:23:59,788 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# TODO infer on NER model with the infer_restaurant.yaml examples\n",
    "!tao token_classification infer \\\n",
    "    -e $SPECS_DIR/token_classification/infer_restaurant.yaml \\\n",
    "    -g 1 \\\n",
    "    -m $MODELS_DIR/namedentityrecognition_english_bert.tlt \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/bert-base/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-04-27 07:16:46 infer:75] Results: Kareem[B-PER] Benzema[I-PER] confident Real[B-ORG] Madrid[I-ORG] will reach Champions League final\n",
      "[NeMo I 2022-04-27 07:16:46 infer:75] Results: Vinicius[B-PER] enroute to Manchester[B-LOC] City[I-LOC] goal post.\n",
      "[NeMo I 2022-04-27 07:23:58 infer:75] Results: I would like to order a pizza for 6pm[B-TIME]\n",
      "[NeMo I 2022-04-27 07:23:58 infer:75] Results: what sauce is in Pilau[B-LOC].\n",
      "[NeMo I 2022-04-27 07:23:58 infer:75] Results: mhh nice Swahili dish.\n",
      "[NeMo I 2022-04-27 07:23:58 infer:75] Results: any good cheap kenyan[B-GPE] restaurants nearby\n",
      "[NeMo I 2022-04-27 07:23:58 infer:75] Results: any good ice cream parlors around\n",
      "[NeMo I 2022-04-27 07:23:58 infer:75] Results: any good place to get a pie at an affordable price\n"
     ]
    }
   ],
   "source": [
    "!grep Results $source_mount/results/bert-base/infer.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Good job running the inference!  Is the result useful?  \n",
    "\n",
    "The current labels are not well suited for the restaurant context!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7.4 NER Training\n",
    "\n",
    "To get useful information in a restaurant context, we need to train a robust classifier on a dataset that has the appropriate entities labeled. We will begin with a pretrained BERT language model to encode the text, as it already inherently understands word relationships. By default, TAO Toolkit uses the `bert-base-uncased` language model (110M parameters). Then, we will train a classifier to recognize restaurant entities.  Fortunately, we have an annotated dataset for restaurants that we can use."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.1 Restaurant Data Exploration\n",
    "\n",
    "The [Restaurant dataset](https://groups.csail.mit.edu/sls/downloads/restaurant) is labeled using the [IOB format](https://en.wikipedia.org/wiki/Inside%E2%80%93outside%E2%80%93beginning_(tagging)) (short for \"inside\", \"outside\", and \"beginning\"). The following entity classes appear in the dataset:\n",
    "\n",
    "```\n",
    "Amenity, Cuisine, Dish, Hours, Location, Price, Rating, Restaurant_Name\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label_ids.csv\t\t    labels_train.txt\t\t  restauranttrain.bio\n",
      "labels_dev.txt\t\t    labels_train_label_stats.tsv  text_dev.txt\n",
      "labels_dev_label_stats.tsv  restauranttest.bio\t\t  text_train.txt\n"
     ]
    }
   ],
   "source": [
    "# set data path and explore data\n",
    "DATA_DOWNLOAD_DIR = os.path.join(source_mount, 'data/restaurant')\n",
    "!ls $DATA_DOWNLOAD_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O\ta\n",
      "B-Rating\tfour\n",
      "I-Rating\tstar\n",
      "O\trestaurant\n",
      "B-Location\twith\n",
      "I-Location\ta\n",
      "B-Amenity\tbar\n"
     ]
    }
   ],
   "source": [
    "# print first test example\n",
    "!head -7 $DATA_DOWNLOAD_DIR/restauranttest.bio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IOB Tagging\n",
    "\n",
    "The files in the dataset, `restauranttrain.bio` and `restauranttest.bio` must be converted to an IOB format that is compatible with [TAO Token Classification module](https://docs.nvidia.com/metropolis/TAO/tao-user-guide/text/nlp/token_classification.html#data-input-for-token-classification-model). TAO Toolkit requires the input to be in two files:\n",
    "-  `text.txt`: Each line of the text.txt file contains text sequences, where words are separated with spaces.\n",
    "-  `labels.txt`: Each line contains corresponding labels for each word in text.txt; the labels are separated with spaces.\n",
    "\n",
    "For the first test example printed previously, the TAO input format should be a `text.txt` file mapped to a `labels.txt` as follows:\n",
    "```text\n",
    "  text.txt:   a four     star     restaurant  with        a          bar\n",
    "labels.txt:   O B-Rating I-Rating O           B-Location  I-Location B-Amenity\n",
    "```\n",
    "To generate the TAO-compatible dataset, we can use the [conversion script](https://github.com/NVIDIA/NeMo/blob/main/examples/nlp/token_classification/data/import_from_iob_format.py) from NVIDIA NeMo toolkit.  \n",
    "\n",
    "We don't need to do that here, as the preprocessed dataset is already available on `data/restaurant` directory for this class. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a four star restaurant with a bar \n",
      "any asian cuisine around \n",
      "any bbq places open before 5 nearby \n",
      "any dancing establishments with reasonable pricing \n",
      "any good cheap german restaurants nearby \n",
      "any good ice cream parlors around \n",
      "any good place to get a pie at an affordable price \n",
      "any good vegan spots nearby \n",
      "any mexican places have a tameles special today \n",
      "any place along the road has a good beer selection that also serves ribs \n"
     ]
    }
   ],
   "source": [
    "# show test text samples\n",
    "!head $DATA_DOWNLOAD_DIR/text_dev.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O B-Rating I-Rating O B-Location I-Location B-Amenity \n",
      "O B-Cuisine O B-Location \n",
      "O B-Cuisine O B-Hours I-Hours I-Hours B-Location \n",
      "O B-Location I-Location O B-Price O \n",
      "O O B-Price B-Cuisine O B-Location \n",
      "O B-Rating B-Cuisine I-Cuisine I-Cuisine B-Location \n",
      "O B-Rating O O O O B-Dish O O B-Price O \n",
      "O O B-Cuisine O B-Location \n",
      "O B-Cuisine O O O B-Dish B-Amenity I-Amenity \n",
      "O O B-Location I-Location I-Location O O B-Rating B-Dish O O O O B-Dish \n"
     ]
    }
   ],
   "source": [
    "# show test labels samples\n",
    "!head $DATA_DOWNLOAD_DIR/labels_dev.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.2 `train` Command\n",
    "\n",
    "To train a model using TAO, we must configure the spec file and run the `tao token_classification train` command. More details about the command can be found in the [documentation](https://docs.nvidia.com/tao/tao-toolkit/text/nlp/token_classification.html#training-a-token-classification-model), including [required arguments](https://docs.nvidia.com/tao/tao-toolkit/text/nlp/token_classification.html#required-arguments-for-training) and an example command:\n",
    "\n",
    "```yaml\n",
    "REQUIRED ARGUMENTS\n",
    "-e: The experiment specification file to set up training.\n",
    "\n",
    "-r: Path to the directory to store the results/logs. Note, the trained-model.tlt would be saved in this specified folder under a subfolder checkpoints; in our case it will be saved here: /results/token_classification/train/checkpoints/trained-model.tlt\n",
    "\n",
    "-k: Encryption key\n",
    "\n",
    "data_dir: Path to the data_dir with the processed data files.\n",
    "\n",
    "model.label_ids: Path to the label_ids.csv file, usually stored at data_dir\n",
    "\n",
    "```\n",
    "\n",
    "```sh\n",
    "EXAMPLE COMMAND\n",
    "tao token_classification train [-h] \\\n",
    "    -e /specs/nlp/token_classification/train.yaml \\\n",
    "    -r /results/token_classification/train/ \\\n",
    "    -g 1 \\\n",
    "    -k $KEY\n",
    "    data_dir=/path/to/data_dir \\\n",
    "    model.label_ids=/path/to/label_ids.csv \\\n",
    "    trainer.max_epochs=5 \\\n",
    "    training_ds.num_samples=-1 \\\n",
    "    validation_ds.num_samples=-1\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This command relies on the [train.yaml](tao/specs/token_classification/train.yaml) specification file. Through the spec file, you can tune many knobs such as the model, dataset, hyperparameters, and optimizers.\n",
    "Each `token_classification` command (`download_and_convert`, `train`, `finetune`, `evaluate`, `infer`, and so on) has a dedicated spec file with configurations pertinent to it. \n",
    "\n",
    "Take a look at the training spec file you downloaded earlier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) 2020, NVIDIA CORPORATION. All rights reserved.\n",
      "# TLT Spec file for training of the BERT model on a Token Classification task:\n",
      "# Named Entity Recognition on GMB dataset\n",
      "\n",
      "trainer:\n",
      "  max_epochs: 5\n",
      "\n",
      "model:\n",
      "  tokenizer:\n",
      "      tokenizer_name: ${model.language_model.pretrained_model_name} # or sentencepiece\n",
      "      vocab_file: null # path to vocab file\n",
      "      tokenizer_model: null # only used if tokenizer is sentencepiece\n",
      "      special_tokens: null\n",
      "\n",
      "  language_model:\n",
      "    pretrained_model_name: bert-base-uncased\n",
      "    lm_checkpoint: null\n",
      "    config_file: null # json file, precedence over config\n",
      "    config: null\n",
      "\n",
      "  head:\n",
      "    num_fc_layers: 2\n",
      "    fc_dropout: 0.5\n",
      "    activation: 'relu'\n",
      "    use_transformer_init: True\n",
      "\n",
      "  # Path to file with label_ids, generated with dataset_convert.py.\n",
      "  # Those labels are used by the model as labels (names of target classes, their number).\n",
      "  label_ids: ???\n",
      "\n",
      "# Path to directory containing both finetuning and validation data.\n",
      "data_dir: ???\n",
      "\n",
      "training_ds:\n",
      "  text_file: text_train.txt\n",
      "  labels_file: labels_train.txt\n",
      "  batch_size: 64\n",
      "\n",
      "validation_ds:\n",
      "  text_file: text_dev.txt\n",
      "  labels_file: labels_dev.txt\n",
      "  batch_size: 64\n",
      "\n",
      "optim:\n",
      "  name: adam\n",
      "  lr: 5e-5\n",
      "  weight_decay: 0.00\n",
      "\n",
      "  # scheduler setup\n",
      "  sched:\n",
      "    name: WarmupAnnealing\n",
      "    # Scheduler params\n",
      "    warmup_steps: null\n",
      "    warmup_ratio: 0.1\n",
      "    last_epoch: -1\n",
      "    # pytorch lightning args\n",
      "    monitor: val_loss\n",
      "    reduce_on_plateau: false\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This line will print the entire training config\n",
    "!cat $source_mount/specs/token_classification/train.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code cell below uses the default `train.yaml`. It is configured to use the `bert-base-uncased` pretrained model. Additionally, these configurations can be overridden by adding the overrides to the `tao` command. Here, we override the `data_dir`, `model.label_ids`, `trainer.max_epochs`, `training_ds.num_samples`, and `validation_ds.num_samples` configurations to suit our needs. <br>\n",
    "\n",
    "In order to get good results, try training for a few epochs (depends on the size of the data). \n",
    "\n",
    "*NOTE: All file paths correspond to the destination-mount directory that is visible in the TAO docker container and used in the backend.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 07:26:57,159 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-04-27 07:26:57,284 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-04-27 07:27:00 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-04-27 07:27:04 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-04-27 07:27:05 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: ???\n",
      "    exp_manager:\n",
      "      explicit_log_dir: /workspace/mount/results/bert-base_ner\n",
      "      exp_dir: null\n",
      "      name: trained-model\n",
      "      version: null\n",
      "      use_datetime_version: true\n",
      "      resume_if_exists: true\n",
      "      resume_past_end: false\n",
      "      resume_ignore_no_checkpoint: true\n",
      "      create_tensorboard_logger: false\n",
      "      summary_writer_kwargs: null\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs: null\n",
      "      create_checkpoint_callback: true\n",
      "      checkpoint_callback_params:\n",
      "        filepath: null\n",
      "        monitor: val_loss\n",
      "        verbose: true\n",
      "        save_last: true\n",
      "        save_top_k: 3\n",
      "        save_weights_only: false\n",
      "        mode: auto\n",
      "        period: 1\n",
      "        prefix: null\n",
      "        postfix: .tlt\n",
      "        save_best_model: false\n",
      "      files_to_copy: null\n",
      "    model:\n",
      "      tokenizer:\n",
      "        tokenizer_name: ${model.language_model.pretrained_model_name}\n",
      "        vocab_file: null\n",
      "        tokenizer_model: null\n",
      "        special_tokens: null\n",
      "      language_model:\n",
      "        pretrained_model_name: bert-base-uncased\n",
      "        lm_checkpoint: null\n",
      "        config_file: null\n",
      "        config: null\n",
      "      head:\n",
      "        num_fc_layers: 2\n",
      "        fc_dropout: 0.5\n",
      "        activation: relu\n",
      "        use_transformer_init: true\n",
      "      label_ids: /workspace/mount/data/restaurant/label_ids.csv\n",
      "      dataset:\n",
      "        data_dir: null\n",
      "        class_balancing: null\n",
      "        max_seq_length: 128\n",
      "        pad_label: O\n",
      "        ignore_extra_tokens: false\n",
      "        ignore_start_end: false\n",
      "        use_cache: true\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "    trainer:\n",
      "      logger: false\n",
      "      checkpoint_callback: false\n",
      "      callbacks: null\n",
      "      default_root_dir: null\n",
      "      gradient_clip_val: 0.0\n",
      "      process_position: 0\n",
      "      num_nodes: 1\n",
      "      num_processes: 1\n",
      "      gpus: 1\n",
      "      auto_select_gpus: false\n",
      "      tpu_cores: null\n",
      "      log_gpu_memory: null\n",
      "      progress_bar_refresh_rate: 1\n",
      "      overfit_batches: 0.0\n",
      "      track_grad_norm: -1\n",
      "      check_val_every_n_epoch: 1\n",
      "      fast_dev_run: false\n",
      "      accumulate_grad_batches: 1\n",
      "      max_epochs: 5\n",
      "      min_epochs: 1\n",
      "      max_steps: null\n",
      "      min_steps: null\n",
      "      limit_train_batches: 1.0\n",
      "      limit_val_batches: 1.0\n",
      "      limit_test_batches: 1.0\n",
      "      val_check_interval: 1.0\n",
      "      flush_logs_every_n_steps: 100\n",
      "      log_every_n_steps: 50\n",
      "      accelerator: ddp\n",
      "      sync_batchnorm: false\n",
      "      precision: 32\n",
      "      weights_summary: full\n",
      "      weights_save_path: null\n",
      "      num_sanity_val_steps: 2\n",
      "      truncated_bptt_steps: null\n",
      "      resume_from_checkpoint: null\n",
      "      profiler: null\n",
      "      benchmark: false\n",
      "      deterministic: false\n",
      "      reload_dataloaders_every_epoch: false\n",
      "      auto_lr_find: false\n",
      "      replace_sampler_ddp: true\n",
      "      terminate_on_nan: false\n",
      "      auto_scale_batch_size: false\n",
      "      prepare_data_per_node: true\n",
      "      amp_backend: native\n",
      "      amp_level: O0\n",
      "    training_ds:\n",
      "      batch_size: 64\n",
      "      text_file: text_train.txt\n",
      "      labels_file: labels_train.txt\n",
      "      shuffle: true\n",
      "      num_samples: -1\n",
      "    validation_ds:\n",
      "      batch_size: 64\n",
      "      text_file: text_dev.txt\n",
      "      labels_file: labels_dev.txt\n",
      "      shuffle: false\n",
      "      num_samples: -1\n",
      "    data_dir: /workspace/mount/data/restaurant\n",
      "    optim:\n",
      "      name: adam\n",
      "      lr: 5.0e-05\n",
      "      weight_decay: 0.0\n",
      "      sched:\n",
      "        name: WarmupAnnealing\n",
      "        warmup_steps: null\n",
      "        warmup_ratio: 0.1\n",
      "        last_epoch: -1\n",
      "        monitor: val_loss\n",
      "        reduce_on_plateau: false\n",
      "    encryption_key: '******'\n",
      "    \n",
      "GPU available: True, used: True\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo W 2022-04-27 07:27:05 exp_manager:303] There was no checkpoint folder at checkpoint_dir :/workspace/mount/results/bert-base_ner/checkpoints. Training from scratch.\n",
      "[NeMo I 2022-04-27 07:27:05 exp_manager:194] Experiments will be logged at /workspace/mount/results/bert-base_ner\n",
      "[NeMo I 2022-04-27 07:27:05 token_classification_model:61] Reusing label_ids file found at /workspace/mount/data/restaurant/label_ids.csv.\n",
      "Lock 139719975344688 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100%|██████████████████████████████| 570/570 [00:00<00:00, 504kB/s]\n",
      "Lock 139719975344688 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 139719976521248 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100%|███████████████████████████| 232k/232k [00:00<00:00, 50.6MB/s]\n",
      "Lock 139719976521248 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 139719975345408 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100%|███████████████████████████| 28.0/28.0 [00:00<00:00, 26.0kB/s]\n",
      "Lock 139719975345408 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 139719976175792 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100%|███████████████████████████| 466k/466k [00:00<00:00, 71.3MB/s]\n",
      "Lock 139719976175792 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "Lock 139719976305088 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100%|███████████████████████████| 440M/440M [00:05<00:00, 86.2MB/s]\n",
      "Lock 139719976305088 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo I 2022-04-27 07:27:15 token_classification_model:105] Setting model.dataset.data_dir to /workspace/mount/data/restaurant.\n",
      "[NeMo I 2022-04-27 07:27:15 token_classification_utils:54] Processing /workspace/mount/data/restaurant/labels_train.txt\n",
      "[NeMo I 2022-04-27 07:27:15 token_classification_utils:74] Using provided labels mapping {'O': 0, 'B-Amenity': 1, 'B-Cuisine': 2, 'B-Dish': 3, 'B-Hours': 4, 'B-Location': 5, 'B-Price': 6, 'B-Rating': 7, 'B-Restaurant_Name': 8, 'I-Amenity': 9, 'I-Cuisine': 10, 'I-Dish': 11, 'I-Hours': 12, 'I-Location': 13, 'I-Price': 14, 'I-Rating': 15, 'I-Restaurant_Name': 16}\n",
      "[NeMo I 2022-04-27 07:27:15 token_classification_utils:90] Labels mapping {'O': 0, 'B-Amenity': 1, 'B-Cuisine': 2, 'B-Dish': 3, 'B-Hours': 4, 'B-Location': 5, 'B-Price': 6, 'B-Rating': 7, 'B-Restaurant_Name': 8, 'I-Amenity': 9, 'I-Cuisine': 10, 'I-Dish': 11, 'I-Hours': 12, 'I-Location': 13, 'I-Price': 14, 'I-Rating': 15, 'I-Restaurant_Name': 16} saved to : /workspace/mount/data/restaurant/label_ids.csv\n",
      "[NeMo I 2022-04-27 07:27:18 token_classification_utils:99] Three most popular labels in /workspace/mount/data/restaurant/labels_train.txt:\n",
      "[NeMo I 2022-04-27 07:27:18 data_preprocessing:131] label: 0, 43670 out of 70525 (61.92%).\n",
      "[NeMo I 2022-04-27 07:27:18 data_preprocessing:131] label: 5, 3817 out of 70525 (5.41%).\n",
      "[NeMo I 2022-04-27 07:27:18 data_preprocessing:131] label: 13, 3658 out of 70525 (5.19%).\n",
      "[NeMo I 2022-04-27 07:27:18 token_classification_utils:101] Total labels: 70525. Label frequencies - {0: 43670, 5: 3817, 13: 3658, 2: 2839, 9: 2676, 1: 2541, 8: 1901, 16: 1668, 3: 1475, 12: 1283, 7: 1070, 4: 990, 11: 767, 6: 730, 10: 630, 15: 527, 14: 283}\n",
      "[NeMo I 2022-04-27 07:27:18 token_classification_utils:110] Class Weights: {0: 0.09499723864814989, 5: 1.0868560156575073, 13: 1.1340977068793618, 2: 1.4612643225659407, 9: 1.550272575397872, 1: 1.632636525684654, 8: 2.1822879598972675, 16: 2.487127944703061, 3: 2.8125623130608175, 12: 3.233460180642795, 7: 3.877130291368884, 4: 4.190433749257279, 11: 5.408773678963111, 6: 5.682917002417406, 10: 6.584967320261438, 15: 7.8719723183391, 14: 14.659114529203908}\n",
      "[NeMo I 2022-04-27 07:27:18 token_classification_utils:114] Class weights saved to /workspace/mount/data/restaurant/labels_train_weights.p\n",
      "[NeMo I 2022-04-27 07:27:26 token_classification_dataset:116] Setting Max Seq length to: 39\n",
      "[NeMo I 2022-04-27 07:27:26 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-04-27 07:27:26 data_preprocessing:297] Min: 3 |                  Max: 39 |                  Mean: 11.860182767624021 |                  Median: 11.0\n",
      "[NeMo I 2022-04-27 07:27:26 data_preprocessing:303] 75 percentile: 14.00\n",
      "[NeMo I 2022-04-27 07:27:26 data_preprocessing:304] 99 percentile: 24.00\n",
      "[NeMo W 2022-04-27 07:27:26 token_classification_dataset:145] 0 are longer than 39\n",
      "[NeMo I 2022-04-27 07:27:26 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2022-04-27 07:27:26 token_classification_dataset:149] i: 0\n",
      "[NeMo I 2022-04-27 07:27:26 token_classification_dataset:150] subtokens: [CLS] 2 start restaurants with inside dining [SEP]\n",
      "[NeMo I 2022-04-27 07:27:26 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 07:27:26 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 07:27:26 token_classification_dataset:153] subtokens_mask: 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 07:27:26 token_classification_dataset:155] labels: 0 7 15 0 0 1 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 07:27:26 token_classification_dataset:264] features saved to /workspace/mount/data/restaurant/cached_text_train.txt_BertTokenizer_128_30522_-1\n",
      "[NeMo I 2022-04-27 07:27:26 token_classification_utils:54] Processing /workspace/mount/data/restaurant/labels_dev.txt\n",
      "[NeMo I 2022-04-27 07:27:26 token_classification_utils:74] Using provided labels mapping {'O': 0, 'B-Amenity': 1, 'B-Cuisine': 2, 'B-Dish': 3, 'B-Hours': 4, 'B-Location': 5, 'B-Price': 6, 'B-Rating': 7, 'B-Restaurant_Name': 8, 'I-Amenity': 9, 'I-Cuisine': 10, 'I-Dish': 11, 'I-Hours': 12, 'I-Location': 13, 'I-Price': 14, 'I-Rating': 15, 'I-Restaurant_Name': 16}\n",
      "[NeMo I 2022-04-27 07:27:26 token_classification_utils:96] /workspace/mount/data/restaurant/labels_dev_label_stats.tsv found, skipping stats calculation.\n",
      "[NeMo I 2022-04-27 07:27:28 token_classification_dataset:116] Setting Max Seq length to: 28\n",
      "[NeMo I 2022-04-27 07:27:28 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-04-27 07:27:28 data_preprocessing:297] Min: 3 |                  Max: 28 |                  Mean: 12.021696252465484 |                  Median: 12.0\n",
      "[NeMo I 2022-04-27 07:27:28 data_preprocessing:303] 75 percentile: 14.00\n",
      "[NeMo I 2022-04-27 07:27:28 data_preprocessing:304] 99 percentile: 23.00\n",
      "[NeMo W 2022-04-27 07:27:28 token_classification_dataset:145] 0 are longer than 28\n",
      "[NeMo I 2022-04-27 07:27:28 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2022-04-27 07:27:28 token_classification_dataset:149] i: 0\n",
      "[NeMo I 2022-04-27 07:27:28 token_classification_dataset:150] subtokens: [CLS] a four star restaurant with a bar [SEP]\n",
      "[NeMo I 2022-04-27 07:27:28 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 07:27:28 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 07:27:28 token_classification_dataset:153] subtokens_mask: 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 07:27:28 token_classification_dataset:155] labels: 0 0 7 15 0 5 13 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 07:27:28 token_classification_dataset:264] features saved to /workspace/mount/data/restaurant/cached_text_dev.txt_BertTokenizer_128_30522_-1\n",
      "[NeMo I 2022-04-27 07:27:28 modelPT:753] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        eps: 1e-08\n",
      "        lr: 5e-05\n",
      "        weight_decay: 0.0\n",
      "    )\n",
      "[NeMo I 2022-04-27 07:27:28 lr_scheduler:617] Scheduler \"<nemo.core.optim.lr_scheduler.WarmupAnnealing object at 0x7f13176fe040>\" \n",
      "    will be used during training (effective maximum steps = 600) - \n",
      "    Parameters : \n",
      "    (warmup_steps: null\n",
      "    warmup_ratio: 0.1\n",
      "    last_epoch: -1\n",
      "    max_steps: 600\n",
      "    )\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "[NeMo I 2022-04-27 07:27:30 modelPT:627] No optimizer config provided, therefore no optimizer was created\n",
      "\n",
      "    | Name                                                   | Type                 | Params\n",
      "--------------------------------------------------------------------------------------------------\n",
      "0   | bert_model                                             | BertEncoder          | 109 M \n",
      "1   | bert_model.embeddings                                  | BertEmbeddings       | 23.8 M\n",
      "2   | bert_model.embeddings.word_embeddings                  | Embedding            | 23.4 M\n",
      "3   | bert_model.embeddings.position_embeddings              | Embedding            | 393 K \n",
      "4   | bert_model.embeddings.token_type_embeddings            | Embedding            | 1.5 K \n",
      "5   | bert_model.embeddings.LayerNorm                        | LayerNorm            | 1.5 K \n",
      "6   | bert_model.embeddings.dropout                          | Dropout              | 0     \n",
      "7   | bert_model.encoder                                     | BertEncoder          | 85.1 M\n",
      "8   | bert_model.encoder.layer                               | ModuleList           | 85.1 M\n",
      "9   | bert_model.encoder.layer.0                             | BertLayer            | 7.1 M \n",
      "10  | bert_model.encoder.layer.0.attention                   | BertAttention        | 2.4 M \n",
      "11  | bert_model.encoder.layer.0.attention.self              | BertSelfAttention    | 1.8 M \n",
      "12  | bert_model.encoder.layer.0.attention.self.query        | Linear               | 590 K \n",
      "13  | bert_model.encoder.layer.0.attention.self.key          | Linear               | 590 K \n",
      "14  | bert_model.encoder.layer.0.attention.self.value        | Linear               | 590 K \n",
      "15  | bert_model.encoder.layer.0.attention.self.dropout      | Dropout              | 0     \n",
      "16  | bert_model.encoder.layer.0.attention.output            | BertSelfOutput       | 592 K \n",
      "17  | bert_model.encoder.layer.0.attention.output.dense      | Linear               | 590 K \n",
      "18  | bert_model.encoder.layer.0.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "19  | bert_model.encoder.layer.0.attention.output.dropout    | Dropout              | 0     \n",
      "20  | bert_model.encoder.layer.0.intermediate                | BertIntermediate     | 2.4 M \n",
      "21  | bert_model.encoder.layer.0.intermediate.dense          | Linear               | 2.4 M \n",
      "22  | bert_model.encoder.layer.0.output                      | BertOutput           | 2.4 M \n",
      "23  | bert_model.encoder.layer.0.output.dense                | Linear               | 2.4 M \n",
      "24  | bert_model.encoder.layer.0.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "25  | bert_model.encoder.layer.0.output.dropout              | Dropout              | 0     \n",
      "26  | bert_model.encoder.layer.1                             | BertLayer            | 7.1 M \n",
      "27  | bert_model.encoder.layer.1.attention                   | BertAttention        | 2.4 M \n",
      "28  | bert_model.encoder.layer.1.attention.self              | BertSelfAttention    | 1.8 M \n",
      "29  | bert_model.encoder.layer.1.attention.self.query        | Linear               | 590 K \n",
      "30  | bert_model.encoder.layer.1.attention.self.key          | Linear               | 590 K \n",
      "31  | bert_model.encoder.layer.1.attention.self.value        | Linear               | 590 K \n",
      "32  | bert_model.encoder.layer.1.attention.self.dropout      | Dropout              | 0     \n",
      "33  | bert_model.encoder.layer.1.attention.output            | BertSelfOutput       | 592 K \n",
      "34  | bert_model.encoder.layer.1.attention.output.dense      | Linear               | 590 K \n",
      "35  | bert_model.encoder.layer.1.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "36  | bert_model.encoder.layer.1.attention.output.dropout    | Dropout              | 0     \n",
      "37  | bert_model.encoder.layer.1.intermediate                | BertIntermediate     | 2.4 M \n",
      "38  | bert_model.encoder.layer.1.intermediate.dense          | Linear               | 2.4 M \n",
      "39  | bert_model.encoder.layer.1.output                      | BertOutput           | 2.4 M \n",
      "40  | bert_model.encoder.layer.1.output.dense                | Linear               | 2.4 M \n",
      "41  | bert_model.encoder.layer.1.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "42  | bert_model.encoder.layer.1.output.dropout              | Dropout              | 0     \n",
      "43  | bert_model.encoder.layer.2                             | BertLayer            | 7.1 M \n",
      "44  | bert_model.encoder.layer.2.attention                   | BertAttention        | 2.4 M \n",
      "45  | bert_model.encoder.layer.2.attention.self              | BertSelfAttention    | 1.8 M \n",
      "46  | bert_model.encoder.layer.2.attention.self.query        | Linear               | 590 K \n",
      "47  | bert_model.encoder.layer.2.attention.self.key          | Linear               | 590 K \n",
      "48  | bert_model.encoder.layer.2.attention.self.value        | Linear               | 590 K \n",
      "49  | bert_model.encoder.layer.2.attention.self.dropout      | Dropout              | 0     \n",
      "50  | bert_model.encoder.layer.2.attention.output            | BertSelfOutput       | 592 K \n",
      "51  | bert_model.encoder.layer.2.attention.output.dense      | Linear               | 590 K \n",
      "52  | bert_model.encoder.layer.2.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "53  | bert_model.encoder.layer.2.attention.output.dropout    | Dropout              | 0     \n",
      "54  | bert_model.encoder.layer.2.intermediate                | BertIntermediate     | 2.4 M \n",
      "55  | bert_model.encoder.layer.2.intermediate.dense          | Linear               | 2.4 M \n",
      "56  | bert_model.encoder.layer.2.output                      | BertOutput           | 2.4 M \n",
      "57  | bert_model.encoder.layer.2.output.dense                | Linear               | 2.4 M \n",
      "58  | bert_model.encoder.layer.2.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "59  | bert_model.encoder.layer.2.output.dropout              | Dropout              | 0     \n",
      "60  | bert_model.encoder.layer.3                             | BertLayer            | 7.1 M \n",
      "61  | bert_model.encoder.layer.3.attention                   | BertAttention        | 2.4 M \n",
      "62  | bert_model.encoder.layer.3.attention.self              | BertSelfAttention    | 1.8 M \n",
      "63  | bert_model.encoder.layer.3.attention.self.query        | Linear               | 590 K \n",
      "64  | bert_model.encoder.layer.3.attention.self.key          | Linear               | 590 K \n",
      "65  | bert_model.encoder.layer.3.attention.self.value        | Linear               | 590 K \n",
      "66  | bert_model.encoder.layer.3.attention.self.dropout      | Dropout              | 0     \n",
      "67  | bert_model.encoder.layer.3.attention.output            | BertSelfOutput       | 592 K \n",
      "68  | bert_model.encoder.layer.3.attention.output.dense      | Linear               | 590 K \n",
      "69  | bert_model.encoder.layer.3.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "70  | bert_model.encoder.layer.3.attention.output.dropout    | Dropout              | 0     \n",
      "71  | bert_model.encoder.layer.3.intermediate                | BertIntermediate     | 2.4 M \n",
      "72  | bert_model.encoder.layer.3.intermediate.dense          | Linear               | 2.4 M \n",
      "73  | bert_model.encoder.layer.3.output                      | BertOutput           | 2.4 M \n",
      "74  | bert_model.encoder.layer.3.output.dense                | Linear               | 2.4 M \n",
      "75  | bert_model.encoder.layer.3.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "76  | bert_model.encoder.layer.3.output.dropout              | Dropout              | 0     \n",
      "77  | bert_model.encoder.layer.4                             | BertLayer            | 7.1 M \n",
      "78  | bert_model.encoder.layer.4.attention                   | BertAttention        | 2.4 M \n",
      "79  | bert_model.encoder.layer.4.attention.self              | BertSelfAttention    | 1.8 M \n",
      "80  | bert_model.encoder.layer.4.attention.self.query        | Linear               | 590 K \n",
      "81  | bert_model.encoder.layer.4.attention.self.key          | Linear               | 590 K \n",
      "82  | bert_model.encoder.layer.4.attention.self.value        | Linear               | 590 K \n",
      "83  | bert_model.encoder.layer.4.attention.self.dropout      | Dropout              | 0     \n",
      "84  | bert_model.encoder.layer.4.attention.output            | BertSelfOutput       | 592 K \n",
      "85  | bert_model.encoder.layer.4.attention.output.dense      | Linear               | 590 K \n",
      "86  | bert_model.encoder.layer.4.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "87  | bert_model.encoder.layer.4.attention.output.dropout    | Dropout              | 0     \n",
      "88  | bert_model.encoder.layer.4.intermediate                | BertIntermediate     | 2.4 M \n",
      "89  | bert_model.encoder.layer.4.intermediate.dense          | Linear               | 2.4 M \n",
      "90  | bert_model.encoder.layer.4.output                      | BertOutput           | 2.4 M \n",
      "91  | bert_model.encoder.layer.4.output.dense                | Linear               | 2.4 M \n",
      "92  | bert_model.encoder.layer.4.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "93  | bert_model.encoder.layer.4.output.dropout              | Dropout              | 0     \n",
      "94  | bert_model.encoder.layer.5                             | BertLayer            | 7.1 M \n",
      "95  | bert_model.encoder.layer.5.attention                   | BertAttention        | 2.4 M \n",
      "96  | bert_model.encoder.layer.5.attention.self              | BertSelfAttention    | 1.8 M \n",
      "97  | bert_model.encoder.layer.5.attention.self.query        | Linear               | 590 K \n",
      "98  | bert_model.encoder.layer.5.attention.self.key          | Linear               | 590 K \n",
      "99  | bert_model.encoder.layer.5.attention.self.value        | Linear               | 590 K \n",
      "100 | bert_model.encoder.layer.5.attention.self.dropout      | Dropout              | 0     \n",
      "101 | bert_model.encoder.layer.5.attention.output            | BertSelfOutput       | 592 K \n",
      "102 | bert_model.encoder.layer.5.attention.output.dense      | Linear               | 590 K \n",
      "103 | bert_model.encoder.layer.5.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "104 | bert_model.encoder.layer.5.attention.output.dropout    | Dropout              | 0     \n",
      "105 | bert_model.encoder.layer.5.intermediate                | BertIntermediate     | 2.4 M \n",
      "106 | bert_model.encoder.layer.5.intermediate.dense          | Linear               | 2.4 M \n",
      "107 | bert_model.encoder.layer.5.output                      | BertOutput           | 2.4 M \n",
      "108 | bert_model.encoder.layer.5.output.dense                | Linear               | 2.4 M \n",
      "109 | bert_model.encoder.layer.5.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "110 | bert_model.encoder.layer.5.output.dropout              | Dropout              | 0     \n",
      "111 | bert_model.encoder.layer.6                             | BertLayer            | 7.1 M \n",
      "112 | bert_model.encoder.layer.6.attention                   | BertAttention        | 2.4 M \n",
      "113 | bert_model.encoder.layer.6.attention.self              | BertSelfAttention    | 1.8 M \n",
      "114 | bert_model.encoder.layer.6.attention.self.query        | Linear               | 590 K \n",
      "115 | bert_model.encoder.layer.6.attention.self.key          | Linear               | 590 K \n",
      "116 | bert_model.encoder.layer.6.attention.self.value        | Linear               | 590 K \n",
      "117 | bert_model.encoder.layer.6.attention.self.dropout      | Dropout              | 0     \n",
      "118 | bert_model.encoder.layer.6.attention.output            | BertSelfOutput       | 592 K \n",
      "119 | bert_model.encoder.layer.6.attention.output.dense      | Linear               | 590 K \n",
      "120 | bert_model.encoder.layer.6.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "121 | bert_model.encoder.layer.6.attention.output.dropout    | Dropout              | 0     \n",
      "122 | bert_model.encoder.layer.6.intermediate                | BertIntermediate     | 2.4 M \n",
      "123 | bert_model.encoder.layer.6.intermediate.dense          | Linear               | 2.4 M \n",
      "124 | bert_model.encoder.layer.6.output                      | BertOutput           | 2.4 M \n",
      "125 | bert_model.encoder.layer.6.output.dense                | Linear               | 2.4 M \n",
      "126 | bert_model.encoder.layer.6.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "127 | bert_model.encoder.layer.6.output.dropout              | Dropout              | 0     \n",
      "128 | bert_model.encoder.layer.7                             | BertLayer            | 7.1 M \n",
      "129 | bert_model.encoder.layer.7.attention                   | BertAttention        | 2.4 M \n",
      "130 | bert_model.encoder.layer.7.attention.self              | BertSelfAttention    | 1.8 M \n",
      "131 | bert_model.encoder.layer.7.attention.self.query        | Linear               | 590 K \n",
      "132 | bert_model.encoder.layer.7.attention.self.key          | Linear               | 590 K \n",
      "133 | bert_model.encoder.layer.7.attention.self.value        | Linear               | 590 K \n",
      "134 | bert_model.encoder.layer.7.attention.self.dropout      | Dropout              | 0     \n",
      "135 | bert_model.encoder.layer.7.attention.output            | BertSelfOutput       | 592 K \n",
      "136 | bert_model.encoder.layer.7.attention.output.dense      | Linear               | 590 K \n",
      "137 | bert_model.encoder.layer.7.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "138 | bert_model.encoder.layer.7.attention.output.dropout    | Dropout              | 0     \n",
      "139 | bert_model.encoder.layer.7.intermediate                | BertIntermediate     | 2.4 M \n",
      "140 | bert_model.encoder.layer.7.intermediate.dense          | Linear               | 2.4 M \n",
      "141 | bert_model.encoder.layer.7.output                      | BertOutput           | 2.4 M \n",
      "142 | bert_model.encoder.layer.7.output.dense                | Linear               | 2.4 M \n",
      "143 | bert_model.encoder.layer.7.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "144 | bert_model.encoder.layer.7.output.dropout              | Dropout              | 0     \n",
      "145 | bert_model.encoder.layer.8                             | BertLayer            | 7.1 M \n",
      "146 | bert_model.encoder.layer.8.attention                   | BertAttention        | 2.4 M \n",
      "147 | bert_model.encoder.layer.8.attention.self              | BertSelfAttention    | 1.8 M \n",
      "148 | bert_model.encoder.layer.8.attention.self.query        | Linear               | 590 K \n",
      "149 | bert_model.encoder.layer.8.attention.self.key          | Linear               | 590 K \n",
      "150 | bert_model.encoder.layer.8.attention.self.value        | Linear               | 590 K \n",
      "151 | bert_model.encoder.layer.8.attention.self.dropout      | Dropout              | 0     \n",
      "152 | bert_model.encoder.layer.8.attention.output            | BertSelfOutput       | 592 K \n",
      "153 | bert_model.encoder.layer.8.attention.output.dense      | Linear               | 590 K \n",
      "154 | bert_model.encoder.layer.8.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "155 | bert_model.encoder.layer.8.attention.output.dropout    | Dropout              | 0     \n",
      "156 | bert_model.encoder.layer.8.intermediate                | BertIntermediate     | 2.4 M \n",
      "157 | bert_model.encoder.layer.8.intermediate.dense          | Linear               | 2.4 M \n",
      "158 | bert_model.encoder.layer.8.output                      | BertOutput           | 2.4 M \n",
      "159 | bert_model.encoder.layer.8.output.dense                | Linear               | 2.4 M \n",
      "160 | bert_model.encoder.layer.8.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "161 | bert_model.encoder.layer.8.output.dropout              | Dropout              | 0     \n",
      "162 | bert_model.encoder.layer.9                             | BertLayer            | 7.1 M \n",
      "163 | bert_model.encoder.layer.9.attention                   | BertAttention        | 2.4 M \n",
      "164 | bert_model.encoder.layer.9.attention.self              | BertSelfAttention    | 1.8 M \n",
      "165 | bert_model.encoder.layer.9.attention.self.query        | Linear               | 590 K \n",
      "166 | bert_model.encoder.layer.9.attention.self.key          | Linear               | 590 K \n",
      "167 | bert_model.encoder.layer.9.attention.self.value        | Linear               | 590 K \n",
      "168 | bert_model.encoder.layer.9.attention.self.dropout      | Dropout              | 0     \n",
      "169 | bert_model.encoder.layer.9.attention.output            | BertSelfOutput       | 592 K \n",
      "170 | bert_model.encoder.layer.9.attention.output.dense      | Linear               | 590 K \n",
      "171 | bert_model.encoder.layer.9.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "172 | bert_model.encoder.layer.9.attention.output.dropout    | Dropout              | 0     \n",
      "173 | bert_model.encoder.layer.9.intermediate                | BertIntermediate     | 2.4 M \n",
      "174 | bert_model.encoder.layer.9.intermediate.dense          | Linear               | 2.4 M \n",
      "175 | bert_model.encoder.layer.9.output                      | BertOutput           | 2.4 M \n",
      "176 | bert_model.encoder.layer.9.output.dense                | Linear               | 2.4 M \n",
      "177 | bert_model.encoder.layer.9.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "178 | bert_model.encoder.layer.9.output.dropout              | Dropout              | 0     \n",
      "179 | bert_model.encoder.layer.10                            | BertLayer            | 7.1 M \n",
      "180 | bert_model.encoder.layer.10.attention                  | BertAttention        | 2.4 M \n",
      "181 | bert_model.encoder.layer.10.attention.self             | BertSelfAttention    | 1.8 M \n",
      "182 | bert_model.encoder.layer.10.attention.self.query       | Linear               | 590 K \n",
      "183 | bert_model.encoder.layer.10.attention.self.key         | Linear               | 590 K \n",
      "184 | bert_model.encoder.layer.10.attention.self.value       | Linear               | 590 K \n",
      "185 | bert_model.encoder.layer.10.attention.self.dropout     | Dropout              | 0     \n",
      "186 | bert_model.encoder.layer.10.attention.output           | BertSelfOutput       | 592 K \n",
      "187 | bert_model.encoder.layer.10.attention.output.dense     | Linear               | 590 K \n",
      "188 | bert_model.encoder.layer.10.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "189 | bert_model.encoder.layer.10.attention.output.dropout   | Dropout              | 0     \n",
      "190 | bert_model.encoder.layer.10.intermediate               | BertIntermediate     | 2.4 M \n",
      "191 | bert_model.encoder.layer.10.intermediate.dense         | Linear               | 2.4 M \n",
      "192 | bert_model.encoder.layer.10.output                     | BertOutput           | 2.4 M \n",
      "193 | bert_model.encoder.layer.10.output.dense               | Linear               | 2.4 M \n",
      "194 | bert_model.encoder.layer.10.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "195 | bert_model.encoder.layer.10.output.dropout             | Dropout              | 0     \n",
      "196 | bert_model.encoder.layer.11                            | BertLayer            | 7.1 M \n",
      "197 | bert_model.encoder.layer.11.attention                  | BertAttention        | 2.4 M \n",
      "198 | bert_model.encoder.layer.11.attention.self             | BertSelfAttention    | 1.8 M \n",
      "199 | bert_model.encoder.layer.11.attention.self.query       | Linear               | 590 K \n",
      "200 | bert_model.encoder.layer.11.attention.self.key         | Linear               | 590 K \n",
      "201 | bert_model.encoder.layer.11.attention.self.value       | Linear               | 590 K \n",
      "202 | bert_model.encoder.layer.11.attention.self.dropout     | Dropout              | 0     \n",
      "203 | bert_model.encoder.layer.11.attention.output           | BertSelfOutput       | 592 K \n",
      "204 | bert_model.encoder.layer.11.attention.output.dense     | Linear               | 590 K \n",
      "205 | bert_model.encoder.layer.11.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "206 | bert_model.encoder.layer.11.attention.output.dropout   | Dropout              | 0     \n",
      "207 | bert_model.encoder.layer.11.intermediate               | BertIntermediate     | 2.4 M \n",
      "208 | bert_model.encoder.layer.11.intermediate.dense         | Linear               | 2.4 M \n",
      "209 | bert_model.encoder.layer.11.output                     | BertOutput           | 2.4 M \n",
      "210 | bert_model.encoder.layer.11.output.dense               | Linear               | 2.4 M \n",
      "211 | bert_model.encoder.layer.11.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "212 | bert_model.encoder.layer.11.output.dropout             | Dropout              | 0     \n",
      "213 | bert_model.pooler                                      | BertPooler           | 590 K \n",
      "214 | bert_model.pooler.dense                                | Linear               | 590 K \n",
      "215 | bert_model.pooler.activation                           | Tanh                 | 0     \n",
      "216 | classifier                                             | TokenClassifier      | 603 K \n",
      "217 | classifier.dropout                                     | Dropout              | 0     \n",
      "218 | classifier.mlp                                         | MultiLayerPerceptron | 603 K \n",
      "219 | classifier.mlp.layer0                                  | Linear               | 590 K \n",
      "220 | classifier.mlp.layer2                                  | Linear               | 13.1 K\n",
      "221 | loss                                                   | CrossEntropyLoss     | 0     \n",
      "222 | classification_report                                  | ClassificationReport | 0     \n",
      "--------------------------------------------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "\n",
      "    | Name                                                   | Type                 | Params\n",
      "--------------------------------------------------------------------------------------------------\n",
      "0   | bert_model                                             | BertEncoder          | 109 M \n",
      "1   | bert_model.embeddings                                  | BertEmbeddings       | 23.8 M\n",
      "2   | bert_model.embeddings.word_embeddings                  | Embedding            | 23.4 M\n",
      "3   | bert_model.embeddings.position_embeddings              | Embedding            | 393 K \n",
      "4   | bert_model.embeddings.token_type_embeddings            | Embedding            | 1.5 K \n",
      "5   | bert_model.embeddings.LayerNorm                        | LayerNorm            | 1.5 K \n",
      "6   | bert_model.embeddings.dropout                          | Dropout              | 0     \n",
      "7   | bert_model.encoder                                     | BertEncoder          | 85.1 M\n",
      "8   | bert_model.encoder.layer                               | ModuleList           | 85.1 M\n",
      "9   | bert_model.encoder.layer.0                             | BertLayer            | 7.1 M \n",
      "10  | bert_model.encoder.layer.0.attention                   | BertAttention        | 2.4 M \n",
      "11  | bert_model.encoder.layer.0.attention.self              | BertSelfAttention    | 1.8 M \n",
      "12  | bert_model.encoder.layer.0.attention.self.query        | Linear               | 590 K \n",
      "13  | bert_model.encoder.layer.0.attention.self.key          | Linear               | 590 K \n",
      "14  | bert_model.encoder.layer.0.attention.self.value        | Linear               | 590 K \n",
      "15  | bert_model.encoder.layer.0.attention.self.dropout      | Dropout              | 0     \n",
      "16  | bert_model.encoder.layer.0.attention.output            | BertSelfOutput       | 592 K \n",
      "17  | bert_model.encoder.layer.0.attention.output.dense      | Linear               | 590 K \n",
      "18  | bert_model.encoder.layer.0.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "19  | bert_model.encoder.layer.0.attention.output.dropout    | Dropout              | 0     \n",
      "20  | bert_model.encoder.layer.0.intermediate                | BertIntermediate     | 2.4 M \n",
      "21  | bert_model.encoder.layer.0.intermediate.dense          | Linear               | 2.4 M \n",
      "22  | bert_model.encoder.layer.0.output                      | BertOutput           | 2.4 M \n",
      "23  | bert_model.encoder.layer.0.output.dense                | Linear               | 2.4 M \n",
      "24  | bert_model.encoder.layer.0.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "25  | bert_model.encoder.layer.0.output.dropout              | Dropout              | 0     \n",
      "26  | bert_model.encoder.layer.1                             | BertLayer            | 7.1 M \n",
      "27  | bert_model.encoder.layer.1.attention                   | BertAttention        | 2.4 M \n",
      "28  | bert_model.encoder.layer.1.attention.self              | BertSelfAttention    | 1.8 M \n",
      "29  | bert_model.encoder.layer.1.attention.self.query        | Linear               | 590 K \n",
      "30  | bert_model.encoder.layer.1.attention.self.key          | Linear               | 590 K \n",
      "31  | bert_model.encoder.layer.1.attention.self.value        | Linear               | 590 K \n",
      "32  | bert_model.encoder.layer.1.attention.self.dropout      | Dropout              | 0     \n",
      "33  | bert_model.encoder.layer.1.attention.output            | BertSelfOutput       | 592 K \n",
      "34  | bert_model.encoder.layer.1.attention.output.dense      | Linear               | 590 K \n",
      "35  | bert_model.encoder.layer.1.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "36  | bert_model.encoder.layer.1.attention.output.dropout    | Dropout              | 0     \n",
      "37  | bert_model.encoder.layer.1.intermediate                | BertIntermediate     | 2.4 M \n",
      "38  | bert_model.encoder.layer.1.intermediate.dense          | Linear               | 2.4 M \n",
      "39  | bert_model.encoder.layer.1.output                      | BertOutput           | 2.4 M \n",
      "40  | bert_model.encoder.layer.1.output.dense                | Linear               | 2.4 M \n",
      "41  | bert_model.encoder.layer.1.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "42  | bert_model.encoder.layer.1.output.dropout              | Dropout              | 0     \n",
      "43  | bert_model.encoder.layer.2                             | BertLayer            | 7.1 M \n",
      "44  | bert_model.encoder.layer.2.attention                   | BertAttention        | 2.4 M \n",
      "45  | bert_model.encoder.layer.2.attention.self              | BertSelfAttention    | 1.8 M \n",
      "46  | bert_model.encoder.layer.2.attention.self.query        | Linear               | 590 K \n",
      "47  | bert_model.encoder.layer.2.attention.self.key          | Linear               | 590 K \n",
      "48  | bert_model.encoder.layer.2.attention.self.value        | Linear               | 590 K \n",
      "49  | bert_model.encoder.layer.2.attention.self.dropout      | Dropout              | 0     \n",
      "50  | bert_model.encoder.layer.2.attention.output            | BertSelfOutput       | 592 K \n",
      "51  | bert_model.encoder.layer.2.attention.output.dense      | Linear               | 590 K \n",
      "52  | bert_model.encoder.layer.2.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "53  | bert_model.encoder.layer.2.attention.output.dropout    | Dropout              | 0     \n",
      "54  | bert_model.encoder.layer.2.intermediate                | BertIntermediate     | 2.4 M \n",
      "55  | bert_model.encoder.layer.2.intermediate.dense          | Linear               | 2.4 M \n",
      "56  | bert_model.encoder.layer.2.output                      | BertOutput           | 2.4 M \n",
      "57  | bert_model.encoder.layer.2.output.dense                | Linear               | 2.4 M \n",
      "58  | bert_model.encoder.layer.2.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "59  | bert_model.encoder.layer.2.output.dropout              | Dropout              | 0     \n",
      "60  | bert_model.encoder.layer.3                             | BertLayer            | 7.1 M \n",
      "61  | bert_model.encoder.layer.3.attention                   | BertAttention        | 2.4 M \n",
      "62  | bert_model.encoder.layer.3.attention.self              | BertSelfAttention    | 1.8 M \n",
      "63  | bert_model.encoder.layer.3.attention.self.query        | Linear               | 590 K \n",
      "64  | bert_model.encoder.layer.3.attention.self.key          | Linear               | 590 K \n",
      "65  | bert_model.encoder.layer.3.attention.self.value        | Linear               | 590 K \n",
      "66  | bert_model.encoder.layer.3.attention.self.dropout      | Dropout              | 0     \n",
      "67  | bert_model.encoder.layer.3.attention.output            | BertSelfOutput       | 592 K \n",
      "68  | bert_model.encoder.layer.3.attention.output.dense      | Linear               | 590 K \n",
      "69  | bert_model.encoder.layer.3.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "70  | bert_model.encoder.layer.3.attention.output.dropout    | Dropout              | 0     \n",
      "71  | bert_model.encoder.layer.3.intermediate                | BertIntermediate     | 2.4 M \n",
      "72  | bert_model.encoder.layer.3.intermediate.dense          | Linear               | 2.4 M \n",
      "73  | bert_model.encoder.layer.3.output                      | BertOutput           | 2.4 M \n",
      "74  | bert_model.encoder.layer.3.output.dense                | Linear               | 2.4 M \n",
      "75  | bert_model.encoder.layer.3.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "76  | bert_model.encoder.layer.3.output.dropout              | Dropout              | 0     \n",
      "77  | bert_model.encoder.layer.4                             | BertLayer            | 7.1 M \n",
      "78  | bert_model.encoder.layer.4.attention                   | BertAttention        | 2.4 M \n",
      "79  | bert_model.encoder.layer.4.attention.self              | BertSelfAttention    | 1.8 M \n",
      "80  | bert_model.encoder.layer.4.attention.self.query        | Linear               | 590 K \n",
      "81  | bert_model.encoder.layer.4.attention.self.key          | Linear               | 590 K \n",
      "82  | bert_model.encoder.layer.4.attention.self.value        | Linear               | 590 K \n",
      "83  | bert_model.encoder.layer.4.attention.self.dropout      | Dropout              | 0     \n",
      "84  | bert_model.encoder.layer.4.attention.output            | BertSelfOutput       | 592 K \n",
      "85  | bert_model.encoder.layer.4.attention.output.dense      | Linear               | 590 K \n",
      "86  | bert_model.encoder.layer.4.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "87  | bert_model.encoder.layer.4.attention.output.dropout    | Dropout              | 0     \n",
      "88  | bert_model.encoder.layer.4.intermediate                | BertIntermediate     | 2.4 M \n",
      "89  | bert_model.encoder.layer.4.intermediate.dense          | Linear               | 2.4 M \n",
      "90  | bert_model.encoder.layer.4.output                      | BertOutput           | 2.4 M \n",
      "91  | bert_model.encoder.layer.4.output.dense                | Linear               | 2.4 M \n",
      "92  | bert_model.encoder.layer.4.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "93  | bert_model.encoder.layer.4.output.dropout              | Dropout              | 0     \n",
      "94  | bert_model.encoder.layer.5                             | BertLayer            | 7.1 M \n",
      "95  | bert_model.encoder.layer.5.attention                   | BertAttention        | 2.4 M \n",
      "96  | bert_model.encoder.layer.5.attention.self              | BertSelfAttention    | 1.8 M \n",
      "97  | bert_model.encoder.layer.5.attention.self.query        | Linear               | 590 K \n",
      "98  | bert_model.encoder.layer.5.attention.self.key          | Linear               | 590 K \n",
      "99  | bert_model.encoder.layer.5.attention.self.value        | Linear               | 590 K \n",
      "100 | bert_model.encoder.layer.5.attention.self.dropout      | Dropout              | 0     \n",
      "101 | bert_model.encoder.layer.5.attention.output            | BertSelfOutput       | 592 K \n",
      "102 | bert_model.encoder.layer.5.attention.output.dense      | Linear               | 590 K \n",
      "103 | bert_model.encoder.layer.5.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "104 | bert_model.encoder.layer.5.attention.output.dropout    | Dropout              | 0     \n",
      "105 | bert_model.encoder.layer.5.intermediate                | BertIntermediate     | 2.4 M \n",
      "106 | bert_model.encoder.layer.5.intermediate.dense          | Linear               | 2.4 M \n",
      "107 | bert_model.encoder.layer.5.output                      | BertOutput           | 2.4 M \n",
      "108 | bert_model.encoder.layer.5.output.dense                | Linear               | 2.4 M \n",
      "109 | bert_model.encoder.layer.5.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "110 | bert_model.encoder.layer.5.output.dropout              | Dropout              | 0     \n",
      "111 | bert_model.encoder.layer.6                             | BertLayer            | 7.1 M \n",
      "112 | bert_model.encoder.layer.6.attention                   | BertAttention        | 2.4 M \n",
      "113 | bert_model.encoder.layer.6.attention.self              | BertSelfAttention    | 1.8 M \n",
      "114 | bert_model.encoder.layer.6.attention.self.query        | Linear               | 590 K \n",
      "115 | bert_model.encoder.layer.6.attention.self.key          | Linear               | 590 K \n",
      "116 | bert_model.encoder.layer.6.attention.self.value        | Linear               | 590 K \n",
      "117 | bert_model.encoder.layer.6.attention.self.dropout      | Dropout              | 0     \n",
      "118 | bert_model.encoder.layer.6.attention.output            | BertSelfOutput       | 592 K \n",
      "119 | bert_model.encoder.layer.6.attention.output.dense      | Linear               | 590 K \n",
      "120 | bert_model.encoder.layer.6.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "121 | bert_model.encoder.layer.6.attention.output.dropout    | Dropout              | 0     \n",
      "122 | bert_model.encoder.layer.6.intermediate                | BertIntermediate     | 2.4 M \n",
      "123 | bert_model.encoder.layer.6.intermediate.dense          | Linear               | 2.4 M \n",
      "124 | bert_model.encoder.layer.6.output                      | BertOutput           | 2.4 M \n",
      "125 | bert_model.encoder.layer.6.output.dense                | Linear               | 2.4 M \n",
      "126 | bert_model.encoder.layer.6.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "127 | bert_model.encoder.layer.6.output.dropout              | Dropout              | 0     \n",
      "128 | bert_model.encoder.layer.7                             | BertLayer            | 7.1 M \n",
      "129 | bert_model.encoder.layer.7.attention                   | BertAttention        | 2.4 M \n",
      "130 | bert_model.encoder.layer.7.attention.self              | BertSelfAttention    | 1.8 M \n",
      "131 | bert_model.encoder.layer.7.attention.self.query        | Linear               | 590 K \n",
      "132 | bert_model.encoder.layer.7.attention.self.key          | Linear               | 590 K \n",
      "133 | bert_model.encoder.layer.7.attention.self.value        | Linear               | 590 K \n",
      "134 | bert_model.encoder.layer.7.attention.self.dropout      | Dropout              | 0     \n",
      "135 | bert_model.encoder.layer.7.attention.output            | BertSelfOutput       | 592 K \n",
      "136 | bert_model.encoder.layer.7.attention.output.dense      | Linear               | 590 K \n",
      "137 | bert_model.encoder.layer.7.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "138 | bert_model.encoder.layer.7.attention.output.dropout    | Dropout              | 0     \n",
      "139 | bert_model.encoder.layer.7.intermediate                | BertIntermediate     | 2.4 M \n",
      "140 | bert_model.encoder.layer.7.intermediate.dense          | Linear               | 2.4 M \n",
      "141 | bert_model.encoder.layer.7.output                      | BertOutput           | 2.4 M \n",
      "142 | bert_model.encoder.layer.7.output.dense                | Linear               | 2.4 M \n",
      "143 | bert_model.encoder.layer.7.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "144 | bert_model.encoder.layer.7.output.dropout              | Dropout              | 0     \n",
      "145 | bert_model.encoder.layer.8                             | BertLayer            | 7.1 M \n",
      "146 | bert_model.encoder.layer.8.attention                   | BertAttention        | 2.4 M \n",
      "147 | bert_model.encoder.layer.8.attention.self              | BertSelfAttention    | 1.8 M \n",
      "148 | bert_model.encoder.layer.8.attention.self.query        | Linear               | 590 K \n",
      "149 | bert_model.encoder.layer.8.attention.self.key          | Linear               | 590 K \n",
      "150 | bert_model.encoder.layer.8.attention.self.value        | Linear               | 590 K \n",
      "151 | bert_model.encoder.layer.8.attention.self.dropout      | Dropout              | 0     \n",
      "152 | bert_model.encoder.layer.8.attention.output            | BertSelfOutput       | 592 K \n",
      "153 | bert_model.encoder.layer.8.attention.output.dense      | Linear               | 590 K \n",
      "154 | bert_model.encoder.layer.8.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "155 | bert_model.encoder.layer.8.attention.output.dropout    | Dropout              | 0     \n",
      "156 | bert_model.encoder.layer.8.intermediate                | BertIntermediate     | 2.4 M \n",
      "157 | bert_model.encoder.layer.8.intermediate.dense          | Linear               | 2.4 M \n",
      "158 | bert_model.encoder.layer.8.output                      | BertOutput           | 2.4 M \n",
      "159 | bert_model.encoder.layer.8.output.dense                | Linear               | 2.4 M \n",
      "160 | bert_model.encoder.layer.8.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "161 | bert_model.encoder.layer.8.output.dropout              | Dropout              | 0     \n",
      "162 | bert_model.encoder.layer.9                             | BertLayer            | 7.1 M \n",
      "163 | bert_model.encoder.layer.9.attention                   | BertAttention        | 2.4 M \n",
      "164 | bert_model.encoder.layer.9.attention.self              | BertSelfAttention    | 1.8 M \n",
      "165 | bert_model.encoder.layer.9.attention.self.query        | Linear               | 590 K \n",
      "166 | bert_model.encoder.layer.9.attention.self.key          | Linear               | 590 K \n",
      "167 | bert_model.encoder.layer.9.attention.self.value        | Linear               | 590 K \n",
      "168 | bert_model.encoder.layer.9.attention.self.dropout      | Dropout              | 0     \n",
      "169 | bert_model.encoder.layer.9.attention.output            | BertSelfOutput       | 592 K \n",
      "170 | bert_model.encoder.layer.9.attention.output.dense      | Linear               | 590 K \n",
      "171 | bert_model.encoder.layer.9.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "172 | bert_model.encoder.layer.9.attention.output.dropout    | Dropout              | 0     \n",
      "173 | bert_model.encoder.layer.9.intermediate                | BertIntermediate     | 2.4 M \n",
      "174 | bert_model.encoder.layer.9.intermediate.dense          | Linear               | 2.4 M \n",
      "175 | bert_model.encoder.layer.9.output                      | BertOutput           | 2.4 M \n",
      "176 | bert_model.encoder.layer.9.output.dense                | Linear               | 2.4 M \n",
      "177 | bert_model.encoder.layer.9.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "178 | bert_model.encoder.layer.9.output.dropout              | Dropout              | 0     \n",
      "179 | bert_model.encoder.layer.10                            | BertLayer            | 7.1 M \n",
      "180 | bert_model.encoder.layer.10.attention                  | BertAttention        | 2.4 M \n",
      "181 | bert_model.encoder.layer.10.attention.self             | BertSelfAttention    | 1.8 M \n",
      "182 | bert_model.encoder.layer.10.attention.self.query       | Linear               | 590 K \n",
      "183 | bert_model.encoder.layer.10.attention.self.key         | Linear               | 590 K \n",
      "184 | bert_model.encoder.layer.10.attention.self.value       | Linear               | 590 K \n",
      "185 | bert_model.encoder.layer.10.attention.self.dropout     | Dropout              | 0     \n",
      "186 | bert_model.encoder.layer.10.attention.output           | BertSelfOutput       | 592 K \n",
      "187 | bert_model.encoder.layer.10.attention.output.dense     | Linear               | 590 K \n",
      "188 | bert_model.encoder.layer.10.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "189 | bert_model.encoder.layer.10.attention.output.dropout   | Dropout              | 0     \n",
      "190 | bert_model.encoder.layer.10.intermediate               | BertIntermediate     | 2.4 M \n",
      "191 | bert_model.encoder.layer.10.intermediate.dense         | Linear               | 2.4 M \n",
      "192 | bert_model.encoder.layer.10.output                     | BertOutput           | 2.4 M \n",
      "193 | bert_model.encoder.layer.10.output.dense               | Linear               | 2.4 M \n",
      "194 | bert_model.encoder.layer.10.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "195 | bert_model.encoder.layer.10.output.dropout             | Dropout              | 0     \n",
      "196 | bert_model.encoder.layer.11                            | BertLayer            | 7.1 M \n",
      "197 | bert_model.encoder.layer.11.attention                  | BertAttention        | 2.4 M \n",
      "198 | bert_model.encoder.layer.11.attention.self             | BertSelfAttention    | 1.8 M \n",
      "199 | bert_model.encoder.layer.11.attention.self.query       | Linear               | 590 K \n",
      "200 | bert_model.encoder.layer.11.attention.self.key         | Linear               | 590 K \n",
      "201 | bert_model.encoder.layer.11.attention.self.value       | Linear               | 590 K \n",
      "202 | bert_model.encoder.layer.11.attention.self.dropout     | Dropout              | 0     \n",
      "203 | bert_model.encoder.layer.11.attention.output           | BertSelfOutput       | 592 K \n",
      "204 | bert_model.encoder.layer.11.attention.output.dense     | Linear               | 590 K \n",
      "205 | bert_model.encoder.layer.11.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "206 | bert_model.encoder.layer.11.attention.output.dropout   | Dropout              | 0     \n",
      "207 | bert_model.encoder.layer.11.intermediate               | BertIntermediate     | 2.4 M \n",
      "208 | bert_model.encoder.layer.11.intermediate.dense         | Linear               | 2.4 M \n",
      "209 | bert_model.encoder.layer.11.output                     | BertOutput           | 2.4 M \n",
      "210 | bert_model.encoder.layer.11.output.dense               | Linear               | 2.4 M \n",
      "211 | bert_model.encoder.layer.11.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "212 | bert_model.encoder.layer.11.output.dropout             | Dropout              | 0     \n",
      "213 | bert_model.pooler                                      | BertPooler           | 590 K \n",
      "214 | bert_model.pooler.dense                                | Linear               | 590 K \n",
      "215 | bert_model.pooler.activation                           | Tanh                 | 0     \n",
      "216 | classifier                                             | TokenClassifier      | 603 K \n",
      "217 | classifier.dropout                                     | Dropout              | 0     \n",
      "218 | classifier.mlp                                         | MultiLayerPerceptron | 603 K \n",
      "219 | classifier.mlp.layer0                                  | Linear               | 590 K \n",
      "220 | classifier.mlp.layer2                                  | Linear               | 13.1 K\n",
      "221 | loss                                                   | CrossEntropyLoss     | 0     \n",
      "222 | classification_report                                  | ClassificationReport | 0     \n",
      "--------------------------------------------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "Validation sanity check: 100%|████████████████████| 2/2 [00:01<00:00,  1.56it/s][NeMo I 2022-04-27 07:27:31 token_classification_model:178] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         49.23       4.80       8.74        667\n",
      "    B-Amenity (label_id: 1)                                  0.00       0.00       0.00         49\n",
      "    B-Cuisine (label_id: 2)                                  3.85       1.85       2.50         54\n",
      "    B-Dish (label_id: 3)                                     2.58      21.74       4.61         23\n",
      "    B-Hours (label_id: 4)                                    3.03      15.79       5.08         19\n",
      "    B-Location (label_id: 5)                                 0.00       0.00       0.00         92\n",
      "    B-Price (label_id: 6)                                    0.00       0.00       0.00         12\n",
      "    B-Rating (label_id: 7)                                   1.66      66.67       3.25         15\n",
      "    B-Restaurant_Name (label_id: 8)                          0.00       0.00       0.00         14\n",
      "    I-Amenity (label_id: 9)                                  0.00       0.00       0.00         56\n",
      "    I-Cuisine (label_id: 10)                                 0.74       6.67       1.33         15\n",
      "    I-Dish (label_id: 11)                                    0.00       0.00       0.00          9\n",
      "    I-Hours (label_id: 12)                                   7.41       5.13       6.06         39\n",
      "    I-Location (label_id: 13)                                0.00       0.00       0.00        103\n",
      "    I-Price (label_id: 14)                                   0.00       0.00       0.00          6\n",
      "    I-Rating (label_id: 15)                                  0.00       0.00       0.00          6\n",
      "    I-Restaurant_Name (label_id: 16)                       100.00       5.26      10.00         19\n",
      "    -------------------\n",
      "    micro avg                                                4.59       4.59       4.59       1198\n",
      "    macro avg                                                9.91       7.52       2.45       1198\n",
      "    weighted avg                                            29.54       4.59       5.56       1198\n",
      "    \n",
      "Epoch 0:  83%|▊| 120/144 [00:46<00:09,  2.60it/s, loss=0.596, val_loss=2.83, lr=\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  85%|▊| 122/144 [00:46<00:08,  2.63it/s, loss=0.596, val_loss=2.83, lr=\u001b[A\n",
      "Validating:   8%|██▋                             | 2/24 [00:00<00:04,  5.40it/s]\u001b[A\n",
      "Epoch 0:  86%|▊| 124/144 [00:46<00:07,  2.66it/s, loss=0.596, val_loss=2.83, lr=\u001b[A\n",
      "Validating:  17%|█████▎                          | 4/24 [00:00<00:02,  6.95it/s]\u001b[A\n",
      "Epoch 0:  88%|▉| 126/144 [00:46<00:06,  2.69it/s, loss=0.596, val_loss=2.83, lr=\u001b[A\n",
      "Validating:  25%|████████                        | 6/24 [00:00<00:02,  8.09it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 128/144 [00:47<00:05,  2.72it/s, loss=0.596, val_loss=2.83, lr=\u001b[A\n",
      "Validating:  33%|██████████▋                     | 8/24 [00:00<00:01,  8.74it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 130/144 [00:47<00:05,  2.75it/s, loss=0.596, val_loss=2.83, lr=\u001b[A\n",
      "Validating:  42%|████████████▉                  | 10/24 [00:01<00:01,  9.07it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 132/144 [00:47<00:04,  2.78it/s, loss=0.596, val_loss=2.83, lr=\u001b[A\n",
      "Validating:  50%|███████████████▌               | 12/24 [00:01<00:01,  9.25it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 134/144 [00:47<00:03,  2.81it/s, loss=0.596, val_loss=2.83, lr=\u001b[A\n",
      "Validating:  58%|██████████████████             | 14/24 [00:01<00:01,  9.36it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 136/144 [00:47<00:02,  2.84it/s, loss=0.596, val_loss=2.83, lr=\u001b[A\n",
      "Validating:  67%|████████████████████▋          | 16/24 [00:01<00:00,  9.46it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 138/144 [00:48<00:02,  2.87it/s, loss=0.596, val_loss=2.83, lr=\u001b[A\n",
      "Validating:  75%|███████████████████████▎       | 18/24 [00:02<00:00,  9.47it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 140/144 [00:48<00:01,  2.90it/s, loss=0.596, val_loss=2.83, lr=\u001b[A\n",
      "Validating:  83%|█████████████████████████▊     | 20/24 [00:02<00:00,  9.49it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 142/144 [00:48<00:00,  2.93it/s, loss=0.596, val_loss=2.83, lr=\u001b[A\n",
      "Validating:  92%|████████████████████████████▍  | 22/24 [00:02<00:00,  9.49it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 144/144 [00:48<00:00,  2.96it/s, loss=0.596, val_loss=2.83, lr=\u001b[A[NeMo I 2022-04-27 07:28:20 token_classification_model:178] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         94.33      96.49      95.40       8659\n",
      "    B-Amenity (label_id: 1)                                 59.66      59.10      59.38        533\n",
      "    B-Cuisine (label_id: 2)                                 69.17      86.47      76.86        532\n",
      "    B-Dish (label_id: 3)                                    55.26      78.47      64.85        288\n",
      "    B-Hours (label_id: 4)                                   60.00       1.42       2.76        212\n",
      "    B-Location (label_id: 5)                                85.63      85.84      85.73        812\n",
      "    B-Price (label_id: 6)                                    0.00       0.00       0.00        171\n",
      "    B-Rating (label_id: 7)                                  46.65      83.08      59.75        201\n",
      "    B-Restaurant_Name (label_id: 8)                         56.21      90.05      69.22        402\n",
      "    I-Amenity (label_id: 9)                                 61.16      62.21      61.68        524\n",
      "    I-Cuisine (label_id: 10)                                 0.00       0.00       0.00        135\n",
      "    I-Dish (label_id: 11)                                    0.00       0.00       0.00        121\n",
      "    I-Hours (label_id: 12)                                  54.13      95.59      69.12        295\n",
      "    I-Location (label_id: 13)                               83.98      88.45      86.16        788\n",
      "    I-Price (label_id: 14)                                   0.00       0.00       0.00         66\n",
      "    I-Rating (label_id: 15)                                  0.00       0.00       0.00        125\n",
      "    I-Restaurant_Name (label_id: 16)                        70.65      16.58      26.86        392\n",
      "    -------------------\n",
      "    micro avg                                               83.86      83.86      83.86      14256\n",
      "    macro avg                                               46.87      49.63      44.57      14256\n",
      "    weighted avg                                            81.19      83.86      81.26      14256\n",
      "    \n",
      "Epoch 0: 100%|█| 144/144 [00:48<00:00,  2.95it/s, loss=0.596, val_loss=0.509, lr\n",
      "                                                                                \u001b[AEpoch 0, global step 119: val_loss reached 0.50906 (best 0.50906), saving model to \"/workspace/mount/results/bert-base_ner/checkpoints/trained-model---val_loss=0.51-epoch=0.ckpt\" as top 3\n",
      "Epoch 0, global step 119: val_loss reached 0.50906 (best 0.50906), saving model to \"/workspace/mount/results/bert-base_ner/checkpoints/trained-model---val_loss=0.51-epoch=0.ckpt\" as top 3\n",
      "Epoch 1:  83%|▊| 120/144 [00:47<00:09,  2.52it/s, loss=0.294, val_loss=0.509, lr\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  85%|▊| 122/144 [00:47<00:08,  2.55it/s, loss=0.294, val_loss=0.509, lr\u001b[A\n",
      "Validating:   8%|██▋                             | 2/24 [00:00<00:04,  5.20it/s]\u001b[A\n",
      "Epoch 1:  86%|▊| 124/144 [00:48<00:07,  2.58it/s, loss=0.294, val_loss=0.509, lr\u001b[A\n",
      "Validating:  17%|█████▎                          | 4/24 [00:00<00:02,  6.67it/s]\u001b[A\n",
      "Epoch 1:  88%|▉| 126/144 [00:48<00:06,  2.61it/s, loss=0.294, val_loss=0.509, lr\u001b[A\n",
      "Validating:  25%|████████                        | 6/24 [00:00<00:02,  7.80it/s]\u001b[A\n",
      "Epoch 1:  89%|▉| 128/144 [00:48<00:06,  2.64it/s, loss=0.294, val_loss=0.509, lr\u001b[A\n",
      "Validating:  33%|██████████▋                     | 8/24 [00:00<00:01,  8.48it/s]\u001b[A\n",
      "Epoch 1:  90%|▉| 130/144 [00:48<00:05,  2.66it/s, loss=0.294, val_loss=0.509, lr\u001b[A\n",
      "Validating:  42%|████████████▉                  | 10/24 [00:01<00:01,  8.81it/s]\u001b[A\n",
      "Epoch 1:  92%|▉| 132/144 [00:49<00:04,  2.69it/s, loss=0.294, val_loss=0.509, lr\u001b[A\n",
      "Validating:  50%|███████████████▌               | 12/24 [00:01<00:01,  8.99it/s]\u001b[A\n",
      "Epoch 1:  93%|▉| 134/144 [00:49<00:03,  2.72it/s, loss=0.294, val_loss=0.509, lr\u001b[A\n",
      "Validating:  58%|██████████████████             | 14/24 [00:01<00:01,  9.09it/s]\u001b[A\n",
      "Epoch 1:  94%|▉| 136/144 [00:49<00:02,  2.75it/s, loss=0.294, val_loss=0.509, lr\u001b[A\n",
      "Validating:  67%|████████████████████▋          | 16/24 [00:01<00:00,  9.14it/s]\u001b[A\n",
      "Epoch 1:  96%|▉| 138/144 [00:49<00:02,  2.78it/s, loss=0.294, val_loss=0.509, lr\u001b[A\n",
      "Validating:  75%|███████████████████████▎       | 18/24 [00:02<00:00,  9.19it/s]\u001b[A\n",
      "Epoch 1:  97%|▉| 140/144 [00:49<00:01,  2.81it/s, loss=0.294, val_loss=0.509, lr\u001b[A\n",
      "Validating:  83%|█████████████████████████▊     | 20/24 [00:02<00:00,  9.20it/s]\u001b[A\n",
      "Epoch 1:  99%|▉| 142/144 [00:50<00:00,  2.84it/s, loss=0.294, val_loss=0.509, lr\u001b[A\n",
      "Validating:  92%|████████████████████████████▍  | 22/24 [00:02<00:00,  9.24it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 144/144 [00:50<00:00,  2.86it/s, loss=0.294, val_loss=0.509, lr\u001b[A[NeMo I 2022-04-27 07:29:35 token_classification_model:178] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         97.00      95.29      96.14       8659\n",
      "    B-Amenity (label_id: 1)                                 73.57      79.36      76.35        533\n",
      "    B-Cuisine (label_id: 2)                                 89.60      84.21      86.82        532\n",
      "    B-Dish (label_id: 3)                                    77.64      86.81      81.97        288\n",
      "    B-Hours (label_id: 4)                                   70.59      73.58      72.06        212\n",
      "    B-Location (label_id: 5)                                89.83      90.27      90.05        812\n",
      "    B-Price (label_id: 6)                                   75.00      89.47      81.60        171\n",
      "    B-Rating (label_id: 7)                                  77.12      90.55      83.30        201\n",
      "    B-Restaurant_Name (label_id: 8)                         94.43      92.79      93.60        402\n",
      "    I-Amenity (label_id: 9)                                 74.61      81.87      78.07        524\n",
      "    I-Cuisine (label_id: 10)                                78.35      56.30      65.52        135\n",
      "    I-Dish (label_id: 11)                                   66.88      88.43      76.16        121\n",
      "    I-Hours (label_id: 12)                                  82.98      92.54      87.50        295\n",
      "    I-Location (label_id: 13)                               89.77      87.94      88.85        788\n",
      "    I-Price (label_id: 14)                                 100.00      19.70      32.91         66\n",
      "    I-Rating (label_id: 15)                                 83.90      79.20      81.48        125\n",
      "    I-Restaurant_Name (label_id: 16)                        86.33      91.84      89.00        392\n",
      "    -------------------\n",
      "    micro avg                                               91.32      91.32      91.32      14256\n",
      "    macro avg                                               82.80      81.19      80.08      14256\n",
      "    weighted avg                                            91.70      91.32      91.31      14256\n",
      "    \n",
      "Epoch 1: 100%|█| 144/144 [00:50<00:00,  2.85it/s, loss=0.294, val_loss=0.276, lr\n",
      "                                                                                \u001b[AEpoch 1, global step 239: val_loss reached 0.27615 (best 0.27615), saving model to \"/workspace/mount/results/bert-base_ner/checkpoints/trained-model---val_loss=0.28-epoch=1.ckpt\" as top 3\n",
      "Epoch 1, global step 239: val_loss reached 0.27615 (best 0.27615), saving model to \"/workspace/mount/results/bert-base_ner/checkpoints/trained-model---val_loss=0.28-epoch=1.ckpt\" as top 3\n",
      "Epoch 2:  83%|▊| 120/144 [00:48<00:09,  2.47it/s, loss=0.214, val_loss=0.276, lr\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  85%|▊| 122/144 [00:48<00:08,  2.50it/s, loss=0.214, val_loss=0.276, lr\u001b[A\n",
      "Validating:   8%|██▋                             | 2/24 [00:00<00:04,  5.40it/s]\u001b[A\n",
      "Epoch 2:  86%|▊| 124/144 [00:48<00:07,  2.53it/s, loss=0.214, val_loss=0.276, lr\u001b[A\n",
      "Validating:  17%|█████▎                          | 4/24 [00:00<00:02,  6.85it/s]\u001b[A\n",
      "Epoch 2:  88%|▉| 126/144 [00:49<00:07,  2.56it/s, loss=0.214, val_loss=0.276, lr\u001b[A\n",
      "Validating:  25%|████████                        | 6/24 [00:00<00:02,  7.82it/s]\u001b[A\n",
      "Epoch 2:  89%|▉| 128/144 [00:49<00:06,  2.59it/s, loss=0.214, val_loss=0.276, lr\u001b[A\n",
      "Validating:  33%|██████████▋                     | 8/24 [00:00<00:01,  8.42it/s]\u001b[A\n",
      "Epoch 2:  90%|▉| 130/144 [00:49<00:05,  2.62it/s, loss=0.214, val_loss=0.276, lr\u001b[A\n",
      "Validating:  42%|████████████▉                  | 10/24 [00:01<00:01,  8.71it/s]\u001b[A\n",
      "Epoch 2:  92%|▉| 132/144 [00:49<00:04,  2.65it/s, loss=0.214, val_loss=0.276, lr\u001b[A\n",
      "Validating:  50%|███████████████▌               | 12/24 [00:01<00:01,  8.93it/s]\u001b[A\n",
      "Epoch 2:  93%|▉| 134/144 [00:50<00:03,  2.68it/s, loss=0.214, val_loss=0.276, lr\u001b[A\n",
      "Validating:  58%|██████████████████             | 14/24 [00:01<00:01,  9.01it/s]\u001b[A\n",
      "Epoch 2:  94%|▉| 136/144 [00:50<00:02,  2.71it/s, loss=0.214, val_loss=0.276, lr\u001b[A\n",
      "Validating:  67%|████████████████████▋          | 16/24 [00:01<00:00,  9.08it/s]\u001b[A\n",
      "Epoch 2:  96%|▉| 138/144 [00:50<00:02,  2.73it/s, loss=0.214, val_loss=0.276, lr\u001b[A\n",
      "Validating:  75%|███████████████████████▎       | 18/24 [00:02<00:00,  9.10it/s]\u001b[A\n",
      "Epoch 2:  97%|▉| 140/144 [00:50<00:01,  2.76it/s, loss=0.214, val_loss=0.276, lr\u001b[A\n",
      "Validating:  83%|█████████████████████████▊     | 20/24 [00:02<00:00,  9.09it/s]\u001b[A\n",
      "Epoch 2:  99%|▉| 142/144 [00:50<00:00,  2.79it/s, loss=0.214, val_loss=0.276, lr\u001b[A\n",
      "Validating:  92%|████████████████████████████▍  | 22/24 [00:02<00:00,  9.05it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 144/144 [00:51<00:00,  2.82it/s, loss=0.214, val_loss=0.276, lr\u001b[A[NeMo I 2022-04-27 07:30:55 token_classification_model:178] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         97.03      95.40      96.21       8659\n",
      "    B-Amenity (label_id: 1)                                 77.44      77.30      77.37        533\n",
      "    B-Cuisine (label_id: 2)                                 89.78      84.21      86.91        532\n",
      "    B-Dish (label_id: 3)                                    76.08      91.67      83.15        288\n",
      "    B-Hours (label_id: 4)                                   70.72      74.06      72.35        212\n",
      "    B-Location (label_id: 5)                                90.63      90.52      90.57        812\n",
      "    B-Price (label_id: 6)                                   81.03      92.40      86.34        171\n",
      "    B-Rating (label_id: 7)                                  76.07      88.56      81.84        201\n",
      "    B-Restaurant_Name (label_id: 8)                         94.87      92.04      93.43        402\n",
      "    I-Amenity (label_id: 9)                                 83.27      78.82      80.98        524\n",
      "    I-Cuisine (label_id: 10)                                74.80      70.37      72.52        135\n",
      "    I-Dish (label_id: 11)                                   69.68      89.26      78.26        121\n",
      "    I-Hours (label_id: 12)                                  86.13      90.51      88.26        295\n",
      "    I-Location (label_id: 13)                               85.32      93.65      89.29        788\n",
      "    I-Price (label_id: 14)                                  85.71      63.64      73.04         66\n",
      "    I-Rating (label_id: 15)                                 81.60      81.60      81.60        125\n",
      "    I-Restaurant_Name (label_id: 16)                        90.39      88.78      89.58        392\n",
      "    -------------------\n",
      "    micro avg                                               91.86      91.86      91.86      14256\n",
      "    macro avg                                               82.97      84.87      83.63      14256\n",
      "    weighted avg                                            92.11      91.86      91.92      14256\n",
      "    \n",
      "Epoch 2: 100%|█| 144/144 [00:51<00:00,  2.81it/s, loss=0.214, val_loss=0.258, lr\n",
      "                                                                                \u001b[AEpoch 2, global step 359: val_loss reached 0.25835 (best 0.25835), saving model to \"/workspace/mount/results/bert-base_ner/checkpoints/trained-model---val_loss=0.26-epoch=2.ckpt\" as top 3\n",
      "Epoch 2, global step 359: val_loss reached 0.25835 (best 0.25835), saving model to \"/workspace/mount/results/bert-base_ner/checkpoints/trained-model---val_loss=0.26-epoch=2.ckpt\" as top 3\n",
      "Epoch 3:  83%|▊| 120/144 [00:48<00:09,  2.45it/s, loss=0.164, val_loss=0.258, lr\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 3:  85%|▊| 122/144 [00:49<00:08,  2.48it/s, loss=0.164, val_loss=0.258, lr\u001b[A\n",
      "Validating:   8%|██▋                             | 2/24 [00:00<00:04,  5.41it/s]\u001b[A\n",
      "Epoch 3:  86%|▊| 124/144 [00:49<00:07,  2.51it/s, loss=0.164, val_loss=0.258, lr\u001b[A\n",
      "Validating:  17%|█████▎                          | 4/24 [00:00<00:02,  6.80it/s]\u001b[A\n",
      "Epoch 3:  88%|▉| 126/144 [00:49<00:07,  2.54it/s, loss=0.164, val_loss=0.258, lr\u001b[A\n",
      "Validating:  25%|████████                        | 6/24 [00:00<00:02,  7.80it/s]\u001b[A\n",
      "Epoch 3:  89%|▉| 128/144 [00:49<00:06,  2.57it/s, loss=0.164, val_loss=0.258, lr\u001b[A\n",
      "Validating:  33%|██████████▋                     | 8/24 [00:00<00:01,  8.30it/s]\u001b[A\n",
      "Epoch 3:  90%|▉| 130/144 [00:50<00:05,  2.60it/s, loss=0.164, val_loss=0.258, lr\u001b[A\n",
      "Validating:  42%|████████████▉                  | 10/24 [00:01<00:01,  8.57it/s]\u001b[A\n",
      "Epoch 3:  92%|▉| 132/144 [00:50<00:04,  2.62it/s, loss=0.164, val_loss=0.258, lr\u001b[A\n",
      "Validating:  50%|███████████████▌               | 12/24 [00:01<00:01,  8.77it/s]\u001b[A\n",
      "Epoch 3:  93%|▉| 134/144 [00:50<00:03,  2.65it/s, loss=0.164, val_loss=0.258, lr\u001b[A\n",
      "Validating:  58%|██████████████████             | 14/24 [00:01<00:01,  8.87it/s]\u001b[A\n",
      "Epoch 3:  94%|▉| 136/144 [00:50<00:02,  2.68it/s, loss=0.164, val_loss=0.258, lr\u001b[A\n",
      "Validating:  67%|████████████████████▋          | 16/24 [00:01<00:00,  8.92it/s]\u001b[A\n",
      "Epoch 3:  96%|▉| 138/144 [00:50<00:02,  2.71it/s, loss=0.164, val_loss=0.258, lr\u001b[A\n",
      "Validating:  75%|███████████████████████▎       | 18/24 [00:02<00:00,  8.90it/s]\u001b[A\n",
      "Epoch 3:  97%|▉| 140/144 [00:51<00:01,  2.73it/s, loss=0.164, val_loss=0.258, lr\u001b[A\n",
      "Validating:  83%|█████████████████████████▊     | 20/24 [00:02<00:00,  8.94it/s]\u001b[A\n",
      "Epoch 3:  99%|▉| 142/144 [00:51<00:00,  2.76it/s, loss=0.164, val_loss=0.258, lr\u001b[A\n",
      "Validating:  92%|████████████████████████████▍  | 22/24 [00:02<00:00,  8.97it/s]\u001b[A\n",
      "Epoch 3: 100%|█| 144/144 [00:51<00:00,  2.79it/s, loss=0.164, val_loss=0.258, lr\u001b[A[NeMo I 2022-04-27 07:32:16 token_classification_model:178] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         96.89      95.37      96.12       8659\n",
      "    B-Amenity (label_id: 1)                                 76.20      74.48      75.33        533\n",
      "    B-Cuisine (label_id: 2)                                 86.13      88.72      87.41        532\n",
      "    B-Dish (label_id: 3)                                    84.62      84.03      84.32        288\n",
      "    B-Hours (label_id: 4)                                   69.43      75.00      72.11        212\n",
      "    B-Location (label_id: 5)                                90.49      90.27      90.38        812\n",
      "    B-Price (label_id: 6)                                   81.54      92.98      86.89        171\n",
      "    B-Rating (label_id: 7)                                  77.29      88.06      82.33        201\n",
      "    B-Restaurant_Name (label_id: 8)                         94.25      93.78      94.01        402\n",
      "    I-Amenity (label_id: 9)                                 78.08      80.92      79.48        524\n",
      "    I-Cuisine (label_id: 10)                                70.92      74.07      72.46        135\n",
      "    I-Dish (label_id: 11)                                   73.38      84.30      78.46        121\n",
      "    I-Hours (label_id: 12)                                  83.69      93.90      88.50        295\n",
      "    I-Location (label_id: 13)                               87.39      91.50      89.40        788\n",
      "    I-Price (label_id: 14)                                  81.48      66.67      73.33         66\n",
      "    I-Rating (label_id: 15)                                 86.84      79.20      82.85        125\n",
      "    I-Restaurant_Name (label_id: 16)                        93.21      87.50      90.26        392\n",
      "    -------------------\n",
      "    micro avg                                               91.78      91.78      91.78      14256\n",
      "    macro avg                                               83.05      84.75      83.74      14256\n",
      "    weighted avg                                            91.96      91.78      91.84      14256\n",
      "    \n",
      "Epoch 3: 100%|█| 144/144 [00:51<00:00,  2.78it/s, loss=0.164, val_loss=0.259, lr\n",
      "                                                                                \u001b[AEpoch 3, global step 479: val_loss reached 0.25870 (best 0.25835), saving model to \"/workspace/mount/results/bert-base_ner/checkpoints/trained-model---val_loss=0.26-epoch=3.ckpt\" as top 3\n",
      "Epoch 3, global step 479: val_loss reached 0.25870 (best 0.25835), saving model to \"/workspace/mount/results/bert-base_ner/checkpoints/trained-model---val_loss=0.26-epoch=3.ckpt\" as top 3\n",
      "Epoch 4:  83%|▊| 120/144 [00:49<00:09,  2.44it/s, loss=0.138, val_loss=0.259, lr\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 4:  85%|▊| 122/144 [00:49<00:08,  2.47it/s, loss=0.138, val_loss=0.259, lr\u001b[A\n",
      "Validating:   8%|██▋                             | 2/24 [00:00<00:04,  5.18it/s]\u001b[A\n",
      "Epoch 4:  86%|▊| 124/144 [00:49<00:08,  2.50it/s, loss=0.138, val_loss=0.259, lr\u001b[A\n",
      "Validating:  17%|█████▎                          | 4/24 [00:00<00:03,  6.58it/s]\u001b[A\n",
      "Epoch 4:  88%|▉| 126/144 [00:49<00:07,  2.52it/s, loss=0.138, val_loss=0.259, lr\u001b[A\n",
      "Validating:  25%|████████                        | 6/24 [00:00<00:02,  7.62it/s]\u001b[A\n",
      "Epoch 4:  89%|▉| 128/144 [00:50<00:06,  2.55it/s, loss=0.138, val_loss=0.259, lr\u001b[A\n",
      "Validating:  33%|██████████▋                     | 8/24 [00:01<00:01,  8.14it/s]\u001b[A\n",
      "Epoch 4:  90%|▉| 130/144 [00:50<00:05,  2.58it/s, loss=0.138, val_loss=0.259, lr\u001b[A\n",
      "Validating:  42%|████████████▉                  | 10/24 [00:01<00:01,  8.51it/s]\u001b[A\n",
      "Epoch 4:  92%|▉| 132/144 [00:50<00:04,  2.61it/s, loss=0.138, val_loss=0.259, lr\u001b[A\n",
      "Validating:  50%|███████████████▌               | 12/24 [00:01<00:01,  8.68it/s]\u001b[A\n",
      "Epoch 4:  93%|▉| 134/144 [00:50<00:03,  2.64it/s, loss=0.138, val_loss=0.259, lr\u001b[A\n",
      "Validating:  58%|██████████████████             | 14/24 [00:01<00:01,  8.78it/s]\u001b[A\n",
      "Epoch 4:  94%|▉| 136/144 [00:51<00:03,  2.67it/s, loss=0.138, val_loss=0.259, lr\u001b[A\n",
      "Validating:  67%|████████████████████▋          | 16/24 [00:01<00:00,  8.83it/s]\u001b[A\n",
      "Epoch 4:  96%|▉| 138/144 [00:51<00:02,  2.69it/s, loss=0.138, val_loss=0.259, lr\u001b[A\n",
      "Validating:  75%|███████████████████████▎       | 18/24 [00:02<00:00,  8.85it/s]\u001b[A\n",
      "Epoch 4:  97%|▉| 140/144 [00:51<00:01,  2.72it/s, loss=0.138, val_loss=0.259, lr\u001b[A\n",
      "Validating:  83%|█████████████████████████▊     | 20/24 [00:02<00:00,  8.87it/s]\u001b[A\n",
      "Epoch 4:  99%|▉| 142/144 [00:51<00:00,  2.75it/s, loss=0.138, val_loss=0.259, lr\u001b[A\n",
      "Validating:  92%|████████████████████████████▍  | 22/24 [00:02<00:00,  8.87it/s]\u001b[A\n",
      "Epoch 4: 100%|█| 144/144 [00:51<00:00,  2.77it/s, loss=0.138, val_loss=0.259, lr\u001b[A[NeMo I 2022-04-27 07:33:37 token_classification_model:178] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         96.83      95.57      96.19       8659\n",
      "    B-Amenity (label_id: 1)                                 75.55      77.11      76.32        533\n",
      "    B-Cuisine (label_id: 2)                                 89.44      87.59      88.51        532\n",
      "    B-Dish (label_id: 3)                                    81.88      84.72      83.28        288\n",
      "    B-Hours (label_id: 4)                                   70.00      75.94      72.85        212\n",
      "    B-Location (label_id: 5)                                90.49      90.27      90.38        812\n",
      "    B-Price (label_id: 6)                                   82.01      90.64      86.11        171\n",
      "    B-Rating (label_id: 7)                                  78.90      85.57      82.10        201\n",
      "    B-Restaurant_Name (label_id: 8)                         94.67      92.79      93.72        402\n",
      "    I-Amenity (label_id: 9)                                 78.77      82.82      80.74        524\n",
      "    I-Cuisine (label_id: 10)                                74.24      72.59      73.41        135\n",
      "    I-Dish (label_id: 11)                                   71.72      85.95      78.20        121\n",
      "    I-Hours (label_id: 12)                                  84.10      93.22      88.42        295\n",
      "    I-Location (label_id: 13)                               88.34      90.36      89.33        788\n",
      "    I-Price (label_id: 14)                                  78.33      71.21      74.60         66\n",
      "    I-Rating (label_id: 15)                                 86.73      78.40      82.35        125\n",
      "    I-Restaurant_Name (label_id: 16)                        91.94      87.24      89.53        392\n",
      "    -------------------\n",
      "    micro avg                                               91.89      91.89      91.89      14256\n",
      "    macro avg                                               83.17      84.82      83.89      14256\n",
      "    weighted avg                                            92.07      91.89      91.95      14256\n",
      "    \n",
      "Epoch 4: 100%|█| 144/144 [00:52<00:00,  2.77it/s, loss=0.138, val_loss=0.261, lr\n",
      "                                                                                \u001b[AEpoch 4, global step 599: val_loss reached 0.26073 (best 0.25835), saving model to \"/workspace/mount/results/bert-base_ner/checkpoints/trained-model---val_loss=0.26-epoch=4.ckpt\" as top 3\n",
      "Epoch 4, global step 599: val_loss reached 0.26073 (best 0.25835), saving model to \"/workspace/mount/results/bert-base_ner/checkpoints/trained-model---val_loss=0.26-epoch=4.ckpt\" as top 3\n",
      "Epoch 4: 100%|█| 144/144 [01:02<00:00,  2.30it/s, loss=0.138, val_loss=0.261, lrSaving latest checkpoint...\n",
      "Saving latest checkpoint...\n",
      "Epoch 4: 100%|█| 144/144 [01:20<00:00,  1.78it/s, loss=0.138, val_loss=0.261, lr\n",
      "[NeMo I 2022-04-27 07:34:27 train:129] Experiment logs saved to '/workspace/mount/results/bert-base_ner'\n",
      "[NeMo I 2022-04-27 07:34:27 train:130] Trained model saved to '/workspace/mount/results/bert-base_ner/checkpoints/trained-model.tlt'\n",
      "2022-04-27 07:34:28,995 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n",
      "CPU times: user 6.3 s, sys: 1.7 s, total: 8 s\n",
      "Wall time: 7min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# TAO train NER model - this takes few minutes\n",
    "!tao token_classification train \\\n",
    "    -e $SPECS_DIR/token_classification/train.yaml \\\n",
    "    -g 1  \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/bert-base_ner \\\n",
    "    data_dir={destination_mount}/data/restaurant \\\n",
    "    model.label_ids={destination_mount}/data/restaurant/label_ids.csv \\\n",
    "    trainer.max_epochs=5 \\\n",
    "    training_ds.num_samples=-1 \\\n",
    "    validation_ds.num_samples=-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The train command produces `trained-model.tlt` saved at `$RESULTS_DIR/bert-base_ner/checkpoints/trained-model.tlt`. \n",
    "This file can be fed directly into the fine-tuning stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.3 Faster Training with AMP\n",
    "There are a number of parameters you can change for training.  For example, the batch size (`training_ds.batch_size`) may influence the validation accuracy. Larger batch sizes are faster to train with, however, you may get slighly better results with smaller batches.\n",
    "\n",
    "An important consideration is the [Automatic Mixed Precision (AMP)](https://developer.nvidia.com/automatic-mixed-precision) setting.  To accelerate the training without loss of quality, it is possible to train with these parameters:  `trainer.amp_level=\"O1\"` and `trainer.precision=16` for reduced precision.\n",
    "\n",
    "Experiment by training again using mixed precision:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time \n",
    "# TAO train NER model with mixed precision\n",
    "!tao token_classification train \\\n",
    "    -e $SPECS_DIR/token_classification/train.yaml \\\n",
    "    -g 1  \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/bert-base_ner_fp16 \\\n",
    "    data_dir={destination_mount}/data/restaurant \\\n",
    "    model.label_ids={destination_mount}/data/restaurant/label_ids.csv \\\n",
    "    trainer.max_epochs=3 \\\n",
    "    trainer.amp_level=\"O1\" \\\n",
    "    trainer.precision=16 \\\n",
    "    training_ds.num_samples=-1 \\\n",
    "    validation_ds.num_samples=-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the two trainings with and without AMP in terms of:\n",
    "- Training duration?\n",
    "- NER Model performance?\n",
    "\n",
    "Discuss your observations with the instructor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.4 Change the Language Model\n",
    "\n",
    "Before training the NER classifier, the input text is encoded using a language model. TAO Toolkit supports four BERT and Megatron language models: \n",
    "- `bert-base-cased`\n",
    "- `bert-base-uncased`\n",
    "- `megatron-bert-345m-cased`\n",
    "- `megatron-bert-345m-uncased`\n",
    "\n",
    "By default, TAO Toolkit uses `bert-base-uncased`. This is the encoder you've used so far for training. To specify a different language model, add the `pretrained_model_name` argument to the launch command:\n",
    "```python\n",
    "    model.language_model.pretrained_model_name=<language-model-name>\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 07:34:58,113 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-04-27 07:34:58,240 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-04-27 07:35:02 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-04-27 07:35:06 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-04-27 07:35:07 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: ???\n",
      "    exp_manager:\n",
      "      explicit_log_dir: /workspace/mount/results/megatron-base_ner5\n",
      "      exp_dir: null\n",
      "      name: trained-model\n",
      "      version: null\n",
      "      use_datetime_version: true\n",
      "      resume_if_exists: true\n",
      "      resume_past_end: false\n",
      "      resume_ignore_no_checkpoint: true\n",
      "      create_tensorboard_logger: false\n",
      "      summary_writer_kwargs: null\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs: null\n",
      "      create_checkpoint_callback: false\n",
      "      checkpoint_callback_params:\n",
      "        filepath: null\n",
      "        monitor: val_loss\n",
      "        verbose: true\n",
      "        save_last: true\n",
      "        save_top_k: 3\n",
      "        save_weights_only: false\n",
      "        mode: auto\n",
      "        period: 1\n",
      "        prefix: null\n",
      "        postfix: .tlt\n",
      "        save_best_model: false\n",
      "      files_to_copy: null\n",
      "    model:\n",
      "      tokenizer:\n",
      "        tokenizer_name: ${model.language_model.pretrained_model_name}\n",
      "        vocab_file: null\n",
      "        tokenizer_model: null\n",
      "        special_tokens: null\n",
      "      language_model:\n",
      "        pretrained_model_name: megatron-bert-345m-uncased\n",
      "        lm_checkpoint: null\n",
      "        config_file: null\n",
      "        config: null\n",
      "      head:\n",
      "        num_fc_layers: 2\n",
      "        fc_dropout: 0.5\n",
      "        activation: relu\n",
      "        use_transformer_init: true\n",
      "      label_ids: /workspace/mount/data/restaurant/label_ids.csv\n",
      "      dataset:\n",
      "        data_dir: null\n",
      "        class_balancing: null\n",
      "        max_seq_length: 128\n",
      "        pad_label: O\n",
      "        ignore_extra_tokens: false\n",
      "        ignore_start_end: false\n",
      "        use_cache: true\n",
      "        num_workers: 3\n",
      "        drop_last: false\n",
      "        pin_memory: false\n",
      "    trainer:\n",
      "      logger: false\n",
      "      checkpoint_callback: false\n",
      "      callbacks: null\n",
      "      default_root_dir: null\n",
      "      gradient_clip_val: 0.0\n",
      "      process_position: 0\n",
      "      num_nodes: 1\n",
      "      num_processes: 1\n",
      "      gpus: 1\n",
      "      auto_select_gpus: false\n",
      "      tpu_cores: null\n",
      "      log_gpu_memory: null\n",
      "      progress_bar_refresh_rate: 1\n",
      "      overfit_batches: 0.0\n",
      "      track_grad_norm: -1\n",
      "      check_val_every_n_epoch: 1\n",
      "      fast_dev_run: false\n",
      "      accumulate_grad_batches: 1\n",
      "      max_epochs: 3\n",
      "      min_epochs: 1\n",
      "      max_steps: null\n",
      "      min_steps: null\n",
      "      limit_train_batches: 1.0\n",
      "      limit_val_batches: 1.0\n",
      "      limit_test_batches: 1.0\n",
      "      val_check_interval: 1.0\n",
      "      flush_logs_every_n_steps: 100\n",
      "      log_every_n_steps: 50\n",
      "      accelerator: ddp\n",
      "      sync_batchnorm: false\n",
      "      precision: 16\n",
      "      weights_summary: full\n",
      "      weights_save_path: null\n",
      "      num_sanity_val_steps: 2\n",
      "      truncated_bptt_steps: null\n",
      "      resume_from_checkpoint: null\n",
      "      profiler: null\n",
      "      benchmark: false\n",
      "      deterministic: false\n",
      "      reload_dataloaders_every_epoch: false\n",
      "      auto_lr_find: false\n",
      "      replace_sampler_ddp: true\n",
      "      terminate_on_nan: false\n",
      "      auto_scale_batch_size: false\n",
      "      prepare_data_per_node: true\n",
      "      amp_backend: native\n",
      "      amp_level: O1\n",
      "    training_ds:\n",
      "      batch_size: 64\n",
      "      text_file: text_train.txt\n",
      "      labels_file: labels_train.txt\n",
      "      shuffle: true\n",
      "      num_samples: -1\n",
      "    validation_ds:\n",
      "      batch_size: 64\n",
      "      text_file: text_dev.txt\n",
      "      labels_file: labels_dev.txt\n",
      "      shuffle: false\n",
      "      num_samples: -1\n",
      "    data_dir: /workspace/mount/data/restaurant\n",
      "    optim:\n",
      "      name: adam\n",
      "      lr: 5.0e-05\n",
      "      weight_decay: 0.0\n",
      "      sched:\n",
      "        name: WarmupAnnealing\n",
      "        warmup_steps: null\n",
      "        warmup_ratio: 0.1\n",
      "        last_epoch: -1\n",
      "        monitor: val_loss\n",
      "        reduce_on_plateau: false\n",
      "    encryption_key: '*******'\n",
      "    \n",
      "GPU available: True, used: True\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "Using native 16bit precision.\n",
      "[NeMo W 2022-04-27 07:35:07 exp_manager:303] There was no checkpoint folder at checkpoint_dir :/workspace/mount/results/megatron-base_ner5/checkpoints. Training from scratch.\n",
      "[NeMo I 2022-04-27 07:35:07 exp_manager:194] Experiments will be logged at /workspace/mount/results/megatron-base_ner5\n",
      "[NeMo I 2022-04-27 07:35:07 token_classification_model:61] Reusing label_ids file found at /workspace/mount/data/restaurant/label_ids.csv.\n",
      "[NeMo I 2022-04-27 07:35:07 megatron_utils:266] Downloading from https://s3.amazonaws.com/models.huggingface.co/bert/bert-large-uncased-vocab.txt\n",
      "100% [........................................................] 231508 / 231508Lock 139772688047504 acquired on /root/.cache/huggingface/transformers/1cf090f220f9674b67b3434decfe4d40a6532d7849653eac435ff94d31a4904c.1d03e5e4fa2db2532c517b2cd98290d8444b237619bd3d2039850a6d5e86473d.lock\n",
      "Downloading: 100%|██████████████████████████████| 571/571 [00:00<00:00, 499kB/s]\n",
      "Lock 139772688047504 released on /root/.cache/huggingface/transformers/1cf090f220f9674b67b3434decfe4d40a6532d7849653eac435ff94d31a4904c.1d03e5e4fa2db2532c517b2cd98290d8444b237619bd3d2039850a6d5e86473d.lock\n",
      "Lock 139772688047360 acquired on /root/.cache/huggingface/transformers/e12f02d630da91a0982ce6db1ad595231d155a2b725ab106971898276d842ecc.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100%|███████████████████████████| 232k/232k [00:00<00:00, 14.2MB/s]\n",
      "Lock 139772688047360 released on /root/.cache/huggingface/transformers/e12f02d630da91a0982ce6db1ad595231d155a2b725ab106971898276d842ecc.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 139772688798480 acquired on /root/.cache/huggingface/transformers/300ecd79785b4602752c0085f8a89c3f0232ef367eda291c79a5600f3778b677.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100%|███████████████████████████| 28.0/28.0 [00:00<00:00, 25.3kB/s]\n",
      "Lock 139772688798480 released on /root/.cache/huggingface/transformers/300ecd79785b4602752c0085f8a89c3f0232ef367eda291c79a5600f3778b677.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 139772688353456 acquired on /root/.cache/huggingface/transformers/475d46024228961ca8770cead39e1079f135fd2441d14cf216727ffac8d41d78.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100%|███████████████████████████| 466k/466k [00:00<00:00, 39.8MB/s]\n",
      "Lock 139772688353456 released on /root/.cache/huggingface/transformers/475d46024228961ca8770cead39e1079f135fd2441d14cf216727ffac8d41d78.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo I 2022-04-27 07:35:07 megatron_utils:266] Downloading from https://api.ngc.nvidia.com/v2/models/nvidia/megatron_bert_345m/versions/v0.0/files/release/mp_rank_00/model_optim_rng.pt\n",
      "100% [..................................................] 672662168 / 672662168using world size: 1 and model-parallel size: 1 \n",
      "using torch.float32 for parameters ...\n",
      "-------------------- arguments --------------------\n",
      "  adlr_autoresume ................. False\n",
      "  adlr_autoresume_interval ........ 1000\n",
      "  apply_query_key_layer_scaling ... False\n",
      "  apply_residual_connection_post_layernorm  False\n",
      "  attention_dropout ............... 0.1\n",
      "  attention_softmax_in_fp32 ....... False\n",
      "  batch_size ...................... None\n",
      "  bert_load ....................... None\n",
      "  bias_dropout_fusion ............. False\n",
      "  bias_gelu_fusion ................ False\n",
      "  block_data_path ................. None\n",
      "  checkpoint_activations .......... False\n",
      "  checkpoint_num_layers ........... 1\n",
      "  clip_grad ....................... 1.0\n",
      "  data_impl ....................... infer\n",
      "  data_path ....................... None\n",
      "  DDP_impl ........................ local\n",
      "  distribute_checkpointed_activations  False\n",
      "  distributed_backend ............. nccl\n",
      "  dynamic_loss_scale .............. True\n",
      "  eod_mask_loss ................... False\n",
      "  eval_interval ................... 1000\n",
      "  eval_iters ...................... 100\n",
      "  exit_interval ................... None\n",
      "  faiss_use_gpu ................... False\n",
      "  finetune ........................ False\n",
      "  fp16 ............................ False\n",
      "  fp16_lm_cross_entropy ........... False\n",
      "  fp32_allreduce .................. False\n",
      "  hidden_dropout .................. 0.1\n",
      "  hidden_size ..................... 1024\n",
      "  hysteresis ...................... 2\n",
      "  ict_head_size ................... None\n",
      "  ict_load ........................ None\n",
      "  indexer_batch_size .............. 128\n",
      "  indexer_log_interval ............ 1000\n",
      "  init_method_std ................. 0.02\n",
      "  layernorm_epsilon ............... 1e-05\n",
      "  lazy_mpu_init ................... True\n",
      "  load ............................ None\n",
      "  local_rank ...................... None\n",
      "  log_interval .................... 100\n",
      "  loss_scale ...................... None\n",
      "  loss_scale_window ............... 1000\n",
      "  lr .............................. None\n",
      "  lr_decay_iters .................. None\n",
      "  lr_decay_style .................. linear\n",
      "  make_vocab_size_divisible_by .... 128\n",
      "  mask_prob ....................... 0.15\n",
      "  max_position_embeddings ......... 512\n",
      "  merge_file ...................... None\n",
      "  min_lr .......................... 0.0\n",
      "  min_scale ....................... 1\n",
      "  mmap_warmup ..................... False\n",
      "  model_parallel_size ............. 1\n",
      "  no_load_optim ................... False\n",
      "  no_load_rng ..................... False\n",
      "  no_save_optim ................... False\n",
      "  no_save_rng ..................... False\n",
      "  num_attention_heads ............. 16\n",
      "  num_layers ...................... 24\n",
      "  num_unique_layers ............... None\n",
      "  num_workers ..................... 2\n",
      "  onnx_safe ....................... True\n",
      "  openai_gelu ..................... False\n",
      "  override_lr_scheduler ........... False\n",
      "  param_sharing_style ............. grouped\n",
      "  params_dtype .................... torch.float32\n",
      "  query_in_block_prob ............. 0.1\n",
      "  rank ............................ 0\n",
      "  report_topk_accuracies .......... []\n",
      "  reset_attention_mask ............ False\n",
      "  reset_position_ids .............. False\n",
      "  save ............................ None\n",
      "  save_interval ................... None\n",
      "  scaled_masked_softmax_fusion .... False\n",
      "  scaled_upper_triang_masked_softmax_fusion  False\n",
      "  seed ............................ 1234\n",
      "  seq_length ...................... None\n",
      "  short_seq_prob .................. 0.1\n",
      "  split ........................... 969, 30, 1\n",
      "  tensorboard_dir ................. None\n",
      "  titles_data_path ................ None\n",
      "  tokenizer_type .................. BertWordPieceLowerCase\n",
      "  train_iters ..................... None\n",
      "  use_checkpoint_lr_scheduler ..... False\n",
      "  use_cpu_initialization .......... False\n",
      "  use_one_sent_docs ............... False\n",
      "  vocab_file ...................... /root/.cache/torch/megatron/megatron-bert-345m-uncased_vocab\n",
      "  warmup .......................... 0.01\n",
      "  weight_decay .................... 0.01\n",
      "  world_size ...................... 1\n",
      "---------------- end of arguments ----------------\n",
      "> building BertWordPieceLowerCase tokenizer ...\n",
      " > padded vocab (size: 30522) with 70 dummy tokens (new size: 30592)\n",
      "[NeMo I 2022-04-27 07:35:39 megatron_bert:103] Megatron-lm argparse args: Namespace(DDP_impl='local', adlr_autoresume=False, adlr_autoresume_interval=1000, apply_query_key_layer_scaling=False, apply_residual_connection_post_layernorm=False, attention_dropout=0.1, attention_softmax_in_fp32=False, batch_size=None, bert_load=None, bias_dropout_fusion=False, bias_gelu_fusion=False, block_data_path=None, checkpoint_activations=False, checkpoint_num_layers=1, clip_grad=1.0, data_impl='infer', data_path=None, distribute_checkpointed_activations=False, distributed_backend='nccl', dynamic_loss_scale=True, eod_mask_loss=False, eval_interval=1000, eval_iters=100, exit_interval=None, faiss_use_gpu=False, finetune=False, fp16=False, fp16_lm_cross_entropy=False, fp32_allreduce=False, hidden_dropout=0.1, hidden_size=1024, hysteresis=2, ict_head_size=None, ict_load=None, indexer_batch_size=128, indexer_log_interval=1000, init_method_std=0.02, layernorm_epsilon=1e-05, lazy_mpu_init=True, load=None, local_rank=None, log_interval=100, loss_scale=None, loss_scale_window=1000, lr=None, lr_decay_iters=None, lr_decay_style='linear', make_vocab_size_divisible_by=128, mask_prob=0.15, max_position_embeddings=512, merge_file=None, min_lr=0.0, min_scale=1, mmap_warmup=False, model_parallel_size=1, no_load_optim=False, no_load_rng=False, no_save_optim=False, no_save_rng=False, num_attention_heads=16, num_layers=24, num_unique_layers=None, num_workers=2, onnx_safe=True, openai_gelu=False, override_lr_scheduler=False, padded_vocab_size=30592, param_sharing_style='grouped', params_dtype=torch.float32, query_in_block_prob=0.1, rank=0, report_topk_accuracies=[], reset_attention_mask=False, reset_position_ids=False, save=None, save_interval=None, scaled_masked_softmax_fusion=False, scaled_upper_triang_masked_softmax_fusion=False, seed=1234, seq_length=None, short_seq_prob=0.1, split='969, 30, 1', tensorboard_dir=None, titles_data_path=None, tokenizer_type='BertWordPieceLowerCase', train_iters=None, use_checkpoint_lr_scheduler=False, use_cpu_initialization=True, use_one_sent_docs=False, vocab_file='/root/.cache/torch/megatron/megatron-bert-345m-uncased_vocab', warmup=0.01, weight_decay=0.01, world_size=1)\n",
      "[NeMo I 2022-04-27 07:35:42 megatron_bert:155] restore_path: /root/.cache/torch/megatron/megatron-bert-345m-uncased is a file. Assuming no megatron model parallelism\n",
      "[NeMo W 2022-04-27 07:35:42 megatron_bert:161] Megatron-lm checkpoint version not found. Setting checkpoint_version to 0.\n",
      "[NeMo I 2022-04-27 07:35:43 megatron_bert:168] weights restored from /root/.cache/torch/megatron/megatron-bert-345m-uncased\n",
      "[NeMo I 2022-04-27 07:35:43 token_classification_model:105] Setting model.dataset.data_dir to /workspace/mount/data/restaurant.\n",
      "[NeMo I 2022-04-27 07:35:43 token_classification_utils:54] Processing /workspace/mount/data/restaurant/labels_train.txt\n",
      "[NeMo I 2022-04-27 07:35:43 token_classification_utils:74] Using provided labels mapping {'O': 0, 'B-Amenity': 1, 'B-Cuisine': 2, 'B-Dish': 3, 'B-Hours': 4, 'B-Location': 5, 'B-Price': 6, 'B-Rating': 7, 'B-Restaurant_Name': 8, 'I-Amenity': 9, 'I-Cuisine': 10, 'I-Dish': 11, 'I-Hours': 12, 'I-Location': 13, 'I-Price': 14, 'I-Rating': 15, 'I-Restaurant_Name': 16}\n",
      "[NeMo I 2022-04-27 07:35:43 token_classification_utils:90] Labels mapping {'O': 0, 'B-Amenity': 1, 'B-Cuisine': 2, 'B-Dish': 3, 'B-Hours': 4, 'B-Location': 5, 'B-Price': 6, 'B-Rating': 7, 'B-Restaurant_Name': 8, 'I-Amenity': 9, 'I-Cuisine': 10, 'I-Dish': 11, 'I-Hours': 12, 'I-Location': 13, 'I-Price': 14, 'I-Rating': 15, 'I-Restaurant_Name': 16} saved to : /workspace/mount/data/restaurant/label_ids.csv\n",
      "[NeMo I 2022-04-27 07:35:46 token_classification_utils:99] Three most popular labels in /workspace/mount/data/restaurant/labels_train.txt:\n",
      "[NeMo I 2022-04-27 07:35:46 data_preprocessing:131] label: 0, 43670 out of 70525 (61.92%).\n",
      "[NeMo I 2022-04-27 07:35:46 data_preprocessing:131] label: 5, 3817 out of 70525 (5.41%).\n",
      "[NeMo I 2022-04-27 07:35:46 data_preprocessing:131] label: 13, 3658 out of 70525 (5.19%).\n",
      "[NeMo I 2022-04-27 07:35:46 token_classification_utils:101] Total labels: 70525. Label frequencies - {0: 43670, 5: 3817, 13: 3658, 2: 2839, 9: 2676, 1: 2541, 8: 1901, 16: 1668, 3: 1475, 12: 1283, 7: 1070, 4: 990, 11: 767, 6: 730, 10: 630, 15: 527, 14: 283}\n",
      "[NeMo I 2022-04-27 07:35:46 token_classification_utils:107] Class weights restored from /workspace/mount/data/restaurant/labels_train_weights.p\n",
      "[NeMo I 2022-04-27 07:35:46 token_classification_dataset:272] features restored from /workspace/mount/data/restaurant/cached_text_train.txt_BertTokenizer_128_30522_-1\n",
      "[NeMo I 2022-04-27 07:35:46 token_classification_utils:54] Processing /workspace/mount/data/restaurant/labels_dev.txt\n",
      "[NeMo I 2022-04-27 07:35:46 token_classification_utils:74] Using provided labels mapping {'O': 0, 'B-Amenity': 1, 'B-Cuisine': 2, 'B-Dish': 3, 'B-Hours': 4, 'B-Location': 5, 'B-Price': 6, 'B-Rating': 7, 'B-Restaurant_Name': 8, 'I-Amenity': 9, 'I-Cuisine': 10, 'I-Dish': 11, 'I-Hours': 12, 'I-Location': 13, 'I-Price': 14, 'I-Rating': 15, 'I-Restaurant_Name': 16}\n",
      "[NeMo I 2022-04-27 07:35:46 token_classification_utils:96] /workspace/mount/data/restaurant/labels_dev_label_stats.tsv found, skipping stats calculation.\n",
      "[NeMo I 2022-04-27 07:35:46 token_classification_dataset:272] features restored from /workspace/mount/data/restaurant/cached_text_dev.txt_BertTokenizer_128_30522_-1\n",
      "[NeMo I 2022-04-27 07:35:46 modelPT:753] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        eps: 1e-08\n",
      "        lr: 5e-05\n",
      "        weight_decay: 0.0\n",
      "    )\n",
      "[NeMo I 2022-04-27 07:35:46 lr_scheduler:617] Scheduler \"<nemo.core.optim.lr_scheduler.WarmupAnnealing object at 0x7f1f5d9e4bb0>\" \n",
      "    will be used during training (effective maximum steps = 360) - \n",
      "    Parameters : \n",
      "    (warmup_steps: null\n",
      "    warmup_ratio: 0.1\n",
      "    last_epoch: -1\n",
      "    max_steps: 360\n",
      "    )\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "torch distributed is already initialized, skipping initialization ...\n",
      "> initializing model parallel with size 1\n",
      "Added key: store_based_barrier_key:2 to store for rank: 0\n",
      "Added key: store_based_barrier_key:3 to store for rank: 0\n",
      "> setting random seeds to 1234 ...\n",
      "> initializing model parallel cuda seeds on global rank 0, model parallel rank 0, and data parallel rank 0 with model parallel seed: 3952 and data parallel seed: 1234\n",
      "[NeMo I 2022-04-27 07:35:48 modelPT:627] No optimizer config provided, therefore no optimizer was created\n",
      "\n",
      "    | Name                                                                         | Type                     | Params\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "0   | bert_model                                                                   | MegatronBertEncoder      | 334 M \n",
      "1   | bert_model.language_model                                                    | TransformerLanguageModel | 334 M \n",
      "2   | bert_model.language_model.embedding                                          | Embedding                | 31.9 M\n",
      "3   | bert_model.language_model.embedding.word_embeddings                          | VocabParallelEmbedding   | 31.3 M\n",
      "4   | bert_model.language_model.embedding.position_embeddings                      | Embedding                | 524 K \n",
      "5   | bert_model.language_model.embedding.tokentype_embeddings                     | Embedding                | 2.0 K \n",
      "6   | bert_model.language_model.embedding.embedding_dropout                        | Dropout                  | 0     \n",
      "7   | bert_model.language_model.transformer                                        | ParallelTransformer      | 302 M \n",
      "8   | bert_model.language_model.transformer.layers                                 | ModuleList               | 302 M \n",
      "9   | bert_model.language_model.transformer.layers.0                               | ParallelTransformerLayer | 12.6 M\n",
      "10  | bert_model.language_model.transformer.layers.0.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "11  | bert_model.language_model.transformer.layers.0.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "12  | bert_model.language_model.transformer.layers.0.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "13  | bert_model.language_model.transformer.layers.0.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "14  | bert_model.language_model.transformer.layers.0.attention.attention_dropout   | Dropout                  | 0     \n",
      "15  | bert_model.language_model.transformer.layers.0.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "16  | bert_model.language_model.transformer.layers.0.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "17  | bert_model.language_model.transformer.layers.0.mlp                           | ParallelMLP              | 8.4 M \n",
      "18  | bert_model.language_model.transformer.layers.0.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "19  | bert_model.language_model.transformer.layers.0.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "20  | bert_model.language_model.transformer.layers.1                               | ParallelTransformerLayer | 12.6 M\n",
      "21  | bert_model.language_model.transformer.layers.1.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "22  | bert_model.language_model.transformer.layers.1.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "23  | bert_model.language_model.transformer.layers.1.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "24  | bert_model.language_model.transformer.layers.1.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "25  | bert_model.language_model.transformer.layers.1.attention.attention_dropout   | Dropout                  | 0     \n",
      "26  | bert_model.language_model.transformer.layers.1.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "27  | bert_model.language_model.transformer.layers.1.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "28  | bert_model.language_model.transformer.layers.1.mlp                           | ParallelMLP              | 8.4 M \n",
      "29  | bert_model.language_model.transformer.layers.1.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "30  | bert_model.language_model.transformer.layers.1.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "31  | bert_model.language_model.transformer.layers.2                               | ParallelTransformerLayer | 12.6 M\n",
      "32  | bert_model.language_model.transformer.layers.2.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "33  | bert_model.language_model.transformer.layers.2.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "34  | bert_model.language_model.transformer.layers.2.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "35  | bert_model.language_model.transformer.layers.2.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "36  | bert_model.language_model.transformer.layers.2.attention.attention_dropout   | Dropout                  | 0     \n",
      "37  | bert_model.language_model.transformer.layers.2.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "38  | bert_model.language_model.transformer.layers.2.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "39  | bert_model.language_model.transformer.layers.2.mlp                           | ParallelMLP              | 8.4 M \n",
      "40  | bert_model.language_model.transformer.layers.2.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "41  | bert_model.language_model.transformer.layers.2.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "42  | bert_model.language_model.transformer.layers.3                               | ParallelTransformerLayer | 12.6 M\n",
      "43  | bert_model.language_model.transformer.layers.3.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "44  | bert_model.language_model.transformer.layers.3.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "45  | bert_model.language_model.transformer.layers.3.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "46  | bert_model.language_model.transformer.layers.3.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "47  | bert_model.language_model.transformer.layers.3.attention.attention_dropout   | Dropout                  | 0     \n",
      "48  | bert_model.language_model.transformer.layers.3.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "49  | bert_model.language_model.transformer.layers.3.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "50  | bert_model.language_model.transformer.layers.3.mlp                           | ParallelMLP              | 8.4 M \n",
      "51  | bert_model.language_model.transformer.layers.3.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "52  | bert_model.language_model.transformer.layers.3.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "53  | bert_model.language_model.transformer.layers.4                               | ParallelTransformerLayer | 12.6 M\n",
      "54  | bert_model.language_model.transformer.layers.4.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "55  | bert_model.language_model.transformer.layers.4.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "56  | bert_model.language_model.transformer.layers.4.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "57  | bert_model.language_model.transformer.layers.4.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "58  | bert_model.language_model.transformer.layers.4.attention.attention_dropout   | Dropout                  | 0     \n",
      "59  | bert_model.language_model.transformer.layers.4.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "60  | bert_model.language_model.transformer.layers.4.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "61  | bert_model.language_model.transformer.layers.4.mlp                           | ParallelMLP              | 8.4 M \n",
      "62  | bert_model.language_model.transformer.layers.4.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "63  | bert_model.language_model.transformer.layers.4.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "64  | bert_model.language_model.transformer.layers.5                               | ParallelTransformerLayer | 12.6 M\n",
      "65  | bert_model.language_model.transformer.layers.5.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "66  | bert_model.language_model.transformer.layers.5.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "67  | bert_model.language_model.transformer.layers.5.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "68  | bert_model.language_model.transformer.layers.5.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "69  | bert_model.language_model.transformer.layers.5.attention.attention_dropout   | Dropout                  | 0     \n",
      "70  | bert_model.language_model.transformer.layers.5.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "71  | bert_model.language_model.transformer.layers.5.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "72  | bert_model.language_model.transformer.layers.5.mlp                           | ParallelMLP              | 8.4 M \n",
      "73  | bert_model.language_model.transformer.layers.5.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "74  | bert_model.language_model.transformer.layers.5.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "75  | bert_model.language_model.transformer.layers.6                               | ParallelTransformerLayer | 12.6 M\n",
      "76  | bert_model.language_model.transformer.layers.6.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "77  | bert_model.language_model.transformer.layers.6.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "78  | bert_model.language_model.transformer.layers.6.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "79  | bert_model.language_model.transformer.layers.6.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "80  | bert_model.language_model.transformer.layers.6.attention.attention_dropout   | Dropout                  | 0     \n",
      "81  | bert_model.language_model.transformer.layers.6.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "82  | bert_model.language_model.transformer.layers.6.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "83  | bert_model.language_model.transformer.layers.6.mlp                           | ParallelMLP              | 8.4 M \n",
      "84  | bert_model.language_model.transformer.layers.6.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "85  | bert_model.language_model.transformer.layers.6.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "86  | bert_model.language_model.transformer.layers.7                               | ParallelTransformerLayer | 12.6 M\n",
      "87  | bert_model.language_model.transformer.layers.7.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "88  | bert_model.language_model.transformer.layers.7.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "89  | bert_model.language_model.transformer.layers.7.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "90  | bert_model.language_model.transformer.layers.7.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "91  | bert_model.language_model.transformer.layers.7.attention.attention_dropout   | Dropout                  | 0     \n",
      "92  | bert_model.language_model.transformer.layers.7.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "93  | bert_model.language_model.transformer.layers.7.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "94  | bert_model.language_model.transformer.layers.7.mlp                           | ParallelMLP              | 8.4 M \n",
      "95  | bert_model.language_model.transformer.layers.7.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "96  | bert_model.language_model.transformer.layers.7.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "97  | bert_model.language_model.transformer.layers.8                               | ParallelTransformerLayer | 12.6 M\n",
      "98  | bert_model.language_model.transformer.layers.8.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "99  | bert_model.language_model.transformer.layers.8.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "100 | bert_model.language_model.transformer.layers.8.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "101 | bert_model.language_model.transformer.layers.8.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "102 | bert_model.language_model.transformer.layers.8.attention.attention_dropout   | Dropout                  | 0     \n",
      "103 | bert_model.language_model.transformer.layers.8.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "104 | bert_model.language_model.transformer.layers.8.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "105 | bert_model.language_model.transformer.layers.8.mlp                           | ParallelMLP              | 8.4 M \n",
      "106 | bert_model.language_model.transformer.layers.8.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "107 | bert_model.language_model.transformer.layers.8.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "108 | bert_model.language_model.transformer.layers.9                               | ParallelTransformerLayer | 12.6 M\n",
      "109 | bert_model.language_model.transformer.layers.9.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "110 | bert_model.language_model.transformer.layers.9.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "111 | bert_model.language_model.transformer.layers.9.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "112 | bert_model.language_model.transformer.layers.9.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "113 | bert_model.language_model.transformer.layers.9.attention.attention_dropout   | Dropout                  | 0     \n",
      "114 | bert_model.language_model.transformer.layers.9.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "115 | bert_model.language_model.transformer.layers.9.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "116 | bert_model.language_model.transformer.layers.9.mlp                           | ParallelMLP              | 8.4 M \n",
      "117 | bert_model.language_model.transformer.layers.9.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "118 | bert_model.language_model.transformer.layers.9.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "119 | bert_model.language_model.transformer.layers.10                              | ParallelTransformerLayer | 12.6 M\n",
      "120 | bert_model.language_model.transformer.layers.10.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "121 | bert_model.language_model.transformer.layers.10.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "122 | bert_model.language_model.transformer.layers.10.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "123 | bert_model.language_model.transformer.layers.10.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "124 | bert_model.language_model.transformer.layers.10.attention.attention_dropout  | Dropout                  | 0     \n",
      "125 | bert_model.language_model.transformer.layers.10.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "126 | bert_model.language_model.transformer.layers.10.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "127 | bert_model.language_model.transformer.layers.10.mlp                          | ParallelMLP              | 8.4 M \n",
      "128 | bert_model.language_model.transformer.layers.10.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "129 | bert_model.language_model.transformer.layers.10.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "130 | bert_model.language_model.transformer.layers.11                              | ParallelTransformerLayer | 12.6 M\n",
      "131 | bert_model.language_model.transformer.layers.11.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "132 | bert_model.language_model.transformer.layers.11.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "133 | bert_model.language_model.transformer.layers.11.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "134 | bert_model.language_model.transformer.layers.11.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "135 | bert_model.language_model.transformer.layers.11.attention.attention_dropout  | Dropout                  | 0     \n",
      "136 | bert_model.language_model.transformer.layers.11.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "137 | bert_model.language_model.transformer.layers.11.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "138 | bert_model.language_model.transformer.layers.11.mlp                          | ParallelMLP              | 8.4 M \n",
      "139 | bert_model.language_model.transformer.layers.11.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "140 | bert_model.language_model.transformer.layers.11.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "141 | bert_model.language_model.transformer.layers.12                              | ParallelTransformerLayer | 12.6 M\n",
      "142 | bert_model.language_model.transformer.layers.12.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "143 | bert_model.language_model.transformer.layers.12.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "144 | bert_model.language_model.transformer.layers.12.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "145 | bert_model.language_model.transformer.layers.12.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "146 | bert_model.language_model.transformer.layers.12.attention.attention_dropout  | Dropout                  | 0     \n",
      "147 | bert_model.language_model.transformer.layers.12.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "148 | bert_model.language_model.transformer.layers.12.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "149 | bert_model.language_model.transformer.layers.12.mlp                          | ParallelMLP              | 8.4 M \n",
      "150 | bert_model.language_model.transformer.layers.12.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "151 | bert_model.language_model.transformer.layers.12.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "152 | bert_model.language_model.transformer.layers.13                              | ParallelTransformerLayer | 12.6 M\n",
      "153 | bert_model.language_model.transformer.layers.13.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "154 | bert_model.language_model.transformer.layers.13.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "155 | bert_model.language_model.transformer.layers.13.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "156 | bert_model.language_model.transformer.layers.13.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "157 | bert_model.language_model.transformer.layers.13.attention.attention_dropout  | Dropout                  | 0     \n",
      "158 | bert_model.language_model.transformer.layers.13.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "159 | bert_model.language_model.transformer.layers.13.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "160 | bert_model.language_model.transformer.layers.13.mlp                          | ParallelMLP              | 8.4 M \n",
      "161 | bert_model.language_model.transformer.layers.13.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "162 | bert_model.language_model.transformer.layers.13.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "163 | bert_model.language_model.transformer.layers.14                              | ParallelTransformerLayer | 12.6 M\n",
      "164 | bert_model.language_model.transformer.layers.14.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "165 | bert_model.language_model.transformer.layers.14.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "166 | bert_model.language_model.transformer.layers.14.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "167 | bert_model.language_model.transformer.layers.14.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "168 | bert_model.language_model.transformer.layers.14.attention.attention_dropout  | Dropout                  | 0     \n",
      "169 | bert_model.language_model.transformer.layers.14.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "170 | bert_model.language_model.transformer.layers.14.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "171 | bert_model.language_model.transformer.layers.14.mlp                          | ParallelMLP              | 8.4 M \n",
      "172 | bert_model.language_model.transformer.layers.14.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "173 | bert_model.language_model.transformer.layers.14.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "174 | bert_model.language_model.transformer.layers.15                              | ParallelTransformerLayer | 12.6 M\n",
      "175 | bert_model.language_model.transformer.layers.15.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "176 | bert_model.language_model.transformer.layers.15.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "177 | bert_model.language_model.transformer.layers.15.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "178 | bert_model.language_model.transformer.layers.15.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "179 | bert_model.language_model.transformer.layers.15.attention.attention_dropout  | Dropout                  | 0     \n",
      "180 | bert_model.language_model.transformer.layers.15.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "181 | bert_model.language_model.transformer.layers.15.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "182 | bert_model.language_model.transformer.layers.15.mlp                          | ParallelMLP              | 8.4 M \n",
      "183 | bert_model.language_model.transformer.layers.15.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "184 | bert_model.language_model.transformer.layers.15.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "185 | bert_model.language_model.transformer.layers.16                              | ParallelTransformerLayer | 12.6 M\n",
      "186 | bert_model.language_model.transformer.layers.16.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "187 | bert_model.language_model.transformer.layers.16.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "188 | bert_model.language_model.transformer.layers.16.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "189 | bert_model.language_model.transformer.layers.16.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "190 | bert_model.language_model.transformer.layers.16.attention.attention_dropout  | Dropout                  | 0     \n",
      "191 | bert_model.language_model.transformer.layers.16.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "192 | bert_model.language_model.transformer.layers.16.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "193 | bert_model.language_model.transformer.layers.16.mlp                          | ParallelMLP              | 8.4 M \n",
      "194 | bert_model.language_model.transformer.layers.16.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "195 | bert_model.language_model.transformer.layers.16.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "196 | bert_model.language_model.transformer.layers.17                              | ParallelTransformerLayer | 12.6 M\n",
      "197 | bert_model.language_model.transformer.layers.17.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "198 | bert_model.language_model.transformer.layers.17.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "199 | bert_model.language_model.transformer.layers.17.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "200 | bert_model.language_model.transformer.layers.17.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "201 | bert_model.language_model.transformer.layers.17.attention.attention_dropout  | Dropout                  | 0     \n",
      "202 | bert_model.language_model.transformer.layers.17.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "203 | bert_model.language_model.transformer.layers.17.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "204 | bert_model.language_model.transformer.layers.17.mlp                          | ParallelMLP              | 8.4 M \n",
      "205 | bert_model.language_model.transformer.layers.17.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "206 | bert_model.language_model.transformer.layers.17.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "207 | bert_model.language_model.transformer.layers.18                              | ParallelTransformerLayer | 12.6 M\n",
      "208 | bert_model.language_model.transformer.layers.18.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "209 | bert_model.language_model.transformer.layers.18.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "210 | bert_model.language_model.transformer.layers.18.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "211 | bert_model.language_model.transformer.layers.18.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "212 | bert_model.language_model.transformer.layers.18.attention.attention_dropout  | Dropout                  | 0     \n",
      "213 | bert_model.language_model.transformer.layers.18.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "214 | bert_model.language_model.transformer.layers.18.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "215 | bert_model.language_model.transformer.layers.18.mlp                          | ParallelMLP              | 8.4 M \n",
      "216 | bert_model.language_model.transformer.layers.18.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "217 | bert_model.language_model.transformer.layers.18.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "218 | bert_model.language_model.transformer.layers.19                              | ParallelTransformerLayer | 12.6 M\n",
      "219 | bert_model.language_model.transformer.layers.19.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "220 | bert_model.language_model.transformer.layers.19.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "221 | bert_model.language_model.transformer.layers.19.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "222 | bert_model.language_model.transformer.layers.19.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "223 | bert_model.language_model.transformer.layers.19.attention.attention_dropout  | Dropout                  | 0     \n",
      "224 | bert_model.language_model.transformer.layers.19.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "225 | bert_model.language_model.transformer.layers.19.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "226 | bert_model.language_model.transformer.layers.19.mlp                          | ParallelMLP              | 8.4 M \n",
      "227 | bert_model.language_model.transformer.layers.19.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "228 | bert_model.language_model.transformer.layers.19.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "229 | bert_model.language_model.transformer.layers.20                              | ParallelTransformerLayer | 12.6 M\n",
      "230 | bert_model.language_model.transformer.layers.20.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "231 | bert_model.language_model.transformer.layers.20.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "232 | bert_model.language_model.transformer.layers.20.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "233 | bert_model.language_model.transformer.layers.20.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "234 | bert_model.language_model.transformer.layers.20.attention.attention_dropout  | Dropout                  | 0     \n",
      "235 | bert_model.language_model.transformer.layers.20.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "236 | bert_model.language_model.transformer.layers.20.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "237 | bert_model.language_model.transformer.layers.20.mlp                          | ParallelMLP              | 8.4 M \n",
      "238 | bert_model.language_model.transformer.layers.20.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "239 | bert_model.language_model.transformer.layers.20.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "240 | bert_model.language_model.transformer.layers.21                              | ParallelTransformerLayer | 12.6 M\n",
      "241 | bert_model.language_model.transformer.layers.21.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "242 | bert_model.language_model.transformer.layers.21.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "243 | bert_model.language_model.transformer.layers.21.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "244 | bert_model.language_model.transformer.layers.21.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "245 | bert_model.language_model.transformer.layers.21.attention.attention_dropout  | Dropout                  | 0     \n",
      "246 | bert_model.language_model.transformer.layers.21.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "247 | bert_model.language_model.transformer.layers.21.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "248 | bert_model.language_model.transformer.layers.21.mlp                          | ParallelMLP              | 8.4 M \n",
      "249 | bert_model.language_model.transformer.layers.21.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "250 | bert_model.language_model.transformer.layers.21.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "251 | bert_model.language_model.transformer.layers.22                              | ParallelTransformerLayer | 12.6 M\n",
      "252 | bert_model.language_model.transformer.layers.22.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "253 | bert_model.language_model.transformer.layers.22.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "254 | bert_model.language_model.transformer.layers.22.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "255 | bert_model.language_model.transformer.layers.22.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "256 | bert_model.language_model.transformer.layers.22.attention.attention_dropout  | Dropout                  | 0     \n",
      "257 | bert_model.language_model.transformer.layers.22.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "258 | bert_model.language_model.transformer.layers.22.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "259 | bert_model.language_model.transformer.layers.22.mlp                          | ParallelMLP              | 8.4 M \n",
      "260 | bert_model.language_model.transformer.layers.22.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "261 | bert_model.language_model.transformer.layers.22.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "262 | bert_model.language_model.transformer.layers.23                              | ParallelTransformerLayer | 12.6 M\n",
      "263 | bert_model.language_model.transformer.layers.23.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "264 | bert_model.language_model.transformer.layers.23.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "265 | bert_model.language_model.transformer.layers.23.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "266 | bert_model.language_model.transformer.layers.23.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "267 | bert_model.language_model.transformer.layers.23.attention.attention_dropout  | Dropout                  | 0     \n",
      "268 | bert_model.language_model.transformer.layers.23.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "269 | bert_model.language_model.transformer.layers.23.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "270 | bert_model.language_model.transformer.layers.23.mlp                          | ParallelMLP              | 8.4 M \n",
      "271 | bert_model.language_model.transformer.layers.23.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "272 | bert_model.language_model.transformer.layers.23.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "273 | bert_model.language_model.transformer.final_layernorm                        | FusedLayerNorm           | 2.0 K \n",
      "274 | classifier                                                                   | TokenClassifier          | 1.1 M \n",
      "275 | classifier.dropout                                                           | Dropout                  | 0     \n",
      "276 | classifier.mlp                                                               | MultiLayerPerceptron     | 1.1 M \n",
      "277 | classifier.mlp.layer0                                                        | Linear                   | 1.0 M \n",
      "278 | classifier.mlp.layer2                                                        | Linear                   | 17.4 K\n",
      "279 | loss                                                                         | CrossEntropyLoss         | 0     \n",
      "280 | classification_report                                                        | ClassificationReport     | 0     \n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "335 M     Trainable params\n",
      "0         Non-trainable params\n",
      "335 M     Total params\n",
      "\n",
      "    | Name                                                                         | Type                     | Params\n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "0   | bert_model                                                                   | MegatronBertEncoder      | 334 M \n",
      "1   | bert_model.language_model                                                    | TransformerLanguageModel | 334 M \n",
      "2   | bert_model.language_model.embedding                                          | Embedding                | 31.9 M\n",
      "3   | bert_model.language_model.embedding.word_embeddings                          | VocabParallelEmbedding   | 31.3 M\n",
      "4   | bert_model.language_model.embedding.position_embeddings                      | Embedding                | 524 K \n",
      "5   | bert_model.language_model.embedding.tokentype_embeddings                     | Embedding                | 2.0 K \n",
      "6   | bert_model.language_model.embedding.embedding_dropout                        | Dropout                  | 0     \n",
      "7   | bert_model.language_model.transformer                                        | ParallelTransformer      | 302 M \n",
      "8   | bert_model.language_model.transformer.layers                                 | ModuleList               | 302 M \n",
      "9   | bert_model.language_model.transformer.layers.0                               | ParallelTransformerLayer | 12.6 M\n",
      "10  | bert_model.language_model.transformer.layers.0.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "11  | bert_model.language_model.transformer.layers.0.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "12  | bert_model.language_model.transformer.layers.0.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "13  | bert_model.language_model.transformer.layers.0.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "14  | bert_model.language_model.transformer.layers.0.attention.attention_dropout   | Dropout                  | 0     \n",
      "15  | bert_model.language_model.transformer.layers.0.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "16  | bert_model.language_model.transformer.layers.0.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "17  | bert_model.language_model.transformer.layers.0.mlp                           | ParallelMLP              | 8.4 M \n",
      "18  | bert_model.language_model.transformer.layers.0.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "19  | bert_model.language_model.transformer.layers.0.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "20  | bert_model.language_model.transformer.layers.1                               | ParallelTransformerLayer | 12.6 M\n",
      "21  | bert_model.language_model.transformer.layers.1.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "22  | bert_model.language_model.transformer.layers.1.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "23  | bert_model.language_model.transformer.layers.1.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "24  | bert_model.language_model.transformer.layers.1.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "25  | bert_model.language_model.transformer.layers.1.attention.attention_dropout   | Dropout                  | 0     \n",
      "26  | bert_model.language_model.transformer.layers.1.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "27  | bert_model.language_model.transformer.layers.1.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "28  | bert_model.language_model.transformer.layers.1.mlp                           | ParallelMLP              | 8.4 M \n",
      "29  | bert_model.language_model.transformer.layers.1.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "30  | bert_model.language_model.transformer.layers.1.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "31  | bert_model.language_model.transformer.layers.2                               | ParallelTransformerLayer | 12.6 M\n",
      "32  | bert_model.language_model.transformer.layers.2.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "33  | bert_model.language_model.transformer.layers.2.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "34  | bert_model.language_model.transformer.layers.2.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "35  | bert_model.language_model.transformer.layers.2.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "36  | bert_model.language_model.transformer.layers.2.attention.attention_dropout   | Dropout                  | 0     \n",
      "37  | bert_model.language_model.transformer.layers.2.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "38  | bert_model.language_model.transformer.layers.2.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "39  | bert_model.language_model.transformer.layers.2.mlp                           | ParallelMLP              | 8.4 M \n",
      "40  | bert_model.language_model.transformer.layers.2.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "41  | bert_model.language_model.transformer.layers.2.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "42  | bert_model.language_model.transformer.layers.3                               | ParallelTransformerLayer | 12.6 M\n",
      "43  | bert_model.language_model.transformer.layers.3.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "44  | bert_model.language_model.transformer.layers.3.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "45  | bert_model.language_model.transformer.layers.3.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "46  | bert_model.language_model.transformer.layers.3.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "47  | bert_model.language_model.transformer.layers.3.attention.attention_dropout   | Dropout                  | 0     \n",
      "48  | bert_model.language_model.transformer.layers.3.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "49  | bert_model.language_model.transformer.layers.3.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "50  | bert_model.language_model.transformer.layers.3.mlp                           | ParallelMLP              | 8.4 M \n",
      "51  | bert_model.language_model.transformer.layers.3.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "52  | bert_model.language_model.transformer.layers.3.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "53  | bert_model.language_model.transformer.layers.4                               | ParallelTransformerLayer | 12.6 M\n",
      "54  | bert_model.language_model.transformer.layers.4.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "55  | bert_model.language_model.transformer.layers.4.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "56  | bert_model.language_model.transformer.layers.4.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "57  | bert_model.language_model.transformer.layers.4.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "58  | bert_model.language_model.transformer.layers.4.attention.attention_dropout   | Dropout                  | 0     \n",
      "59  | bert_model.language_model.transformer.layers.4.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "60  | bert_model.language_model.transformer.layers.4.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "61  | bert_model.language_model.transformer.layers.4.mlp                           | ParallelMLP              | 8.4 M \n",
      "62  | bert_model.language_model.transformer.layers.4.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "63  | bert_model.language_model.transformer.layers.4.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "64  | bert_model.language_model.transformer.layers.5                               | ParallelTransformerLayer | 12.6 M\n",
      "65  | bert_model.language_model.transformer.layers.5.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "66  | bert_model.language_model.transformer.layers.5.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "67  | bert_model.language_model.transformer.layers.5.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "68  | bert_model.language_model.transformer.layers.5.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "69  | bert_model.language_model.transformer.layers.5.attention.attention_dropout   | Dropout                  | 0     \n",
      "70  | bert_model.language_model.transformer.layers.5.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "71  | bert_model.language_model.transformer.layers.5.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "72  | bert_model.language_model.transformer.layers.5.mlp                           | ParallelMLP              | 8.4 M \n",
      "73  | bert_model.language_model.transformer.layers.5.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "74  | bert_model.language_model.transformer.layers.5.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "75  | bert_model.language_model.transformer.layers.6                               | ParallelTransformerLayer | 12.6 M\n",
      "76  | bert_model.language_model.transformer.layers.6.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "77  | bert_model.language_model.transformer.layers.6.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "78  | bert_model.language_model.transformer.layers.6.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "79  | bert_model.language_model.transformer.layers.6.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "80  | bert_model.language_model.transformer.layers.6.attention.attention_dropout   | Dropout                  | 0     \n",
      "81  | bert_model.language_model.transformer.layers.6.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "82  | bert_model.language_model.transformer.layers.6.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "83  | bert_model.language_model.transformer.layers.6.mlp                           | ParallelMLP              | 8.4 M \n",
      "84  | bert_model.language_model.transformer.layers.6.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "85  | bert_model.language_model.transformer.layers.6.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "86  | bert_model.language_model.transformer.layers.7                               | ParallelTransformerLayer | 12.6 M\n",
      "87  | bert_model.language_model.transformer.layers.7.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "88  | bert_model.language_model.transformer.layers.7.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "89  | bert_model.language_model.transformer.layers.7.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "90  | bert_model.language_model.transformer.layers.7.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "91  | bert_model.language_model.transformer.layers.7.attention.attention_dropout   | Dropout                  | 0     \n",
      "92  | bert_model.language_model.transformer.layers.7.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "93  | bert_model.language_model.transformer.layers.7.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "94  | bert_model.language_model.transformer.layers.7.mlp                           | ParallelMLP              | 8.4 M \n",
      "95  | bert_model.language_model.transformer.layers.7.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "96  | bert_model.language_model.transformer.layers.7.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "97  | bert_model.language_model.transformer.layers.8                               | ParallelTransformerLayer | 12.6 M\n",
      "98  | bert_model.language_model.transformer.layers.8.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "99  | bert_model.language_model.transformer.layers.8.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "100 | bert_model.language_model.transformer.layers.8.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "101 | bert_model.language_model.transformer.layers.8.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "102 | bert_model.language_model.transformer.layers.8.attention.attention_dropout   | Dropout                  | 0     \n",
      "103 | bert_model.language_model.transformer.layers.8.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "104 | bert_model.language_model.transformer.layers.8.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "105 | bert_model.language_model.transformer.layers.8.mlp                           | ParallelMLP              | 8.4 M \n",
      "106 | bert_model.language_model.transformer.layers.8.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "107 | bert_model.language_model.transformer.layers.8.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "108 | bert_model.language_model.transformer.layers.9                               | ParallelTransformerLayer | 12.6 M\n",
      "109 | bert_model.language_model.transformer.layers.9.input_layernorm               | FusedLayerNorm           | 2.0 K \n",
      "110 | bert_model.language_model.transformer.layers.9.attention                     | ParallelSelfAttention    | 4.2 M \n",
      "111 | bert_model.language_model.transformer.layers.9.attention.query_key_value     | ColumnParallelLinear     | 3.1 M \n",
      "112 | bert_model.language_model.transformer.layers.9.attention.scale_mask_softmax  | FusedScaleMaskSoftmax    | 0     \n",
      "113 | bert_model.language_model.transformer.layers.9.attention.attention_dropout   | Dropout                  | 0     \n",
      "114 | bert_model.language_model.transformer.layers.9.attention.dense               | RowParallelLinear        | 1.0 M \n",
      "115 | bert_model.language_model.transformer.layers.9.post_attention_layernorm      | FusedLayerNorm           | 2.0 K \n",
      "116 | bert_model.language_model.transformer.layers.9.mlp                           | ParallelMLP              | 8.4 M \n",
      "117 | bert_model.language_model.transformer.layers.9.mlp.dense_h_to_4h             | ColumnParallelLinear     | 4.2 M \n",
      "118 | bert_model.language_model.transformer.layers.9.mlp.dense_4h_to_h             | RowParallelLinear        | 4.2 M \n",
      "119 | bert_model.language_model.transformer.layers.10                              | ParallelTransformerLayer | 12.6 M\n",
      "120 | bert_model.language_model.transformer.layers.10.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "121 | bert_model.language_model.transformer.layers.10.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "122 | bert_model.language_model.transformer.layers.10.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "123 | bert_model.language_model.transformer.layers.10.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "124 | bert_model.language_model.transformer.layers.10.attention.attention_dropout  | Dropout                  | 0     \n",
      "125 | bert_model.language_model.transformer.layers.10.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "126 | bert_model.language_model.transformer.layers.10.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "127 | bert_model.language_model.transformer.layers.10.mlp                          | ParallelMLP              | 8.4 M \n",
      "128 | bert_model.language_model.transformer.layers.10.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "129 | bert_model.language_model.transformer.layers.10.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "130 | bert_model.language_model.transformer.layers.11                              | ParallelTransformerLayer | 12.6 M\n",
      "131 | bert_model.language_model.transformer.layers.11.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "132 | bert_model.language_model.transformer.layers.11.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "133 | bert_model.language_model.transformer.layers.11.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "134 | bert_model.language_model.transformer.layers.11.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "135 | bert_model.language_model.transformer.layers.11.attention.attention_dropout  | Dropout                  | 0     \n",
      "136 | bert_model.language_model.transformer.layers.11.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "137 | bert_model.language_model.transformer.layers.11.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "138 | bert_model.language_model.transformer.layers.11.mlp                          | ParallelMLP              | 8.4 M \n",
      "139 | bert_model.language_model.transformer.layers.11.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "140 | bert_model.language_model.transformer.layers.11.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "141 | bert_model.language_model.transformer.layers.12                              | ParallelTransformerLayer | 12.6 M\n",
      "142 | bert_model.language_model.transformer.layers.12.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "143 | bert_model.language_model.transformer.layers.12.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "144 | bert_model.language_model.transformer.layers.12.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "145 | bert_model.language_model.transformer.layers.12.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "146 | bert_model.language_model.transformer.layers.12.attention.attention_dropout  | Dropout                  | 0     \n",
      "147 | bert_model.language_model.transformer.layers.12.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "148 | bert_model.language_model.transformer.layers.12.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "149 | bert_model.language_model.transformer.layers.12.mlp                          | ParallelMLP              | 8.4 M \n",
      "150 | bert_model.language_model.transformer.layers.12.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "151 | bert_model.language_model.transformer.layers.12.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "152 | bert_model.language_model.transformer.layers.13                              | ParallelTransformerLayer | 12.6 M\n",
      "153 | bert_model.language_model.transformer.layers.13.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "154 | bert_model.language_model.transformer.layers.13.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "155 | bert_model.language_model.transformer.layers.13.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "156 | bert_model.language_model.transformer.layers.13.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "157 | bert_model.language_model.transformer.layers.13.attention.attention_dropout  | Dropout                  | 0     \n",
      "158 | bert_model.language_model.transformer.layers.13.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "159 | bert_model.language_model.transformer.layers.13.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "160 | bert_model.language_model.transformer.layers.13.mlp                          | ParallelMLP              | 8.4 M \n",
      "161 | bert_model.language_model.transformer.layers.13.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "162 | bert_model.language_model.transformer.layers.13.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "163 | bert_model.language_model.transformer.layers.14                              | ParallelTransformerLayer | 12.6 M\n",
      "164 | bert_model.language_model.transformer.layers.14.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "165 | bert_model.language_model.transformer.layers.14.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "166 | bert_model.language_model.transformer.layers.14.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "167 | bert_model.language_model.transformer.layers.14.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "168 | bert_model.language_model.transformer.layers.14.attention.attention_dropout  | Dropout                  | 0     \n",
      "169 | bert_model.language_model.transformer.layers.14.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "170 | bert_model.language_model.transformer.layers.14.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "171 | bert_model.language_model.transformer.layers.14.mlp                          | ParallelMLP              | 8.4 M \n",
      "172 | bert_model.language_model.transformer.layers.14.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "173 | bert_model.language_model.transformer.layers.14.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "174 | bert_model.language_model.transformer.layers.15                              | ParallelTransformerLayer | 12.6 M\n",
      "175 | bert_model.language_model.transformer.layers.15.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "176 | bert_model.language_model.transformer.layers.15.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "177 | bert_model.language_model.transformer.layers.15.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "178 | bert_model.language_model.transformer.layers.15.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "179 | bert_model.language_model.transformer.layers.15.attention.attention_dropout  | Dropout                  | 0     \n",
      "180 | bert_model.language_model.transformer.layers.15.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "181 | bert_model.language_model.transformer.layers.15.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "182 | bert_model.language_model.transformer.layers.15.mlp                          | ParallelMLP              | 8.4 M \n",
      "183 | bert_model.language_model.transformer.layers.15.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "184 | bert_model.language_model.transformer.layers.15.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "185 | bert_model.language_model.transformer.layers.16                              | ParallelTransformerLayer | 12.6 M\n",
      "186 | bert_model.language_model.transformer.layers.16.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "187 | bert_model.language_model.transformer.layers.16.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "188 | bert_model.language_model.transformer.layers.16.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "189 | bert_model.language_model.transformer.layers.16.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "190 | bert_model.language_model.transformer.layers.16.attention.attention_dropout  | Dropout                  | 0     \n",
      "191 | bert_model.language_model.transformer.layers.16.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "192 | bert_model.language_model.transformer.layers.16.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "193 | bert_model.language_model.transformer.layers.16.mlp                          | ParallelMLP              | 8.4 M \n",
      "194 | bert_model.language_model.transformer.layers.16.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "195 | bert_model.language_model.transformer.layers.16.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "196 | bert_model.language_model.transformer.layers.17                              | ParallelTransformerLayer | 12.6 M\n",
      "197 | bert_model.language_model.transformer.layers.17.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "198 | bert_model.language_model.transformer.layers.17.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "199 | bert_model.language_model.transformer.layers.17.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "200 | bert_model.language_model.transformer.layers.17.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "201 | bert_model.language_model.transformer.layers.17.attention.attention_dropout  | Dropout                  | 0     \n",
      "202 | bert_model.language_model.transformer.layers.17.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "203 | bert_model.language_model.transformer.layers.17.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "204 | bert_model.language_model.transformer.layers.17.mlp                          | ParallelMLP              | 8.4 M \n",
      "205 | bert_model.language_model.transformer.layers.17.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "206 | bert_model.language_model.transformer.layers.17.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "207 | bert_model.language_model.transformer.layers.18                              | ParallelTransformerLayer | 12.6 M\n",
      "208 | bert_model.language_model.transformer.layers.18.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "209 | bert_model.language_model.transformer.layers.18.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "210 | bert_model.language_model.transformer.layers.18.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "211 | bert_model.language_model.transformer.layers.18.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "212 | bert_model.language_model.transformer.layers.18.attention.attention_dropout  | Dropout                  | 0     \n",
      "213 | bert_model.language_model.transformer.layers.18.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "214 | bert_model.language_model.transformer.layers.18.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "215 | bert_model.language_model.transformer.layers.18.mlp                          | ParallelMLP              | 8.4 M \n",
      "216 | bert_model.language_model.transformer.layers.18.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "217 | bert_model.language_model.transformer.layers.18.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "218 | bert_model.language_model.transformer.layers.19                              | ParallelTransformerLayer | 12.6 M\n",
      "219 | bert_model.language_model.transformer.layers.19.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "220 | bert_model.language_model.transformer.layers.19.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "221 | bert_model.language_model.transformer.layers.19.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "222 | bert_model.language_model.transformer.layers.19.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "223 | bert_model.language_model.transformer.layers.19.attention.attention_dropout  | Dropout                  | 0     \n",
      "224 | bert_model.language_model.transformer.layers.19.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "225 | bert_model.language_model.transformer.layers.19.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "226 | bert_model.language_model.transformer.layers.19.mlp                          | ParallelMLP              | 8.4 M \n",
      "227 | bert_model.language_model.transformer.layers.19.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "228 | bert_model.language_model.transformer.layers.19.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "229 | bert_model.language_model.transformer.layers.20                              | ParallelTransformerLayer | 12.6 M\n",
      "230 | bert_model.language_model.transformer.layers.20.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "231 | bert_model.language_model.transformer.layers.20.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "232 | bert_model.language_model.transformer.layers.20.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "233 | bert_model.language_model.transformer.layers.20.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "234 | bert_model.language_model.transformer.layers.20.attention.attention_dropout  | Dropout                  | 0     \n",
      "235 | bert_model.language_model.transformer.layers.20.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "236 | bert_model.language_model.transformer.layers.20.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "237 | bert_model.language_model.transformer.layers.20.mlp                          | ParallelMLP              | 8.4 M \n",
      "238 | bert_model.language_model.transformer.layers.20.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "239 | bert_model.language_model.transformer.layers.20.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "240 | bert_model.language_model.transformer.layers.21                              | ParallelTransformerLayer | 12.6 M\n",
      "241 | bert_model.language_model.transformer.layers.21.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "242 | bert_model.language_model.transformer.layers.21.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "243 | bert_model.language_model.transformer.layers.21.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "244 | bert_model.language_model.transformer.layers.21.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "245 | bert_model.language_model.transformer.layers.21.attention.attention_dropout  | Dropout                  | 0     \n",
      "246 | bert_model.language_model.transformer.layers.21.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "247 | bert_model.language_model.transformer.layers.21.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "248 | bert_model.language_model.transformer.layers.21.mlp                          | ParallelMLP              | 8.4 M \n",
      "249 | bert_model.language_model.transformer.layers.21.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "250 | bert_model.language_model.transformer.layers.21.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "251 | bert_model.language_model.transformer.layers.22                              | ParallelTransformerLayer | 12.6 M\n",
      "252 | bert_model.language_model.transformer.layers.22.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "253 | bert_model.language_model.transformer.layers.22.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "254 | bert_model.language_model.transformer.layers.22.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "255 | bert_model.language_model.transformer.layers.22.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "256 | bert_model.language_model.transformer.layers.22.attention.attention_dropout  | Dropout                  | 0     \n",
      "257 | bert_model.language_model.transformer.layers.22.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "258 | bert_model.language_model.transformer.layers.22.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "259 | bert_model.language_model.transformer.layers.22.mlp                          | ParallelMLP              | 8.4 M \n",
      "260 | bert_model.language_model.transformer.layers.22.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "261 | bert_model.language_model.transformer.layers.22.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "262 | bert_model.language_model.transformer.layers.23                              | ParallelTransformerLayer | 12.6 M\n",
      "263 | bert_model.language_model.transformer.layers.23.input_layernorm              | FusedLayerNorm           | 2.0 K \n",
      "264 | bert_model.language_model.transformer.layers.23.attention                    | ParallelSelfAttention    | 4.2 M \n",
      "265 | bert_model.language_model.transformer.layers.23.attention.query_key_value    | ColumnParallelLinear     | 3.1 M \n",
      "266 | bert_model.language_model.transformer.layers.23.attention.scale_mask_softmax | FusedScaleMaskSoftmax    | 0     \n",
      "267 | bert_model.language_model.transformer.layers.23.attention.attention_dropout  | Dropout                  | 0     \n",
      "268 | bert_model.language_model.transformer.layers.23.attention.dense              | RowParallelLinear        | 1.0 M \n",
      "269 | bert_model.language_model.transformer.layers.23.post_attention_layernorm     | FusedLayerNorm           | 2.0 K \n",
      "270 | bert_model.language_model.transformer.layers.23.mlp                          | ParallelMLP              | 8.4 M \n",
      "271 | bert_model.language_model.transformer.layers.23.mlp.dense_h_to_4h            | ColumnParallelLinear     | 4.2 M \n",
      "272 | bert_model.language_model.transformer.layers.23.mlp.dense_4h_to_h            | RowParallelLinear        | 4.2 M \n",
      "273 | bert_model.language_model.transformer.final_layernorm                        | FusedLayerNorm           | 2.0 K \n",
      "274 | classifier                                                                   | TokenClassifier          | 1.1 M \n",
      "275 | classifier.dropout                                                           | Dropout                  | 0     \n",
      "276 | classifier.mlp                                                               | MultiLayerPerceptron     | 1.1 M \n",
      "277 | classifier.mlp.layer0                                                        | Linear                   | 1.0 M \n",
      "278 | classifier.mlp.layer2                                                        | Linear                   | 17.4 K\n",
      "279 | loss                                                                         | CrossEntropyLoss         | 0     \n",
      "280 | classification_report                                                        | ClassificationReport     | 0     \n",
      "----------------------------------------------------------------------------------------------------------------------------\n",
      "335 M     Trainable params\n",
      "0         Non-trainable params\n",
      "335 M     Total params\n",
      "Validation sanity check: 100%|████████████████████| 2/2 [00:01<00:00,  1.15s/it][NeMo I 2022-04-27 07:35:50 token_classification_model:178] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         66.67       6.60      12.01        667\n",
      "    B-Amenity (label_id: 1)                                 16.67       2.04       3.64         49\n",
      "    B-Cuisine (label_id: 2)                                  2.42       9.26       3.83         54\n",
      "    B-Dish (label_id: 3)                                     0.00       0.00       0.00         23\n",
      "    B-Hours (label_id: 4)                                    0.00       0.00       0.00         19\n",
      "    B-Location (label_id: 5)                                 2.22       1.09       1.46         92\n",
      "    B-Price (label_id: 6)                                    2.10      50.00       4.03         12\n",
      "    B-Rating (label_id: 7)                                   5.00       6.67       5.71         15\n",
      "    B-Restaurant_Name (label_id: 8)                          0.00       0.00       0.00         14\n",
      "    I-Amenity (label_id: 9)                                  0.00       0.00       0.00         56\n",
      "    I-Cuisine (label_id: 10)                                 0.00       0.00       0.00         15\n",
      "    I-Dish (label_id: 11)                                   10.00      22.22      13.79          9\n",
      "    I-Hours (label_id: 12)                                   7.36      43.59      12.59         39\n",
      "    I-Location (label_id: 13)                                7.69       0.97       1.72        103\n",
      "    I-Price (label_id: 14)                                   0.00       0.00       0.00          6\n",
      "    I-Rating (label_id: 15)                                  0.00       0.00       0.00          6\n",
      "    I-Restaurant_Name (label_id: 16)                         1.01      10.53       1.84         19\n",
      "    -------------------\n",
      "    micro avg                                                6.68       6.68       6.68       1198\n",
      "    macro avg                                                7.13       9.00       3.57       1198\n",
      "    weighted avg                                            39.15       6.68       7.92       1198\n",
      "    \n",
      "Epoch 0:   0%|                                          | 0/144 [00:00<?, ?it/s][W reducer.cpp:1042] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters. This flag results in an extra traversal of the autograd graph every iteration, which can adversely affect performance. If your model indeed never has any unused parameters, consider turning this flag off. Note that this warning may be a false positive your model has flow control causing later iterations to have unused parameters. (function operator())\n",
      "Epoch 0:  83%|▊| 120/144 [01:23<00:16,  1.44it/s, loss=0.289, val_loss=2.8, lr=3\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  85%|▊| 122/144 [01:23<00:15,  1.46it/s, loss=0.289, val_loss=2.8, lr=3\u001b[A\n",
      "Validating:   8%|██▋                             | 2/24 [00:00<00:04,  4.54it/s]\u001b[A\n",
      "Epoch 0:  86%|▊| 124/144 [01:23<00:13,  1.48it/s, loss=0.289, val_loss=2.8, lr=3\u001b[A\n",
      "Validating:  17%|█████▎                          | 4/24 [00:00<00:03,  5.81it/s]\u001b[A\n",
      "Epoch 0:  88%|▉| 126/144 [01:24<00:12,  1.50it/s, loss=0.289, val_loss=2.8, lr=3\u001b[A\n",
      "Validating:  25%|████████                        | 6/24 [00:00<00:02,  6.80it/s]\u001b[A\n",
      "Epoch 0:  89%|▉| 128/144 [01:24<00:10,  1.52it/s, loss=0.289, val_loss=2.8, lr=3\u001b[A\n",
      "Validating:  33%|██████████▋                     | 8/24 [00:01<00:02,  7.39it/s]\u001b[A\n",
      "Epoch 0:  90%|▉| 130/144 [01:24<00:09,  1.53it/s, loss=0.289, val_loss=2.8, lr=3\u001b[A\n",
      "Validating:  42%|████████████▉                  | 10/24 [00:01<00:01,  7.72it/s]\u001b[A\n",
      "Epoch 0:  92%|▉| 132/144 [01:24<00:07,  1.55it/s, loss=0.289, val_loss=2.8, lr=3\u001b[A\n",
      "Validating:  50%|███████████████▌               | 12/24 [00:01<00:01,  7.87it/s]\u001b[A\n",
      "Epoch 0:  93%|▉| 134/144 [01:25<00:06,  1.57it/s, loss=0.289, val_loss=2.8, lr=3\u001b[A\n",
      "Validating:  58%|██████████████████             | 14/24 [00:01<00:01,  7.92it/s]\u001b[A\n",
      "Epoch 0:  94%|▉| 136/144 [01:25<00:05,  1.59it/s, loss=0.289, val_loss=2.8, lr=3\u001b[A\n",
      "Validating:  67%|████████████████████▋          | 16/24 [00:02<00:01,  7.96it/s]\u001b[A\n",
      "Epoch 0:  96%|▉| 138/144 [01:25<00:03,  1.61it/s, loss=0.289, val_loss=2.8, lr=3\u001b[A\n",
      "Validating:  75%|███████████████████████▎       | 18/24 [00:02<00:00,  8.04it/s]\u001b[A\n",
      "Epoch 0:  97%|▉| 140/144 [01:25<00:02,  1.63it/s, loss=0.289, val_loss=2.8, lr=3\u001b[A\n",
      "Validating:  83%|█████████████████████████▊     | 20/24 [00:02<00:00,  8.09it/s]\u001b[A\n",
      "Epoch 0:  99%|▉| 142/144 [01:26<00:01,  1.65it/s, loss=0.289, val_loss=2.8, lr=3\u001b[A\n",
      "Validating:  92%|████████████████████████████▍  | 22/24 [00:02<00:00,  8.02it/s]\u001b[A\n",
      "Epoch 0: 100%|█| 144/144 [01:26<00:00,  1.67it/s, loss=0.289, val_loss=2.8, lr=3\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 24/24 [00:03<00:00,  8.47it/s]\u001b[A[NeMo I 2022-04-27 07:37:17 token_classification_model:178] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         96.83      94.90      95.85       8659\n",
      "    B-Amenity (label_id: 1)                                 72.70      79.92      76.14        533\n",
      "    B-Cuisine (label_id: 2)                                 79.74      92.48      85.64        532\n",
      "    B-Dish (label_id: 3)                                    83.04      81.60      82.31        288\n",
      "    B-Hours (label_id: 4)                                   68.00      72.17      70.02        212\n",
      "    B-Location (label_id: 5)                                89.93      90.15      90.04        812\n",
      "    B-Price (label_id: 6)                                   82.61      88.89      85.63        171\n",
      "    B-Rating (label_id: 7)                                  79.24      93.03      85.58        201\n",
      "    B-Restaurant_Name (label_id: 8)                         95.48      89.30      92.29        402\n",
      "    I-Amenity (label_id: 9)                                 76.40      80.92      78.59        524\n",
      "    I-Cuisine (label_id: 10)                                75.96      58.52      66.11        135\n",
      "    I-Dish (label_id: 11)                                   81.65      73.55      77.39        121\n",
      "    I-Hours (label_id: 12)                                  81.33      91.53      86.12        295\n",
      "    I-Location (label_id: 13)                               86.99      91.62      89.25        788\n",
      "    I-Price (label_id: 14)                                  94.44      51.52      66.67         66\n",
      "    I-Rating (label_id: 15)                                 89.74      84.00      86.78        125\n",
      "    I-Restaurant_Name (label_id: 16)                        92.62      86.48      89.45        392\n",
      "    -------------------\n",
      "    micro avg                                               91.29      91.29      91.29      14256\n",
      "    macro avg                                               83.92      82.39      82.58      14256\n",
      "    weighted avg                                            91.60      91.29      91.35      14256\n",
      "    \n",
      "Epoch 0: 100%|█| 144/144 [01:26<00:00,  1.66it/s, loss=0.289, val_loss=0.254, lr\n",
      "Epoch 1:  83%|▊| 120/144 [01:24<00:16,  1.43it/s, loss=0.227, val_loss=0.254, lr\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  85%|▊| 122/144 [01:24<00:15,  1.45it/s, loss=0.227, val_loss=0.254, lr\u001b[A\n",
      "Validating:   8%|██▋                             | 2/24 [00:00<00:04,  4.51it/s]\u001b[A\n",
      "Epoch 1:  86%|▊| 124/144 [01:24<00:13,  1.47it/s, loss=0.227, val_loss=0.254, lr\u001b[A\n",
      "Validating:  17%|█████▎                          | 4/24 [00:00<00:03,  5.77it/s]\u001b[A\n",
      "Epoch 1:  88%|▉| 126/144 [01:24<00:12,  1.48it/s, loss=0.227, val_loss=0.254, lr\u001b[A\n",
      "Validating:  25%|████████                        | 6/24 [00:00<00:02,  6.68it/s]\u001b[A\n",
      "Epoch 1:  89%|▉| 128/144 [01:25<00:10,  1.50it/s, loss=0.227, val_loss=0.254, lr\u001b[A\n",
      "Validating:  33%|██████████▋                     | 8/24 [00:01<00:02,  7.23it/s]\u001b[A\n",
      "Epoch 1:  90%|▉| 130/144 [01:25<00:09,  1.52it/s, loss=0.227, val_loss=0.254, lr\u001b[A\n",
      "Validating:  42%|████████████▉                  | 10/24 [00:01<00:01,  7.52it/s]\u001b[A\n",
      "Epoch 1:  92%|▉| 132/144 [01:25<00:07,  1.54it/s, loss=0.227, val_loss=0.254, lr\u001b[A\n",
      "Validating:  50%|███████████████▌               | 12/24 [00:01<00:01,  7.70it/s]\u001b[A\n",
      "Epoch 1:  93%|▉| 134/144 [01:25<00:06,  1.56it/s, loss=0.227, val_loss=0.254, lr\u001b[A\n",
      "Validating:  58%|██████████████████             | 14/24 [00:01<00:01,  7.75it/s]\u001b[A\n",
      "Epoch 1:  94%|▉| 136/144 [01:26<00:05,  1.58it/s, loss=0.227, val_loss=0.254, lr\u001b[A\n",
      "Validating:  67%|████████████████████▋          | 16/24 [00:02<00:01,  7.80it/s]\u001b[A\n",
      "Epoch 1:  96%|▉| 138/144 [01:26<00:03,  1.60it/s, loss=0.227, val_loss=0.254, lr\u001b[A\n",
      "Validating:  75%|███████████████████████▎       | 18/24 [00:02<00:00,  7.89it/s]\u001b[A\n",
      "Epoch 1:  97%|▉| 140/144 [01:26<00:02,  1.62it/s, loss=0.227, val_loss=0.254, lr\u001b[A\n",
      "Validating:  83%|█████████████████████████▊     | 20/24 [00:02<00:00,  7.91it/s]\u001b[A\n",
      "Epoch 1:  99%|▉| 142/144 [01:26<00:01,  1.63it/s, loss=0.227, val_loss=0.254, lr\u001b[A\n",
      "Validating:  92%|████████████████████████████▍  | 22/24 [00:02<00:00,  7.91it/s]\u001b[A\n",
      "Epoch 1: 100%|█| 144/144 [01:27<00:00,  1.65it/s, loss=0.227, val_loss=0.254, lr\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 24/24 [00:03<00:00,  8.38it/s]\u001b[A[NeMo I 2022-04-27 07:38:44 token_classification_model:178] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         97.11      95.58      96.34       8659\n",
      "    B-Amenity (label_id: 1)                                 75.60      83.11      79.18        533\n",
      "    B-Cuisine (label_id: 2)                                 89.31      87.97      88.64        532\n",
      "    B-Dish (label_id: 3)                                    86.51      86.81      86.66        288\n",
      "    B-Hours (label_id: 4)                                   71.49      76.89      74.09        212\n",
      "    B-Location (label_id: 5)                                90.86      90.64      90.75        812\n",
      "    B-Price (label_id: 6)                                   85.00      89.47      87.18        171\n",
      "    B-Rating (label_id: 7)                                  83.64      89.05      86.27        201\n",
      "    B-Restaurant_Name (label_id: 8)                         94.44      93.03      93.73        402\n",
      "    I-Amenity (label_id: 9)                                 77.39      84.92      80.98        524\n",
      "    I-Cuisine (label_id: 10)                                75.94      74.81      75.37        135\n",
      "    I-Dish (label_id: 11)                                   80.95      84.30      82.59        121\n",
      "    I-Hours (label_id: 12)                                  84.01      90.85      87.30        295\n",
      "    I-Location (label_id: 13)                               89.26      91.75      90.49        788\n",
      "    I-Price (label_id: 14)                                  84.31      65.15      73.50         66\n",
      "    I-Rating (label_id: 15)                                 91.74      80.00      85.47        125\n",
      "    I-Restaurant_Name (label_id: 16)                        91.93      90.05      90.98        392\n",
      "    -------------------\n",
      "    micro avg                                               92.43      92.43      92.43      14256\n",
      "    macro avg                                               85.27      85.55      85.27      14256\n",
      "    weighted avg                                            92.64      92.43      92.50      14256\n",
      "    \n",
      "Epoch 1: 100%|█| 144/144 [01:27<00:00,  1.65it/s, loss=0.227, val_loss=0.223, lr\n",
      "Epoch 2:  83%|▊| 120/144 [01:25<00:17,  1.41it/s, loss=0.169, val_loss=0.223, lr\u001b[A\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 2:  85%|▊| 122/144 [01:25<00:15,  1.43it/s, loss=0.169, val_loss=0.223, lr\u001b[A\n",
      "Validating:   8%|██▋                             | 2/24 [00:00<00:04,  4.50it/s]\u001b[A\n",
      "Epoch 2:  86%|▊| 124/144 [01:25<00:13,  1.45it/s, loss=0.169, val_loss=0.223, lr\u001b[A\n",
      "Validating:  17%|█████▎                          | 4/24 [00:00<00:03,  5.73it/s]\u001b[A\n",
      "Epoch 2:  88%|▉| 126/144 [01:25<00:12,  1.47it/s, loss=0.169, val_loss=0.223, lr\u001b[A\n",
      "Validating:  25%|████████                        | 6/24 [00:00<00:02,  6.66it/s]\u001b[A\n",
      "Epoch 2:  89%|▉| 128/144 [01:26<00:10,  1.49it/s, loss=0.169, val_loss=0.223, lr\u001b[A\n",
      "Validating:  33%|██████████▋                     | 8/24 [00:01<00:02,  7.15it/s]\u001b[A\n",
      "Epoch 2:  90%|▉| 130/144 [01:26<00:09,  1.51it/s, loss=0.169, val_loss=0.223, lr\u001b[A\n",
      "Validating:  42%|████████████▉                  | 10/24 [00:01<00:01,  7.46it/s]\u001b[A\n",
      "Epoch 2:  92%|▉| 132/144 [01:26<00:07,  1.52it/s, loss=0.169, val_loss=0.223, lr\u001b[A\n",
      "Validating:  50%|███████████████▌               | 12/24 [00:01<00:01,  7.61it/s]\u001b[A\n",
      "Epoch 2:  93%|▉| 134/144 [01:26<00:06,  1.54it/s, loss=0.169, val_loss=0.223, lr\u001b[A\n",
      "Validating:  58%|██████████████████             | 14/24 [00:01<00:01,  7.72it/s]\u001b[A\n",
      "Epoch 2:  94%|▉| 136/144 [01:27<00:05,  1.56it/s, loss=0.169, val_loss=0.223, lr\u001b[A\n",
      "Validating:  67%|████████████████████▋          | 16/24 [00:02<00:01,  7.75it/s]\u001b[A\n",
      "Epoch 2:  96%|▉| 138/144 [01:27<00:03,  1.58it/s, loss=0.169, val_loss=0.223, lr\u001b[A\n",
      "Validating:  75%|███████████████████████▎       | 18/24 [00:02<00:00,  7.78it/s]\u001b[A\n",
      "Epoch 2:  97%|▉| 140/144 [01:27<00:02,  1.60it/s, loss=0.169, val_loss=0.223, lr\u001b[A\n",
      "Validating:  83%|█████████████████████████▊     | 20/24 [00:02<00:00,  7.76it/s]\u001b[A\n",
      "Epoch 2:  99%|▉| 142/144 [01:27<00:01,  1.62it/s, loss=0.169, val_loss=0.223, lr\u001b[A\n",
      "Validating:  92%|████████████████████████████▍  | 22/24 [00:02<00:00,  7.75it/s]\u001b[A\n",
      "Epoch 2: 100%|█| 144/144 [01:28<00:00,  1.63it/s, loss=0.169, val_loss=0.223, lr\u001b[A\n",
      "Validating: 100%|███████████████████████████████| 24/24 [00:03<00:00,  8.19it/s]\u001b[A[NeMo I 2022-04-27 07:40:13 token_classification_model:178] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         97.34      95.27      96.29       8659\n",
      "    B-Amenity (label_id: 1)                                 74.66      83.49      78.83        533\n",
      "    B-Cuisine (label_id: 2)                                 89.20      88.53      88.87        532\n",
      "    B-Dish (label_id: 3)                                    83.50      87.85      85.62        288\n",
      "    B-Hours (label_id: 4)                                   71.43      77.83      74.49        212\n",
      "    B-Location (label_id: 5)                                90.56      91.01      90.79        812\n",
      "    B-Price (label_id: 6)                                   84.07      89.47      86.69        171\n",
      "    B-Rating (label_id: 7)                                  82.51      91.54      86.79        201\n",
      "    B-Restaurant_Name (label_id: 8)                         96.34      91.54      93.88        402\n",
      "    I-Amenity (label_id: 9)                                 77.43      85.11      81.09        524\n",
      "    I-Cuisine (label_id: 10)                                73.88      73.33      73.61        135\n",
      "    I-Dish (label_id: 11)                                   77.44      85.12      81.10        121\n",
      "    I-Hours (label_id: 12)                                  84.21      92.20      88.03        295\n",
      "    I-Location (label_id: 13)                               89.52      92.13      90.81        788\n",
      "    I-Price (label_id: 14)                                  78.95      68.18      73.17         66\n",
      "    I-Rating (label_id: 15)                                 87.50      84.00      85.71        125\n",
      "    I-Restaurant_Name (label_id: 16)                        94.01      88.01      90.91        392\n",
      "    -------------------\n",
      "    micro avg                                               92.37      92.37      92.37      14256\n",
      "    macro avg                                               84.27      86.15      85.10      14256\n",
      "    weighted avg                                            92.65      92.37      92.47      14256\n",
      "    \n",
      "Epoch 2: 100%|█| 144/144 [01:28<00:00,  1.63it/s, loss=0.169, val_loss=0.227, lr\n",
      "Epoch 2: 100%|█| 144/144 [01:28<00:00,  1.63it/s, loss=0.169, val_loss=0.227, lr\u001b[A\n",
      "[NeMo I 2022-04-27 07:40:15 train:129] Experiment logs saved to '/workspace/mount/results/megatron-base_ner5'\n",
      "[NeMo I 2022-04-27 07:40:15 train:130] Trained model saved to '/workspace/mount/results/megatron-base_ner5/checkpoints/trained-model.tlt'\n",
      "2022-04-27 07:40:16,715 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n",
      "CPU times: user 6.45 s, sys: 5.22 s, total: 11.7 s\n",
      "Wall time: 5min 29s\n"
     ]
    }
   ],
   "source": [
    "%%time \n",
    "# TAO train NER model with Megatron. This takes few minutes\n",
    "!tao token_classification train \\\n",
    "    -e $SPECS_DIR/token_classification/train.yaml \\\n",
    "    -g 1  \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/megatron-base_ner5 \\\n",
    "    data_dir={destination_mount}/data/restaurant \\\n",
    "    model.label_ids={destination_mount}/data/restaurant/label_ids.csv \\\n",
    "    exp_manager.create_checkpoint_callback=false\\\n",
    "    trainer.amp_level=\"O1\" \\\n",
    "    trainer.precision=16 \\\n",
    "    training_ds.num_samples=-1 \\\n",
    "    validation_ds.num_samples=-1 \\\n",
    "    trainer.max_epochs=3 \\\n",
    "    model.language_model.pretrained_model_name=megatron-bert-345m-uncased "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4.5 Evaluate the Trained Model\n",
    "\n",
    "For the token classification task, several metrics are recorded for the evaluation:\n",
    "- Test loss\n",
    "- F1 score, precision and recall per class\n",
    "- F1 score, precision and recall aggregated with micro, macro and weighted average\n",
    "\n",
    "Check out [this article](https://towardsdatascience.com/performance-metrics-confusion-matrix-precision-recall-and-f1-score-a8fe076a2262) to larn more about the performance metrics. \n",
    "\n",
    "The evaluation spec YAML is as simple as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) 2020, NVIDIA CORPORATION. All rights reserved.\n",
      "# TLT Spec file for evaluation of a Token Classification model\n",
      "\n",
      "# Name of the .tlt from which the model will be loaded.\n",
      "restore_from: trained-model.tlt\n",
      "\n",
      "data_dir: ???\n",
      "\n",
      "# Test settings: dataset.\n",
      "test_ds:\n",
      "  text_file: text_dev.txt\n",
      "  labels_file: labels_dev.txt\n",
      "  batch_size: 1\n",
      "  shuffle: false\n",
      "  num_samples: -1 # number of samples to be considered, -1 means the whole the dataset\n"
     ]
    }
   ],
   "source": [
    "# Print the evaluation spec file \n",
    "!cat $source_mount/specs/token_classification/evaluate.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the `data_dir` is not defined, which is an indication that we should override it in the command.  To evaluate the model, we use `tao text_classification evaluate` and override `data_dir`. Other arguments follow the same pattern as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 07:42:50,551 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-04-27 07:42:50,670 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-04-27 07:42:54 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-04-27 07:42:57 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-04-27 07:42:58 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: /workspace/mount/results/bert-base_ner/checkpoints/trained-model.tlt\n",
      "    data_dir: /workspace/mount/data/restaurant\n",
      "    exp_manager:\n",
      "      explicit_log_dir: /workspace/mount/results/bert-base_ner/evaluate\n",
      "      exp_dir: null\n",
      "      name: null\n",
      "      version: null\n",
      "      use_datetime_version: true\n",
      "      resume_if_exists: false\n",
      "      resume_past_end: false\n",
      "      resume_ignore_no_checkpoint: false\n",
      "      create_tensorboard_logger: false\n",
      "      summary_writer_kwargs: null\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs: null\n",
      "      create_checkpoint_callback: false\n",
      "      checkpoint_callback_params:\n",
      "        filepath: null\n",
      "        monitor: val_loss\n",
      "        verbose: true\n",
      "        save_last: true\n",
      "        save_top_k: 3\n",
      "        save_weights_only: false\n",
      "        mode: auto\n",
      "        period: 1\n",
      "        prefix: null\n",
      "        postfix: .nemo\n",
      "        save_best_model: false\n",
      "      files_to_copy: null\n",
      "    trainer:\n",
      "      logger: false\n",
      "      checkpoint_callback: false\n",
      "      callbacks: null\n",
      "      default_root_dir: null\n",
      "      gradient_clip_val: 0.0\n",
      "      process_position: 0\n",
      "      num_nodes: 1\n",
      "      num_processes: 1\n",
      "      gpus: 1\n",
      "      auto_select_gpus: false\n",
      "      tpu_cores: null\n",
      "      log_gpu_memory: null\n",
      "      progress_bar_refresh_rate: 1\n",
      "      overfit_batches: 0.0\n",
      "      track_grad_norm: -1\n",
      "      check_val_every_n_epoch: 1\n",
      "      fast_dev_run: false\n",
      "      accumulate_grad_batches: 1\n",
      "      max_epochs: 1000\n",
      "      min_epochs: 1\n",
      "      max_steps: null\n",
      "      min_steps: null\n",
      "      limit_train_batches: 1.0\n",
      "      limit_val_batches: 1.0\n",
      "      limit_test_batches: 1.0\n",
      "      val_check_interval: 1.0\n",
      "      flush_logs_every_n_steps: 100\n",
      "      log_every_n_steps: 50\n",
      "      accelerator: ddp\n",
      "      sync_batchnorm: false\n",
      "      precision: 32\n",
      "      weights_summary: full\n",
      "      weights_save_path: null\n",
      "      num_sanity_val_steps: 2\n",
      "      truncated_bptt_steps: null\n",
      "      resume_from_checkpoint: null\n",
      "      profiler: null\n",
      "      benchmark: false\n",
      "      deterministic: false\n",
      "      reload_dataloaders_every_epoch: false\n",
      "      auto_lr_find: false\n",
      "      replace_sampler_ddp: true\n",
      "      terminate_on_nan: false\n",
      "      auto_scale_batch_size: false\n",
      "      prepare_data_per_node: true\n",
      "      amp_backend: native\n",
      "      amp_level: O2\n",
      "    test_ds:\n",
      "      batch_size: 1\n",
      "      text_file: text_dev.txt\n",
      "      labels_file: labels_dev.txt\n",
      "      shuffle: false\n",
      "      num_samples: -1\n",
      "    encryption_key: '******'\n",
      "    \n",
      "GPU available: True, used: True\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2022-04-27 07:42:58 exp_manager:194] Experiments will be logged at /workspace/mount/results/bert-base_ner/evaluate\n",
      "[NeMo W 2022-04-27 07:43:00 modelPT:193] Using /tmp/tmpxmwef_g_/tokenizer.vocab_file instead of tokenizer.vocab_file.\n",
      "Lock 139826168217360 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100%|██████████████████████████████| 570/570 [00:00<00:00, 488kB/s]\n",
      "Lock 139826168217360 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 139826168216208 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100%|███████████████████████████| 232k/232k [00:00<00:00, 55.6MB/s]\n",
      "Lock 139826168216208 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 139826168683440 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100%|███████████████████████████| 28.0/28.0 [00:00<00:00, 24.2kB/s]\n",
      "Lock 139826168683440 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 139826168217504 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100%|███████████████████████████| 466k/466k [00:00<00:00, 58.7MB/s]\n",
      "Lock 139826168217504 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-04-27 07:43:01 modelPT:1202] World size can only be set by PyTorch Lightning Trainer.\n",
      "Lock 139826169534208 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100%|███████████████████████████| 440M/440M [00:05<00:00, 88.1MB/s]\n",
      "Lock 139826169534208 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo I 2022-04-27 07:43:15 token_classification_model:105] Setting model.dataset.data_dir to /workspace/mount/data/restaurant.\n",
      "[NeMo I 2022-04-27 07:43:15 token_classification_utils:54] Processing /workspace/mount/data/restaurant/labels_dev.txt\n",
      "[NeMo I 2022-04-27 07:43:15 token_classification_utils:74] Using provided labels mapping {'O': 0, 'B-Amenity': 1, 'B-Cuisine': 2, 'B-Dish': 3, 'B-Hours': 4, 'B-Location': 5, 'B-Price': 6, 'B-Rating': 7, 'B-Restaurant_Name': 8, 'I-Amenity': 9, 'I-Cuisine': 10, 'I-Dish': 11, 'I-Hours': 12, 'I-Location': 13, 'I-Price': 14, 'I-Rating': 15, 'I-Restaurant_Name': 16}\n",
      "[NeMo I 2022-04-27 07:43:15 token_classification_utils:96] /workspace/mount/data/restaurant/labels_dev_label_stats.tsv found, skipping stats calculation.\n",
      "[NeMo I 2022-04-27 07:43:15 token_classification_dataset:272] features restored from /workspace/mount/data/restaurant/cached_text_dev.txt_BertTokenizer_128_30522_-1\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Testing: 100%|██████████████████████████████| 1521/1521 [00:44<00:00, 34.63it/s][NeMo I 2022-04-27 07:44:00 token_classification_model:202] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         96.83      95.57      96.19       8659\n",
      "    B-Amenity (label_id: 1)                                 75.55      77.11      76.32        533\n",
      "    B-Cuisine (label_id: 2)                                 89.44      87.59      88.51        532\n",
      "    B-Dish (label_id: 3)                                    81.88      84.72      83.28        288\n",
      "    B-Hours (label_id: 4)                                   70.00      75.94      72.85        212\n",
      "    B-Location (label_id: 5)                                90.49      90.27      90.38        812\n",
      "    B-Price (label_id: 6)                                   82.01      90.64      86.11        171\n",
      "    B-Rating (label_id: 7)                                  78.90      85.57      82.10        201\n",
      "    B-Restaurant_Name (label_id: 8)                         94.67      92.79      93.72        402\n",
      "    I-Amenity (label_id: 9)                                 78.77      82.82      80.74        524\n",
      "    I-Cuisine (label_id: 10)                                74.24      72.59      73.41        135\n",
      "    I-Dish (label_id: 11)                                   71.72      85.95      78.20        121\n",
      "    I-Hours (label_id: 12)                                  84.10      93.22      88.42        295\n",
      "    I-Location (label_id: 13)                               88.34      90.36      89.33        788\n",
      "    I-Price (label_id: 14)                                  78.33      71.21      74.60         66\n",
      "    I-Rating (label_id: 15)                                 86.73      78.40      82.35        125\n",
      "    I-Restaurant_Name (label_id: 16)                        91.94      87.24      89.53        392\n",
      "    -------------------\n",
      "    micro avg                                               91.89      91.89      91.89      14256\n",
      "    macro avg                                               83.17      84.82      83.89      14256\n",
      "    weighted avg                                            92.07      91.89      91.95      14256\n",
      "    \n",
      "Testing: 100%|██████████████████████████████| 1521/1521 [00:44<00:00, 34.12it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'f1': tensor(83.8857, device='cuda:0'),\n",
      " 'precision': tensor(83.1729, device='cuda:0'),\n",
      " 'recall': tensor(84.8240, device='cuda:0'),\n",
      " 'test_loss': tensor(0.2444, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "[NeMo I 2022-04-27 07:44:00 evaluate:92] Experiment logs saved to '/workspace/mount/results/bert-base_ner/evaluate'\n",
      "2022-04-27 07:44:01,619 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# TAO evaluate NER model\n",
    "!tao token_classification evaluate  \\\n",
    "   -e $SPECS_DIR/token_classification/evaluate.yaml \\\n",
    "   -r $RESULTS_DIR/bert-base_ner/evaluate \\\n",
    "   -g 1 \\\n",
    "   -m $RESULTS_DIR/bert-base_ner/checkpoints/trained-model.tlt \\\n",
    "   -k $KEY \\\n",
    "   data_dir={destination_mount}/data/restaurant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can observe the F1 score, precision and recall metrics per class:\n",
    "\n",
    "```\n",
    "    label                                                precision    recall       f1           support   \n",
    "    O (label_id: 0)                                         96.67      95.61      96.14       8659\n",
    "    B-Amenity (label_id: 1)                                 74.37      77.30      75.80        533\n",
    "    B-Cuisine (label_id: 2)                                 89.57      85.53      87.50        532\n",
    "    B-Dish (label_id: 3)                                    82.83      85.42      84.10        288\n",
    "    B-Hours (label_id: 4)                                   71.74      77.83      74.66        212\n",
    "    B-Location (label_id: 5)                                90.48      90.15      90.31        812\n",
    "    B-Price (label_id: 6)                                   82.97      88.30      85.55        171\n",
    "    B-Rating (label_id: 7)                                  79.00      86.07      82.38        201\n",
    "    B-Restaurant_Name (label_id: 8)                         94.90      92.54      93.70        402\n",
    "    I-Amenity (label_id: 9)                                 75.99      80.92      78.37        524\n",
    "    I-Cuisine (label_id: 10)                                74.26      74.81      74.54        135\n",
    "    I-Dish (label_id: 11)                                   71.23      85.95      77.90        121\n",
    "    I-Hours (label_id: 12)                                  84.42      91.86      87.99        295\n",
    "    I-Location (label_id: 13)                               90.04      90.61      90.32        788\n",
    "    I-Price (label_id: 14)                                  89.80      66.67      76.52         66\n",
    "    I-Rating (label_id: 15)                                 84.87      80.80      82.79        125\n",
    "    I-Restaurant_Name (label_id: 16)                        93.40      90.31      91.83        392\n",
    "    -------------------\n",
    "    micro avg                                               91.88      91.88      91.88      14256\n",
    "    macro avg                                               83.91      84.75      84.14      14256\n",
    "    weighted avg                                            92.07      91.88      91.94      14256\n",
    "```\n",
    "\n",
    "you can also observe the test loss (`test_loss`) and the aggregated F1 score, precision, recall metrics on the entire test set:\n",
    "```\n",
    "DATALOADER:0 TEST RESULTS\n",
    "{'f1': tensor(84.1423, device='cuda:0'),\n",
    " 'precision': tensor(83.9138, device='cuda:0'),\n",
    " 'recall': tensor(84.7453, device='cuda:0'),\n",
    " 'test_loss': tensor(0.2424, device='cuda:0')}\n",
    " ```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5 NER Fine-Tuning\n",
    "\n",
    "The TAO Toolkit command for fine-tuning is very similar to that of training. Instead of `tao text_classification train`, use `tao text_classification finetune`.  This command will generate a fine-tuned model `finetuned-model.tlt` at `$RESULTS_DIR/bert-base-finetuned_ner/checkpoints`. \n",
    "\n",
    "The fine-tuning process will start with the trained model weights instead of random weights for the token classification model.  \n",
    "Specify the model checkpoint from the previously trained model with the `-m` argument and specify the spec file corresponding to fine-tuning. \n",
    "\n",
    "The token classification fine-tuning of TAO allows users to:\n",
    "- Fine-tune the token classifier on additional data\n",
    "- Fine-tune on a subset of labels by removing or merging entities in the dataset\n",
    "\n",
    "For this demonstration, as \"Cuisine\" and \"Dish\" labels are very close semantically in our context, we will merge them and keep one entity, the \"Dish\" label.  The merged data is set up in the directory `tao/data/restaurant_finetune`.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "772\n"
     ]
    }
   ],
   "source": [
    "# We should not find any \"Cuisine\" labels as they have been renamed \"Dish\"\n",
    "!grep Cuisine $source_mount/data/restaurant_finetune/labels_dev.txt |wc -l\n",
    "!grep Dish $source_mount/data/restaurant_finetune/labels_dev.txt |wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) 2020, NVIDIA CORPORATION. All rights reserved.\n",
      "# TLT Spec file for finetuning of the pre-trained TokenClassification model\n",
      "\n",
      "\n",
      "data_dir: ???\n",
      "\n",
      "# Fine-tuning settings: training dataset.\n",
      "finetuning_ds:\n",
      "  num_samples: -1 # number of samples to be considered, -1 means all the dataset\n",
      "\n",
      "# Fine-tuning settings: validation dataset.\n",
      "validation_ds:\n",
      "  num_samples: -1 # number of samples to be considered, -1 means all the dataset\n",
      "\n",
      "# Fine-tuning settings: different optimizer.\n",
      "optim:\n",
      "  name: adam\n",
      "  lr: 2e-5\n",
      "\n",
      "trainer:\n",
      "  max_epochs: 3"
     ]
    }
   ],
   "source": [
    "# Print the fine-tuning spec file \n",
    "!cat $source_mount/specs/token_classification/finetune.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 08:11:41,809 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-04-27 08:11:41,932 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-04-27 08:11:45 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-04-27 08:11:49 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-04-27 08:11:50 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: /workspace/mount/results/bert-base_ner/checkpoints/trained-model.tlt\n",
      "    exp_manager:\n",
      "      explicit_log_dir: /workspace/mount/results/bert-base-finetuned_ner/\n",
      "      exp_dir: null\n",
      "      name: finetuned-model\n",
      "      version: null\n",
      "      use_datetime_version: true\n",
      "      resume_if_exists: true\n",
      "      resume_past_end: false\n",
      "      resume_ignore_no_checkpoint: true\n",
      "      create_tensorboard_logger: false\n",
      "      summary_writer_kwargs: null\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs: null\n",
      "      create_checkpoint_callback: true\n",
      "      checkpoint_callback_params:\n",
      "        filepath: null\n",
      "        monitor: val_loss\n",
      "        verbose: true\n",
      "        save_last: true\n",
      "        save_top_k: 3\n",
      "        save_weights_only: false\n",
      "        mode: auto\n",
      "        period: 1\n",
      "        prefix: null\n",
      "        postfix: .tlt\n",
      "        save_best_model: false\n",
      "      files_to_copy: null\n",
      "    trainer:\n",
      "      logger: false\n",
      "      checkpoint_callback: false\n",
      "      callbacks: null\n",
      "      default_root_dir: null\n",
      "      gradient_clip_val: 0.0\n",
      "      process_position: 0\n",
      "      num_nodes: 1\n",
      "      num_processes: 1\n",
      "      gpus: 1\n",
      "      auto_select_gpus: false\n",
      "      tpu_cores: null\n",
      "      log_gpu_memory: null\n",
      "      progress_bar_refresh_rate: 1\n",
      "      overfit_batches: 0.0\n",
      "      track_grad_norm: -1\n",
      "      check_val_every_n_epoch: 1\n",
      "      fast_dev_run: false\n",
      "      accumulate_grad_batches: 1\n",
      "      max_epochs: 2\n",
      "      min_epochs: 1\n",
      "      max_steps: null\n",
      "      min_steps: null\n",
      "      limit_train_batches: 1.0\n",
      "      limit_val_batches: 1.0\n",
      "      limit_test_batches: 1.0\n",
      "      val_check_interval: 1.0\n",
      "      flush_logs_every_n_steps: 100\n",
      "      log_every_n_steps: 50\n",
      "      accelerator: ddp\n",
      "      sync_batchnorm: false\n",
      "      precision: 16\n",
      "      weights_summary: full\n",
      "      weights_save_path: null\n",
      "      num_sanity_val_steps: 2\n",
      "      truncated_bptt_steps: null\n",
      "      resume_from_checkpoint: null\n",
      "      profiler: null\n",
      "      benchmark: false\n",
      "      deterministic: false\n",
      "      reload_dataloaders_every_epoch: false\n",
      "      auto_lr_find: false\n",
      "      replace_sampler_ddp: true\n",
      "      terminate_on_nan: false\n",
      "      auto_scale_batch_size: false\n",
      "      prepare_data_per_node: true\n",
      "      amp_backend: native\n",
      "      amp_level: O1\n",
      "    data_dir: /workspace/mount/data/restaurant_finetune\n",
      "    finetuning_ds:\n",
      "      batch_size: 32\n",
      "      text_file: text_train.txt\n",
      "      labels_file: labels_train.txt\n",
      "      shuffle: true\n",
      "      num_samples: -1\n",
      "    validation_ds:\n",
      "      batch_size: 32\n",
      "      text_file: text_dev.txt\n",
      "      labels_file: labels_dev.txt\n",
      "      shuffle: false\n",
      "      num_samples: -1\n",
      "    optim:\n",
      "      name: adam\n",
      "      lr: 2.0e-05\n",
      "    encryption_key: '********'\n",
      "    \n",
      "GPU available: True, used: True\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Using native 16bit precision.\n",
      "Using native 16bit precision.\n",
      "[NeMo W 2022-04-27 08:11:50 exp_manager:303] There was no checkpoint folder at checkpoint_dir :/workspace/mount/results/bert-base-finetuned_ner/checkpoints. Training from scratch.\n",
      "[NeMo I 2022-04-27 08:11:50 exp_manager:194] Experiments will be logged at /workspace/mount/results/bert-base-finetuned_ner\n",
      "[NeMo W 2022-04-27 08:11:52 modelPT:193] Using /tmp/tmpk2c_b1fg/tokenizer.vocab_file instead of tokenizer.vocab_file.\n",
      "Lock 140455047120208 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100%|██████████████████████████████| 570/570 [00:00<00:00, 484kB/s]\n",
      "Lock 140455047120208 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 140455047289200 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100%|███████████████████████████| 232k/232k [00:00<00:00, 53.1MB/s]\n",
      "Lock 140455047289200 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 140455046965568 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100%|███████████████████████████| 28.0/28.0 [00:00<00:00, 24.9kB/s]\n",
      "Lock 140455046965568 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 140455046879072 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100%|███████████████████████████| 466k/466k [00:00<00:00, 65.4MB/s]\n",
      "Lock 140455046879072 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-04-27 08:11:52 modelPT:1202] World size can only be set by PyTorch Lightning Trainer.\n",
      "Lock 140455046130560 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100%|███████████████████████████| 440M/440M [00:05<00:00, 76.0MB/s]\n",
      "Lock 140455046130560 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo I 2022-04-27 08:12:08 finetune:108] Model restored from '/workspace/mount/results/bert-base_ner/checkpoints/trained-model.tlt'\n",
      "[NeMo I 2022-04-27 08:12:08 token_classification_model:105] Setting model.dataset.data_dir to /workspace/mount/data/restaurant_finetune.\n",
      "[NeMo I 2022-04-27 08:12:08 token_classification_utils:54] Processing /workspace/mount/data/restaurant_finetune/labels_train.txt\n",
      "[NeMo I 2022-04-27 08:12:08 token_classification_utils:74] Using provided labels mapping {'O': 0, 'B-Amenity': 1, 'B-Cuisine': 2, 'B-Dish': 3, 'B-Hours': 4, 'B-Location': 5, 'B-Price': 6, 'B-Rating': 7, 'B-Restaurant_Name': 8, 'I-Amenity': 9, 'I-Cuisine': 10, 'I-Dish': 11, 'I-Hours': 12, 'I-Location': 13, 'I-Price': 14, 'I-Rating': 15, 'I-Restaurant_Name': 16}\n",
      "[NeMo I 2022-04-27 08:12:08 token_classification_utils:90] Labels mapping {'O': 0, 'B-Amenity': 1, 'B-Cuisine': 2, 'B-Dish': 3, 'B-Hours': 4, 'B-Location': 5, 'B-Price': 6, 'B-Rating': 7, 'B-Restaurant_Name': 8, 'I-Amenity': 9, 'I-Cuisine': 10, 'I-Dish': 11, 'I-Hours': 12, 'I-Location': 13, 'I-Price': 14, 'I-Rating': 15, 'I-Restaurant_Name': 16} saved to : /workspace/mount/data/restaurant_finetune/label_ids.csv\n",
      "[NeMo I 2022-04-27 08:12:11 token_classification_utils:99] Three most popular labels in /workspace/mount/data/restaurant_finetune/labels_train.txt:\n",
      "[NeMo I 2022-04-27 08:12:11 data_preprocessing:131] label: 0, 43670 out of 70525 (61.92%).\n",
      "[NeMo I 2022-04-27 08:12:11 data_preprocessing:131] label: 3, 4314 out of 70525 (6.12%).\n",
      "[NeMo I 2022-04-27 08:12:11 data_preprocessing:131] label: 5, 3817 out of 70525 (5.41%).\n",
      "[NeMo I 2022-04-27 08:12:11 token_classification_utils:101] Total labels: 70525. Label frequencies - {0: 43670, 3: 4314, 5: 3817, 13: 3658, 9: 2676, 1: 2541, 8: 1901, 16: 1668, 11: 1397, 12: 1283, 7: 1070, 4: 990, 6: 730, 15: 527, 14: 283}\n",
      "[NeMo I 2022-04-27 08:12:11 token_classification_utils:110] Class Weights: {0: 0.10766353713456989, 3: 1.0898624632977902, 5: 1.2317701510785084, 13: 1.2853107344632768, 9: 1.7569755854509217, 1: 1.8503213957759412, 8: 2.47325968788357, 16: 2.8187450039968027, 11: 3.3655452159389165, 12: 3.664588204728501, 7: 4.394080996884735, 4: 4.749158249158249, 6: 6.440639269406392, 15: 8.92156862745098, 14: 16.613663133097763}\n",
      "[NeMo I 2022-04-27 08:12:11 token_classification_utils:114] Class weights saved to /workspace/mount/data/restaurant_finetune/labels_train_weights.p\n",
      "[NeMo I 2022-04-27 08:12:19 token_classification_dataset:116] Setting Max Seq length to: 39\n",
      "[NeMo I 2022-04-27 08:12:19 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-04-27 08:12:19 data_preprocessing:297] Min: 3 |                  Max: 39 |                  Mean: 11.860182767624021 |                  Median: 11.0\n",
      "[NeMo I 2022-04-27 08:12:19 data_preprocessing:303] 75 percentile: 14.00\n",
      "[NeMo I 2022-04-27 08:12:19 data_preprocessing:304] 99 percentile: 24.00\n",
      "[NeMo W 2022-04-27 08:12:19 token_classification_dataset:145] 0 are longer than 39\n",
      "[NeMo I 2022-04-27 08:12:19 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2022-04-27 08:12:19 token_classification_dataset:149] i: 0\n",
      "[NeMo I 2022-04-27 08:12:19 token_classification_dataset:150] subtokens: [CLS] 2 start restaurants with inside dining [SEP]\n",
      "[NeMo I 2022-04-27 08:12:19 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 08:12:19 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 08:12:19 token_classification_dataset:153] subtokens_mask: 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 08:12:19 token_classification_dataset:155] labels: 0 7 15 0 0 1 9 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 08:12:19 token_classification_dataset:264] features saved to /workspace/mount/data/restaurant_finetune/cached_text_train.txt_BertTokenizer_128_30522_-1\n",
      "[NeMo I 2022-04-27 08:12:19 token_classification_utils:54] Processing /workspace/mount/data/restaurant_finetune/labels_dev.txt\n",
      "[NeMo I 2022-04-27 08:12:19 token_classification_utils:74] Using provided labels mapping {'O': 0, 'B-Amenity': 1, 'B-Cuisine': 2, 'B-Dish': 3, 'B-Hours': 4, 'B-Location': 5, 'B-Price': 6, 'B-Rating': 7, 'B-Restaurant_Name': 8, 'I-Amenity': 9, 'I-Cuisine': 10, 'I-Dish': 11, 'I-Hours': 12, 'I-Location': 13, 'I-Price': 14, 'I-Rating': 15, 'I-Restaurant_Name': 16}\n",
      "[NeMo I 2022-04-27 08:12:20 token_classification_utils:99] Three most popular labels in /workspace/mount/data/restaurant_finetune/labels_dev.txt:\n",
      "[NeMo I 2022-04-27 08:12:20 data_preprocessing:131] label: 0, 8659 out of 14256 (60.74%).\n",
      "[NeMo I 2022-04-27 08:12:20 data_preprocessing:131] label: 3, 820 out of 14256 (5.75%).\n",
      "[NeMo I 2022-04-27 08:12:20 data_preprocessing:131] label: 5, 812 out of 14256 (5.70%).\n",
      "[NeMo I 2022-04-27 08:12:20 token_classification_utils:101] Total labels: 14256. Label frequencies - {0: 8659, 3: 820, 5: 812, 13: 788, 1: 533, 9: 524, 8: 402, 16: 392, 12: 295, 11: 256, 4: 212, 7: 201, 6: 171, 15: 125, 14: 66}\n",
      "[NeMo I 2022-04-27 08:12:21 token_classification_dataset:116] Setting Max Seq length to: 28\n",
      "[NeMo I 2022-04-27 08:12:21 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-04-27 08:12:21 data_preprocessing:297] Min: 3 |                  Max: 28 |                  Mean: 12.021696252465484 |                  Median: 12.0\n",
      "[NeMo I 2022-04-27 08:12:21 data_preprocessing:303] 75 percentile: 14.00\n",
      "[NeMo I 2022-04-27 08:12:21 data_preprocessing:304] 99 percentile: 23.00\n",
      "[NeMo W 2022-04-27 08:12:21 token_classification_dataset:145] 0 are longer than 28\n",
      "[NeMo I 2022-04-27 08:12:21 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2022-04-27 08:12:21 token_classification_dataset:149] i: 0\n",
      "[NeMo I 2022-04-27 08:12:21 token_classification_dataset:150] subtokens: [CLS] a four star restaurant with a bar [SEP]\n",
      "[NeMo I 2022-04-27 08:12:21 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 08:12:21 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 08:12:21 token_classification_dataset:153] subtokens_mask: 0 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 08:12:21 token_classification_dataset:155] labels: 0 0 7 15 0 5 13 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      "[NeMo I 2022-04-27 08:12:21 token_classification_dataset:264] features saved to /workspace/mount/data/restaurant_finetune/cached_text_dev.txt_BertTokenizer_128_30522_-1\n",
      "[NeMo I 2022-04-27 08:12:21 modelPT:753] Optimizer config = Adam (\n",
      "    Parameter Group 0\n",
      "        amsgrad: False\n",
      "        betas: (0.9, 0.999)\n",
      "        eps: 1e-08\n",
      "        lr: 2e-05\n",
      "        weight_decay: 0\n",
      "    )\n",
      "[NeMo I 2022-04-27 08:12:21 lr_scheduler:492] Scheduler not initialized as no `sched` config supplied to setup_optimizer()\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "[NeMo I 2022-04-27 08:12:21 modelPT:627] No optimizer config provided, therefore no optimizer was created\n",
      "\n",
      "    | Name                                                   | Type                 | Params\n",
      "--------------------------------------------------------------------------------------------------\n",
      "0   | bert_model                                             | BertEncoder          | 109 M \n",
      "1   | bert_model.embeddings                                  | BertEmbeddings       | 23.8 M\n",
      "2   | bert_model.embeddings.word_embeddings                  | Embedding            | 23.4 M\n",
      "3   | bert_model.embeddings.position_embeddings              | Embedding            | 393 K \n",
      "4   | bert_model.embeddings.token_type_embeddings            | Embedding            | 1.5 K \n",
      "5   | bert_model.embeddings.LayerNorm                        | LayerNorm            | 1.5 K \n",
      "6   | bert_model.embeddings.dropout                          | Dropout              | 0     \n",
      "7   | bert_model.encoder                                     | BertEncoder          | 85.1 M\n",
      "8   | bert_model.encoder.layer                               | ModuleList           | 85.1 M\n",
      "9   | bert_model.encoder.layer.0                             | BertLayer            | 7.1 M \n",
      "10  | bert_model.encoder.layer.0.attention                   | BertAttention        | 2.4 M \n",
      "11  | bert_model.encoder.layer.0.attention.self              | BertSelfAttention    | 1.8 M \n",
      "12  | bert_model.encoder.layer.0.attention.self.query        | Linear               | 590 K \n",
      "13  | bert_model.encoder.layer.0.attention.self.key          | Linear               | 590 K \n",
      "14  | bert_model.encoder.layer.0.attention.self.value        | Linear               | 590 K \n",
      "15  | bert_model.encoder.layer.0.attention.self.dropout      | Dropout              | 0     \n",
      "16  | bert_model.encoder.layer.0.attention.output            | BertSelfOutput       | 592 K \n",
      "17  | bert_model.encoder.layer.0.attention.output.dense      | Linear               | 590 K \n",
      "18  | bert_model.encoder.layer.0.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "19  | bert_model.encoder.layer.0.attention.output.dropout    | Dropout              | 0     \n",
      "20  | bert_model.encoder.layer.0.intermediate                | BertIntermediate     | 2.4 M \n",
      "21  | bert_model.encoder.layer.0.intermediate.dense          | Linear               | 2.4 M \n",
      "22  | bert_model.encoder.layer.0.output                      | BertOutput           | 2.4 M \n",
      "23  | bert_model.encoder.layer.0.output.dense                | Linear               | 2.4 M \n",
      "24  | bert_model.encoder.layer.0.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "25  | bert_model.encoder.layer.0.output.dropout              | Dropout              | 0     \n",
      "26  | bert_model.encoder.layer.1                             | BertLayer            | 7.1 M \n",
      "27  | bert_model.encoder.layer.1.attention                   | BertAttention        | 2.4 M \n",
      "28  | bert_model.encoder.layer.1.attention.self              | BertSelfAttention    | 1.8 M \n",
      "29  | bert_model.encoder.layer.1.attention.self.query        | Linear               | 590 K \n",
      "30  | bert_model.encoder.layer.1.attention.self.key          | Linear               | 590 K \n",
      "31  | bert_model.encoder.layer.1.attention.self.value        | Linear               | 590 K \n",
      "32  | bert_model.encoder.layer.1.attention.self.dropout      | Dropout              | 0     \n",
      "33  | bert_model.encoder.layer.1.attention.output            | BertSelfOutput       | 592 K \n",
      "34  | bert_model.encoder.layer.1.attention.output.dense      | Linear               | 590 K \n",
      "35  | bert_model.encoder.layer.1.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "36  | bert_model.encoder.layer.1.attention.output.dropout    | Dropout              | 0     \n",
      "37  | bert_model.encoder.layer.1.intermediate                | BertIntermediate     | 2.4 M \n",
      "38  | bert_model.encoder.layer.1.intermediate.dense          | Linear               | 2.4 M \n",
      "39  | bert_model.encoder.layer.1.output                      | BertOutput           | 2.4 M \n",
      "40  | bert_model.encoder.layer.1.output.dense                | Linear               | 2.4 M \n",
      "41  | bert_model.encoder.layer.1.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "42  | bert_model.encoder.layer.1.output.dropout              | Dropout              | 0     \n",
      "43  | bert_model.encoder.layer.2                             | BertLayer            | 7.1 M \n",
      "44  | bert_model.encoder.layer.2.attention                   | BertAttention        | 2.4 M \n",
      "45  | bert_model.encoder.layer.2.attention.self              | BertSelfAttention    | 1.8 M \n",
      "46  | bert_model.encoder.layer.2.attention.self.query        | Linear               | 590 K \n",
      "47  | bert_model.encoder.layer.2.attention.self.key          | Linear               | 590 K \n",
      "48  | bert_model.encoder.layer.2.attention.self.value        | Linear               | 590 K \n",
      "49  | bert_model.encoder.layer.2.attention.self.dropout      | Dropout              | 0     \n",
      "50  | bert_model.encoder.layer.2.attention.output            | BertSelfOutput       | 592 K \n",
      "51  | bert_model.encoder.layer.2.attention.output.dense      | Linear               | 590 K \n",
      "52  | bert_model.encoder.layer.2.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "53  | bert_model.encoder.layer.2.attention.output.dropout    | Dropout              | 0     \n",
      "54  | bert_model.encoder.layer.2.intermediate                | BertIntermediate     | 2.4 M \n",
      "55  | bert_model.encoder.layer.2.intermediate.dense          | Linear               | 2.4 M \n",
      "56  | bert_model.encoder.layer.2.output                      | BertOutput           | 2.4 M \n",
      "57  | bert_model.encoder.layer.2.output.dense                | Linear               | 2.4 M \n",
      "58  | bert_model.encoder.layer.2.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "59  | bert_model.encoder.layer.2.output.dropout              | Dropout              | 0     \n",
      "60  | bert_model.encoder.layer.3                             | BertLayer            | 7.1 M \n",
      "61  | bert_model.encoder.layer.3.attention                   | BertAttention        | 2.4 M \n",
      "62  | bert_model.encoder.layer.3.attention.self              | BertSelfAttention    | 1.8 M \n",
      "63  | bert_model.encoder.layer.3.attention.self.query        | Linear               | 590 K \n",
      "64  | bert_model.encoder.layer.3.attention.self.key          | Linear               | 590 K \n",
      "65  | bert_model.encoder.layer.3.attention.self.value        | Linear               | 590 K \n",
      "66  | bert_model.encoder.layer.3.attention.self.dropout      | Dropout              | 0     \n",
      "67  | bert_model.encoder.layer.3.attention.output            | BertSelfOutput       | 592 K \n",
      "68  | bert_model.encoder.layer.3.attention.output.dense      | Linear               | 590 K \n",
      "69  | bert_model.encoder.layer.3.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "70  | bert_model.encoder.layer.3.attention.output.dropout    | Dropout              | 0     \n",
      "71  | bert_model.encoder.layer.3.intermediate                | BertIntermediate     | 2.4 M \n",
      "72  | bert_model.encoder.layer.3.intermediate.dense          | Linear               | 2.4 M \n",
      "73  | bert_model.encoder.layer.3.output                      | BertOutput           | 2.4 M \n",
      "74  | bert_model.encoder.layer.3.output.dense                | Linear               | 2.4 M \n",
      "75  | bert_model.encoder.layer.3.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "76  | bert_model.encoder.layer.3.output.dropout              | Dropout              | 0     \n",
      "77  | bert_model.encoder.layer.4                             | BertLayer            | 7.1 M \n",
      "78  | bert_model.encoder.layer.4.attention                   | BertAttention        | 2.4 M \n",
      "79  | bert_model.encoder.layer.4.attention.self              | BertSelfAttention    | 1.8 M \n",
      "80  | bert_model.encoder.layer.4.attention.self.query        | Linear               | 590 K \n",
      "81  | bert_model.encoder.layer.4.attention.self.key          | Linear               | 590 K \n",
      "82  | bert_model.encoder.layer.4.attention.self.value        | Linear               | 590 K \n",
      "83  | bert_model.encoder.layer.4.attention.self.dropout      | Dropout              | 0     \n",
      "84  | bert_model.encoder.layer.4.attention.output            | BertSelfOutput       | 592 K \n",
      "85  | bert_model.encoder.layer.4.attention.output.dense      | Linear               | 590 K \n",
      "86  | bert_model.encoder.layer.4.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "87  | bert_model.encoder.layer.4.attention.output.dropout    | Dropout              | 0     \n",
      "88  | bert_model.encoder.layer.4.intermediate                | BertIntermediate     | 2.4 M \n",
      "89  | bert_model.encoder.layer.4.intermediate.dense          | Linear               | 2.4 M \n",
      "90  | bert_model.encoder.layer.4.output                      | BertOutput           | 2.4 M \n",
      "91  | bert_model.encoder.layer.4.output.dense                | Linear               | 2.4 M \n",
      "92  | bert_model.encoder.layer.4.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "93  | bert_model.encoder.layer.4.output.dropout              | Dropout              | 0     \n",
      "94  | bert_model.encoder.layer.5                             | BertLayer            | 7.1 M \n",
      "95  | bert_model.encoder.layer.5.attention                   | BertAttention        | 2.4 M \n",
      "96  | bert_model.encoder.layer.5.attention.self              | BertSelfAttention    | 1.8 M \n",
      "97  | bert_model.encoder.layer.5.attention.self.query        | Linear               | 590 K \n",
      "98  | bert_model.encoder.layer.5.attention.self.key          | Linear               | 590 K \n",
      "99  | bert_model.encoder.layer.5.attention.self.value        | Linear               | 590 K \n",
      "100 | bert_model.encoder.layer.5.attention.self.dropout      | Dropout              | 0     \n",
      "101 | bert_model.encoder.layer.5.attention.output            | BertSelfOutput       | 592 K \n",
      "102 | bert_model.encoder.layer.5.attention.output.dense      | Linear               | 590 K \n",
      "103 | bert_model.encoder.layer.5.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "104 | bert_model.encoder.layer.5.attention.output.dropout    | Dropout              | 0     \n",
      "105 | bert_model.encoder.layer.5.intermediate                | BertIntermediate     | 2.4 M \n",
      "106 | bert_model.encoder.layer.5.intermediate.dense          | Linear               | 2.4 M \n",
      "107 | bert_model.encoder.layer.5.output                      | BertOutput           | 2.4 M \n",
      "108 | bert_model.encoder.layer.5.output.dense                | Linear               | 2.4 M \n",
      "109 | bert_model.encoder.layer.5.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "110 | bert_model.encoder.layer.5.output.dropout              | Dropout              | 0     \n",
      "111 | bert_model.encoder.layer.6                             | BertLayer            | 7.1 M \n",
      "112 | bert_model.encoder.layer.6.attention                   | BertAttention        | 2.4 M \n",
      "113 | bert_model.encoder.layer.6.attention.self              | BertSelfAttention    | 1.8 M \n",
      "114 | bert_model.encoder.layer.6.attention.self.query        | Linear               | 590 K \n",
      "115 | bert_model.encoder.layer.6.attention.self.key          | Linear               | 590 K \n",
      "116 | bert_model.encoder.layer.6.attention.self.value        | Linear               | 590 K \n",
      "117 | bert_model.encoder.layer.6.attention.self.dropout      | Dropout              | 0     \n",
      "118 | bert_model.encoder.layer.6.attention.output            | BertSelfOutput       | 592 K \n",
      "119 | bert_model.encoder.layer.6.attention.output.dense      | Linear               | 590 K \n",
      "120 | bert_model.encoder.layer.6.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "121 | bert_model.encoder.layer.6.attention.output.dropout    | Dropout              | 0     \n",
      "122 | bert_model.encoder.layer.6.intermediate                | BertIntermediate     | 2.4 M \n",
      "123 | bert_model.encoder.layer.6.intermediate.dense          | Linear               | 2.4 M \n",
      "124 | bert_model.encoder.layer.6.output                      | BertOutput           | 2.4 M \n",
      "125 | bert_model.encoder.layer.6.output.dense                | Linear               | 2.4 M \n",
      "126 | bert_model.encoder.layer.6.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "127 | bert_model.encoder.layer.6.output.dropout              | Dropout              | 0     \n",
      "128 | bert_model.encoder.layer.7                             | BertLayer            | 7.1 M \n",
      "129 | bert_model.encoder.layer.7.attention                   | BertAttention        | 2.4 M \n",
      "130 | bert_model.encoder.layer.7.attention.self              | BertSelfAttention    | 1.8 M \n",
      "131 | bert_model.encoder.layer.7.attention.self.query        | Linear               | 590 K \n",
      "132 | bert_model.encoder.layer.7.attention.self.key          | Linear               | 590 K \n",
      "133 | bert_model.encoder.layer.7.attention.self.value        | Linear               | 590 K \n",
      "134 | bert_model.encoder.layer.7.attention.self.dropout      | Dropout              | 0     \n",
      "135 | bert_model.encoder.layer.7.attention.output            | BertSelfOutput       | 592 K \n",
      "136 | bert_model.encoder.layer.7.attention.output.dense      | Linear               | 590 K \n",
      "137 | bert_model.encoder.layer.7.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "138 | bert_model.encoder.layer.7.attention.output.dropout    | Dropout              | 0     \n",
      "139 | bert_model.encoder.layer.7.intermediate                | BertIntermediate     | 2.4 M \n",
      "140 | bert_model.encoder.layer.7.intermediate.dense          | Linear               | 2.4 M \n",
      "141 | bert_model.encoder.layer.7.output                      | BertOutput           | 2.4 M \n",
      "142 | bert_model.encoder.layer.7.output.dense                | Linear               | 2.4 M \n",
      "143 | bert_model.encoder.layer.7.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "144 | bert_model.encoder.layer.7.output.dropout              | Dropout              | 0     \n",
      "145 | bert_model.encoder.layer.8                             | BertLayer            | 7.1 M \n",
      "146 | bert_model.encoder.layer.8.attention                   | BertAttention        | 2.4 M \n",
      "147 | bert_model.encoder.layer.8.attention.self              | BertSelfAttention    | 1.8 M \n",
      "148 | bert_model.encoder.layer.8.attention.self.query        | Linear               | 590 K \n",
      "149 | bert_model.encoder.layer.8.attention.self.key          | Linear               | 590 K \n",
      "150 | bert_model.encoder.layer.8.attention.self.value        | Linear               | 590 K \n",
      "151 | bert_model.encoder.layer.8.attention.self.dropout      | Dropout              | 0     \n",
      "152 | bert_model.encoder.layer.8.attention.output            | BertSelfOutput       | 592 K \n",
      "153 | bert_model.encoder.layer.8.attention.output.dense      | Linear               | 590 K \n",
      "154 | bert_model.encoder.layer.8.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "155 | bert_model.encoder.layer.8.attention.output.dropout    | Dropout              | 0     \n",
      "156 | bert_model.encoder.layer.8.intermediate                | BertIntermediate     | 2.4 M \n",
      "157 | bert_model.encoder.layer.8.intermediate.dense          | Linear               | 2.4 M \n",
      "158 | bert_model.encoder.layer.8.output                      | BertOutput           | 2.4 M \n",
      "159 | bert_model.encoder.layer.8.output.dense                | Linear               | 2.4 M \n",
      "160 | bert_model.encoder.layer.8.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "161 | bert_model.encoder.layer.8.output.dropout              | Dropout              | 0     \n",
      "162 | bert_model.encoder.layer.9                             | BertLayer            | 7.1 M \n",
      "163 | bert_model.encoder.layer.9.attention                   | BertAttention        | 2.4 M \n",
      "164 | bert_model.encoder.layer.9.attention.self              | BertSelfAttention    | 1.8 M \n",
      "165 | bert_model.encoder.layer.9.attention.self.query        | Linear               | 590 K \n",
      "166 | bert_model.encoder.layer.9.attention.self.key          | Linear               | 590 K \n",
      "167 | bert_model.encoder.layer.9.attention.self.value        | Linear               | 590 K \n",
      "168 | bert_model.encoder.layer.9.attention.self.dropout      | Dropout              | 0     \n",
      "169 | bert_model.encoder.layer.9.attention.output            | BertSelfOutput       | 592 K \n",
      "170 | bert_model.encoder.layer.9.attention.output.dense      | Linear               | 590 K \n",
      "171 | bert_model.encoder.layer.9.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "172 | bert_model.encoder.layer.9.attention.output.dropout    | Dropout              | 0     \n",
      "173 | bert_model.encoder.layer.9.intermediate                | BertIntermediate     | 2.4 M \n",
      "174 | bert_model.encoder.layer.9.intermediate.dense          | Linear               | 2.4 M \n",
      "175 | bert_model.encoder.layer.9.output                      | BertOutput           | 2.4 M \n",
      "176 | bert_model.encoder.layer.9.output.dense                | Linear               | 2.4 M \n",
      "177 | bert_model.encoder.layer.9.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "178 | bert_model.encoder.layer.9.output.dropout              | Dropout              | 0     \n",
      "179 | bert_model.encoder.layer.10                            | BertLayer            | 7.1 M \n",
      "180 | bert_model.encoder.layer.10.attention                  | BertAttention        | 2.4 M \n",
      "181 | bert_model.encoder.layer.10.attention.self             | BertSelfAttention    | 1.8 M \n",
      "182 | bert_model.encoder.layer.10.attention.self.query       | Linear               | 590 K \n",
      "183 | bert_model.encoder.layer.10.attention.self.key         | Linear               | 590 K \n",
      "184 | bert_model.encoder.layer.10.attention.self.value       | Linear               | 590 K \n",
      "185 | bert_model.encoder.layer.10.attention.self.dropout     | Dropout              | 0     \n",
      "186 | bert_model.encoder.layer.10.attention.output           | BertSelfOutput       | 592 K \n",
      "187 | bert_model.encoder.layer.10.attention.output.dense     | Linear               | 590 K \n",
      "188 | bert_model.encoder.layer.10.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "189 | bert_model.encoder.layer.10.attention.output.dropout   | Dropout              | 0     \n",
      "190 | bert_model.encoder.layer.10.intermediate               | BertIntermediate     | 2.4 M \n",
      "191 | bert_model.encoder.layer.10.intermediate.dense         | Linear               | 2.4 M \n",
      "192 | bert_model.encoder.layer.10.output                     | BertOutput           | 2.4 M \n",
      "193 | bert_model.encoder.layer.10.output.dense               | Linear               | 2.4 M \n",
      "194 | bert_model.encoder.layer.10.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "195 | bert_model.encoder.layer.10.output.dropout             | Dropout              | 0     \n",
      "196 | bert_model.encoder.layer.11                            | BertLayer            | 7.1 M \n",
      "197 | bert_model.encoder.layer.11.attention                  | BertAttention        | 2.4 M \n",
      "198 | bert_model.encoder.layer.11.attention.self             | BertSelfAttention    | 1.8 M \n",
      "199 | bert_model.encoder.layer.11.attention.self.query       | Linear               | 590 K \n",
      "200 | bert_model.encoder.layer.11.attention.self.key         | Linear               | 590 K \n",
      "201 | bert_model.encoder.layer.11.attention.self.value       | Linear               | 590 K \n",
      "202 | bert_model.encoder.layer.11.attention.self.dropout     | Dropout              | 0     \n",
      "203 | bert_model.encoder.layer.11.attention.output           | BertSelfOutput       | 592 K \n",
      "204 | bert_model.encoder.layer.11.attention.output.dense     | Linear               | 590 K \n",
      "205 | bert_model.encoder.layer.11.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "206 | bert_model.encoder.layer.11.attention.output.dropout   | Dropout              | 0     \n",
      "207 | bert_model.encoder.layer.11.intermediate               | BertIntermediate     | 2.4 M \n",
      "208 | bert_model.encoder.layer.11.intermediate.dense         | Linear               | 2.4 M \n",
      "209 | bert_model.encoder.layer.11.output                     | BertOutput           | 2.4 M \n",
      "210 | bert_model.encoder.layer.11.output.dense               | Linear               | 2.4 M \n",
      "211 | bert_model.encoder.layer.11.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "212 | bert_model.encoder.layer.11.output.dropout             | Dropout              | 0     \n",
      "213 | bert_model.pooler                                      | BertPooler           | 590 K \n",
      "214 | bert_model.pooler.dense                                | Linear               | 590 K \n",
      "215 | bert_model.pooler.activation                           | Tanh                 | 0     \n",
      "216 | classifier                                             | TokenClassifier      | 603 K \n",
      "217 | classifier.dropout                                     | Dropout              | 0     \n",
      "218 | classifier.mlp                                         | MultiLayerPerceptron | 603 K \n",
      "219 | classifier.mlp.layer0                                  | Linear               | 590 K \n",
      "220 | classifier.mlp.layer2                                  | Linear               | 13.1 K\n",
      "221 | loss                                                   | CrossEntropyLoss     | 0     \n",
      "222 | classification_report                                  | ClassificationReport | 0     \n",
      "--------------------------------------------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "\n",
      "    | Name                                                   | Type                 | Params\n",
      "--------------------------------------------------------------------------------------------------\n",
      "0   | bert_model                                             | BertEncoder          | 109 M \n",
      "1   | bert_model.embeddings                                  | BertEmbeddings       | 23.8 M\n",
      "2   | bert_model.embeddings.word_embeddings                  | Embedding            | 23.4 M\n",
      "3   | bert_model.embeddings.position_embeddings              | Embedding            | 393 K \n",
      "4   | bert_model.embeddings.token_type_embeddings            | Embedding            | 1.5 K \n",
      "5   | bert_model.embeddings.LayerNorm                        | LayerNorm            | 1.5 K \n",
      "6   | bert_model.embeddings.dropout                          | Dropout              | 0     \n",
      "7   | bert_model.encoder                                     | BertEncoder          | 85.1 M\n",
      "8   | bert_model.encoder.layer                               | ModuleList           | 85.1 M\n",
      "9   | bert_model.encoder.layer.0                             | BertLayer            | 7.1 M \n",
      "10  | bert_model.encoder.layer.0.attention                   | BertAttention        | 2.4 M \n",
      "11  | bert_model.encoder.layer.0.attention.self              | BertSelfAttention    | 1.8 M \n",
      "12  | bert_model.encoder.layer.0.attention.self.query        | Linear               | 590 K \n",
      "13  | bert_model.encoder.layer.0.attention.self.key          | Linear               | 590 K \n",
      "14  | bert_model.encoder.layer.0.attention.self.value        | Linear               | 590 K \n",
      "15  | bert_model.encoder.layer.0.attention.self.dropout      | Dropout              | 0     \n",
      "16  | bert_model.encoder.layer.0.attention.output            | BertSelfOutput       | 592 K \n",
      "17  | bert_model.encoder.layer.0.attention.output.dense      | Linear               | 590 K \n",
      "18  | bert_model.encoder.layer.0.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "19  | bert_model.encoder.layer.0.attention.output.dropout    | Dropout              | 0     \n",
      "20  | bert_model.encoder.layer.0.intermediate                | BertIntermediate     | 2.4 M \n",
      "21  | bert_model.encoder.layer.0.intermediate.dense          | Linear               | 2.4 M \n",
      "22  | bert_model.encoder.layer.0.output                      | BertOutput           | 2.4 M \n",
      "23  | bert_model.encoder.layer.0.output.dense                | Linear               | 2.4 M \n",
      "24  | bert_model.encoder.layer.0.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "25  | bert_model.encoder.layer.0.output.dropout              | Dropout              | 0     \n",
      "26  | bert_model.encoder.layer.1                             | BertLayer            | 7.1 M \n",
      "27  | bert_model.encoder.layer.1.attention                   | BertAttention        | 2.4 M \n",
      "28  | bert_model.encoder.layer.1.attention.self              | BertSelfAttention    | 1.8 M \n",
      "29  | bert_model.encoder.layer.1.attention.self.query        | Linear               | 590 K \n",
      "30  | bert_model.encoder.layer.1.attention.self.key          | Linear               | 590 K \n",
      "31  | bert_model.encoder.layer.1.attention.self.value        | Linear               | 590 K \n",
      "32  | bert_model.encoder.layer.1.attention.self.dropout      | Dropout              | 0     \n",
      "33  | bert_model.encoder.layer.1.attention.output            | BertSelfOutput       | 592 K \n",
      "34  | bert_model.encoder.layer.1.attention.output.dense      | Linear               | 590 K \n",
      "35  | bert_model.encoder.layer.1.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "36  | bert_model.encoder.layer.1.attention.output.dropout    | Dropout              | 0     \n",
      "37  | bert_model.encoder.layer.1.intermediate                | BertIntermediate     | 2.4 M \n",
      "38  | bert_model.encoder.layer.1.intermediate.dense          | Linear               | 2.4 M \n",
      "39  | bert_model.encoder.layer.1.output                      | BertOutput           | 2.4 M \n",
      "40  | bert_model.encoder.layer.1.output.dense                | Linear               | 2.4 M \n",
      "41  | bert_model.encoder.layer.1.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "42  | bert_model.encoder.layer.1.output.dropout              | Dropout              | 0     \n",
      "43  | bert_model.encoder.layer.2                             | BertLayer            | 7.1 M \n",
      "44  | bert_model.encoder.layer.2.attention                   | BertAttention        | 2.4 M \n",
      "45  | bert_model.encoder.layer.2.attention.self              | BertSelfAttention    | 1.8 M \n",
      "46  | bert_model.encoder.layer.2.attention.self.query        | Linear               | 590 K \n",
      "47  | bert_model.encoder.layer.2.attention.self.key          | Linear               | 590 K \n",
      "48  | bert_model.encoder.layer.2.attention.self.value        | Linear               | 590 K \n",
      "49  | bert_model.encoder.layer.2.attention.self.dropout      | Dropout              | 0     \n",
      "50  | bert_model.encoder.layer.2.attention.output            | BertSelfOutput       | 592 K \n",
      "51  | bert_model.encoder.layer.2.attention.output.dense      | Linear               | 590 K \n",
      "52  | bert_model.encoder.layer.2.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "53  | bert_model.encoder.layer.2.attention.output.dropout    | Dropout              | 0     \n",
      "54  | bert_model.encoder.layer.2.intermediate                | BertIntermediate     | 2.4 M \n",
      "55  | bert_model.encoder.layer.2.intermediate.dense          | Linear               | 2.4 M \n",
      "56  | bert_model.encoder.layer.2.output                      | BertOutput           | 2.4 M \n",
      "57  | bert_model.encoder.layer.2.output.dense                | Linear               | 2.4 M \n",
      "58  | bert_model.encoder.layer.2.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "59  | bert_model.encoder.layer.2.output.dropout              | Dropout              | 0     \n",
      "60  | bert_model.encoder.layer.3                             | BertLayer            | 7.1 M \n",
      "61  | bert_model.encoder.layer.3.attention                   | BertAttention        | 2.4 M \n",
      "62  | bert_model.encoder.layer.3.attention.self              | BertSelfAttention    | 1.8 M \n",
      "63  | bert_model.encoder.layer.3.attention.self.query        | Linear               | 590 K \n",
      "64  | bert_model.encoder.layer.3.attention.self.key          | Linear               | 590 K \n",
      "65  | bert_model.encoder.layer.3.attention.self.value        | Linear               | 590 K \n",
      "66  | bert_model.encoder.layer.3.attention.self.dropout      | Dropout              | 0     \n",
      "67  | bert_model.encoder.layer.3.attention.output            | BertSelfOutput       | 592 K \n",
      "68  | bert_model.encoder.layer.3.attention.output.dense      | Linear               | 590 K \n",
      "69  | bert_model.encoder.layer.3.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "70  | bert_model.encoder.layer.3.attention.output.dropout    | Dropout              | 0     \n",
      "71  | bert_model.encoder.layer.3.intermediate                | BertIntermediate     | 2.4 M \n",
      "72  | bert_model.encoder.layer.3.intermediate.dense          | Linear               | 2.4 M \n",
      "73  | bert_model.encoder.layer.3.output                      | BertOutput           | 2.4 M \n",
      "74  | bert_model.encoder.layer.3.output.dense                | Linear               | 2.4 M \n",
      "75  | bert_model.encoder.layer.3.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "76  | bert_model.encoder.layer.3.output.dropout              | Dropout              | 0     \n",
      "77  | bert_model.encoder.layer.4                             | BertLayer            | 7.1 M \n",
      "78  | bert_model.encoder.layer.4.attention                   | BertAttention        | 2.4 M \n",
      "79  | bert_model.encoder.layer.4.attention.self              | BertSelfAttention    | 1.8 M \n",
      "80  | bert_model.encoder.layer.4.attention.self.query        | Linear               | 590 K \n",
      "81  | bert_model.encoder.layer.4.attention.self.key          | Linear               | 590 K \n",
      "82  | bert_model.encoder.layer.4.attention.self.value        | Linear               | 590 K \n",
      "83  | bert_model.encoder.layer.4.attention.self.dropout      | Dropout              | 0     \n",
      "84  | bert_model.encoder.layer.4.attention.output            | BertSelfOutput       | 592 K \n",
      "85  | bert_model.encoder.layer.4.attention.output.dense      | Linear               | 590 K \n",
      "86  | bert_model.encoder.layer.4.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "87  | bert_model.encoder.layer.4.attention.output.dropout    | Dropout              | 0     \n",
      "88  | bert_model.encoder.layer.4.intermediate                | BertIntermediate     | 2.4 M \n",
      "89  | bert_model.encoder.layer.4.intermediate.dense          | Linear               | 2.4 M \n",
      "90  | bert_model.encoder.layer.4.output                      | BertOutput           | 2.4 M \n",
      "91  | bert_model.encoder.layer.4.output.dense                | Linear               | 2.4 M \n",
      "92  | bert_model.encoder.layer.4.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "93  | bert_model.encoder.layer.4.output.dropout              | Dropout              | 0     \n",
      "94  | bert_model.encoder.layer.5                             | BertLayer            | 7.1 M \n",
      "95  | bert_model.encoder.layer.5.attention                   | BertAttention        | 2.4 M \n",
      "96  | bert_model.encoder.layer.5.attention.self              | BertSelfAttention    | 1.8 M \n",
      "97  | bert_model.encoder.layer.5.attention.self.query        | Linear               | 590 K \n",
      "98  | bert_model.encoder.layer.5.attention.self.key          | Linear               | 590 K \n",
      "99  | bert_model.encoder.layer.5.attention.self.value        | Linear               | 590 K \n",
      "100 | bert_model.encoder.layer.5.attention.self.dropout      | Dropout              | 0     \n",
      "101 | bert_model.encoder.layer.5.attention.output            | BertSelfOutput       | 592 K \n",
      "102 | bert_model.encoder.layer.5.attention.output.dense      | Linear               | 590 K \n",
      "103 | bert_model.encoder.layer.5.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "104 | bert_model.encoder.layer.5.attention.output.dropout    | Dropout              | 0     \n",
      "105 | bert_model.encoder.layer.5.intermediate                | BertIntermediate     | 2.4 M \n",
      "106 | bert_model.encoder.layer.5.intermediate.dense          | Linear               | 2.4 M \n",
      "107 | bert_model.encoder.layer.5.output                      | BertOutput           | 2.4 M \n",
      "108 | bert_model.encoder.layer.5.output.dense                | Linear               | 2.4 M \n",
      "109 | bert_model.encoder.layer.5.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "110 | bert_model.encoder.layer.5.output.dropout              | Dropout              | 0     \n",
      "111 | bert_model.encoder.layer.6                             | BertLayer            | 7.1 M \n",
      "112 | bert_model.encoder.layer.6.attention                   | BertAttention        | 2.4 M \n",
      "113 | bert_model.encoder.layer.6.attention.self              | BertSelfAttention    | 1.8 M \n",
      "114 | bert_model.encoder.layer.6.attention.self.query        | Linear               | 590 K \n",
      "115 | bert_model.encoder.layer.6.attention.self.key          | Linear               | 590 K \n",
      "116 | bert_model.encoder.layer.6.attention.self.value        | Linear               | 590 K \n",
      "117 | bert_model.encoder.layer.6.attention.self.dropout      | Dropout              | 0     \n",
      "118 | bert_model.encoder.layer.6.attention.output            | BertSelfOutput       | 592 K \n",
      "119 | bert_model.encoder.layer.6.attention.output.dense      | Linear               | 590 K \n",
      "120 | bert_model.encoder.layer.6.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "121 | bert_model.encoder.layer.6.attention.output.dropout    | Dropout              | 0     \n",
      "122 | bert_model.encoder.layer.6.intermediate                | BertIntermediate     | 2.4 M \n",
      "123 | bert_model.encoder.layer.6.intermediate.dense          | Linear               | 2.4 M \n",
      "124 | bert_model.encoder.layer.6.output                      | BertOutput           | 2.4 M \n",
      "125 | bert_model.encoder.layer.6.output.dense                | Linear               | 2.4 M \n",
      "126 | bert_model.encoder.layer.6.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "127 | bert_model.encoder.layer.6.output.dropout              | Dropout              | 0     \n",
      "128 | bert_model.encoder.layer.7                             | BertLayer            | 7.1 M \n",
      "129 | bert_model.encoder.layer.7.attention                   | BertAttention        | 2.4 M \n",
      "130 | bert_model.encoder.layer.7.attention.self              | BertSelfAttention    | 1.8 M \n",
      "131 | bert_model.encoder.layer.7.attention.self.query        | Linear               | 590 K \n",
      "132 | bert_model.encoder.layer.7.attention.self.key          | Linear               | 590 K \n",
      "133 | bert_model.encoder.layer.7.attention.self.value        | Linear               | 590 K \n",
      "134 | bert_model.encoder.layer.7.attention.self.dropout      | Dropout              | 0     \n",
      "135 | bert_model.encoder.layer.7.attention.output            | BertSelfOutput       | 592 K \n",
      "136 | bert_model.encoder.layer.7.attention.output.dense      | Linear               | 590 K \n",
      "137 | bert_model.encoder.layer.7.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "138 | bert_model.encoder.layer.7.attention.output.dropout    | Dropout              | 0     \n",
      "139 | bert_model.encoder.layer.7.intermediate                | BertIntermediate     | 2.4 M \n",
      "140 | bert_model.encoder.layer.7.intermediate.dense          | Linear               | 2.4 M \n",
      "141 | bert_model.encoder.layer.7.output                      | BertOutput           | 2.4 M \n",
      "142 | bert_model.encoder.layer.7.output.dense                | Linear               | 2.4 M \n",
      "143 | bert_model.encoder.layer.7.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "144 | bert_model.encoder.layer.7.output.dropout              | Dropout              | 0     \n",
      "145 | bert_model.encoder.layer.8                             | BertLayer            | 7.1 M \n",
      "146 | bert_model.encoder.layer.8.attention                   | BertAttention        | 2.4 M \n",
      "147 | bert_model.encoder.layer.8.attention.self              | BertSelfAttention    | 1.8 M \n",
      "148 | bert_model.encoder.layer.8.attention.self.query        | Linear               | 590 K \n",
      "149 | bert_model.encoder.layer.8.attention.self.key          | Linear               | 590 K \n",
      "150 | bert_model.encoder.layer.8.attention.self.value        | Linear               | 590 K \n",
      "151 | bert_model.encoder.layer.8.attention.self.dropout      | Dropout              | 0     \n",
      "152 | bert_model.encoder.layer.8.attention.output            | BertSelfOutput       | 592 K \n",
      "153 | bert_model.encoder.layer.8.attention.output.dense      | Linear               | 590 K \n",
      "154 | bert_model.encoder.layer.8.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "155 | bert_model.encoder.layer.8.attention.output.dropout    | Dropout              | 0     \n",
      "156 | bert_model.encoder.layer.8.intermediate                | BertIntermediate     | 2.4 M \n",
      "157 | bert_model.encoder.layer.8.intermediate.dense          | Linear               | 2.4 M \n",
      "158 | bert_model.encoder.layer.8.output                      | BertOutput           | 2.4 M \n",
      "159 | bert_model.encoder.layer.8.output.dense                | Linear               | 2.4 M \n",
      "160 | bert_model.encoder.layer.8.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "161 | bert_model.encoder.layer.8.output.dropout              | Dropout              | 0     \n",
      "162 | bert_model.encoder.layer.9                             | BertLayer            | 7.1 M \n",
      "163 | bert_model.encoder.layer.9.attention                   | BertAttention        | 2.4 M \n",
      "164 | bert_model.encoder.layer.9.attention.self              | BertSelfAttention    | 1.8 M \n",
      "165 | bert_model.encoder.layer.9.attention.self.query        | Linear               | 590 K \n",
      "166 | bert_model.encoder.layer.9.attention.self.key          | Linear               | 590 K \n",
      "167 | bert_model.encoder.layer.9.attention.self.value        | Linear               | 590 K \n",
      "168 | bert_model.encoder.layer.9.attention.self.dropout      | Dropout              | 0     \n",
      "169 | bert_model.encoder.layer.9.attention.output            | BertSelfOutput       | 592 K \n",
      "170 | bert_model.encoder.layer.9.attention.output.dense      | Linear               | 590 K \n",
      "171 | bert_model.encoder.layer.9.attention.output.LayerNorm  | LayerNorm            | 1.5 K \n",
      "172 | bert_model.encoder.layer.9.attention.output.dropout    | Dropout              | 0     \n",
      "173 | bert_model.encoder.layer.9.intermediate                | BertIntermediate     | 2.4 M \n",
      "174 | bert_model.encoder.layer.9.intermediate.dense          | Linear               | 2.4 M \n",
      "175 | bert_model.encoder.layer.9.output                      | BertOutput           | 2.4 M \n",
      "176 | bert_model.encoder.layer.9.output.dense                | Linear               | 2.4 M \n",
      "177 | bert_model.encoder.layer.9.output.LayerNorm            | LayerNorm            | 1.5 K \n",
      "178 | bert_model.encoder.layer.9.output.dropout              | Dropout              | 0     \n",
      "179 | bert_model.encoder.layer.10                            | BertLayer            | 7.1 M \n",
      "180 | bert_model.encoder.layer.10.attention                  | BertAttention        | 2.4 M \n",
      "181 | bert_model.encoder.layer.10.attention.self             | BertSelfAttention    | 1.8 M \n",
      "182 | bert_model.encoder.layer.10.attention.self.query       | Linear               | 590 K \n",
      "183 | bert_model.encoder.layer.10.attention.self.key         | Linear               | 590 K \n",
      "184 | bert_model.encoder.layer.10.attention.self.value       | Linear               | 590 K \n",
      "185 | bert_model.encoder.layer.10.attention.self.dropout     | Dropout              | 0     \n",
      "186 | bert_model.encoder.layer.10.attention.output           | BertSelfOutput       | 592 K \n",
      "187 | bert_model.encoder.layer.10.attention.output.dense     | Linear               | 590 K \n",
      "188 | bert_model.encoder.layer.10.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "189 | bert_model.encoder.layer.10.attention.output.dropout   | Dropout              | 0     \n",
      "190 | bert_model.encoder.layer.10.intermediate               | BertIntermediate     | 2.4 M \n",
      "191 | bert_model.encoder.layer.10.intermediate.dense         | Linear               | 2.4 M \n",
      "192 | bert_model.encoder.layer.10.output                     | BertOutput           | 2.4 M \n",
      "193 | bert_model.encoder.layer.10.output.dense               | Linear               | 2.4 M \n",
      "194 | bert_model.encoder.layer.10.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "195 | bert_model.encoder.layer.10.output.dropout             | Dropout              | 0     \n",
      "196 | bert_model.encoder.layer.11                            | BertLayer            | 7.1 M \n",
      "197 | bert_model.encoder.layer.11.attention                  | BertAttention        | 2.4 M \n",
      "198 | bert_model.encoder.layer.11.attention.self             | BertSelfAttention    | 1.8 M \n",
      "199 | bert_model.encoder.layer.11.attention.self.query       | Linear               | 590 K \n",
      "200 | bert_model.encoder.layer.11.attention.self.key         | Linear               | 590 K \n",
      "201 | bert_model.encoder.layer.11.attention.self.value       | Linear               | 590 K \n",
      "202 | bert_model.encoder.layer.11.attention.self.dropout     | Dropout              | 0     \n",
      "203 | bert_model.encoder.layer.11.attention.output           | BertSelfOutput       | 592 K \n",
      "204 | bert_model.encoder.layer.11.attention.output.dense     | Linear               | 590 K \n",
      "205 | bert_model.encoder.layer.11.attention.output.LayerNorm | LayerNorm            | 1.5 K \n",
      "206 | bert_model.encoder.layer.11.attention.output.dropout   | Dropout              | 0     \n",
      "207 | bert_model.encoder.layer.11.intermediate               | BertIntermediate     | 2.4 M \n",
      "208 | bert_model.encoder.layer.11.intermediate.dense         | Linear               | 2.4 M \n",
      "209 | bert_model.encoder.layer.11.output                     | BertOutput           | 2.4 M \n",
      "210 | bert_model.encoder.layer.11.output.dense               | Linear               | 2.4 M \n",
      "211 | bert_model.encoder.layer.11.output.LayerNorm           | LayerNorm            | 1.5 K \n",
      "212 | bert_model.encoder.layer.11.output.dropout             | Dropout              | 0     \n",
      "213 | bert_model.pooler                                      | BertPooler           | 590 K \n",
      "214 | bert_model.pooler.dense                                | Linear               | 590 K \n",
      "215 | bert_model.pooler.activation                           | Tanh                 | 0     \n",
      "216 | classifier                                             | TokenClassifier      | 603 K \n",
      "217 | classifier.dropout                                     | Dropout              | 0     \n",
      "218 | classifier.mlp                                         | MultiLayerPerceptron | 603 K \n",
      "219 | classifier.mlp.layer0                                  | Linear               | 590 K \n",
      "220 | classifier.mlp.layer2                                  | Linear               | 13.1 K\n",
      "221 | loss                                                   | CrossEntropyLoss     | 0     \n",
      "222 | classification_report                                  | ClassificationReport | 0     \n",
      "--------------------------------------------------------------------------------------------------\n",
      "110 M     Trainable params\n",
      "0         Non-trainable params\n",
      "110 M     Total params\n",
      "Validation sanity check:  50%|██████████          | 1/2 [00:00<00:00,  1.23it/s][NeMo I 2022-04-27 08:12:23 token_classification_model:178] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         96.73      89.97      93.23        329\n",
      "    B-Amenity (label_id: 1)                                 64.29      69.23      66.67         26\n",
      "    B-Cuisine (label_id: 2)                                  0.00       0.00       0.00          0\n",
      "    B-Dish (label_id: 3)                                    77.78      19.44      31.11         36\n",
      "    B-Hours (label_id: 4)                                   64.29      75.00      69.23         12\n",
      "    B-Location (label_id: 5)                                89.58      86.00      87.76         50\n",
      "    B-Price (label_id: 6)                                   80.00     100.00      88.89          8\n",
      "    B-Rating (label_id: 7)                                  72.73      88.89      80.00          9\n",
      "    B-Restaurant_Name (label_id: 8)                         85.71      85.71      85.71          7\n",
      "    I-Amenity (label_id: 9)                                 65.52      79.17      71.70         24\n",
      "    I-Cuisine (label_id: 10)                                 0.00       0.00       0.00          0\n",
      "    I-Dish (label_id: 11)                                   50.00      14.29      22.22          7\n",
      "    I-Hours (label_id: 12)                                  71.43     100.00      83.33         20\n",
      "    I-Location (label_id: 13)                               85.71      89.36      87.50         47\n",
      "    I-Price (label_id: 14)                                 100.00      75.00      85.71          4\n",
      "    I-Rating (label_id: 15)                                100.00     100.00     100.00          4\n",
      "    I-Restaurant_Name (label_id: 16)                       100.00      90.00      94.74         10\n",
      "    -------------------\n",
      "    micro avg                                               83.14      83.14      83.14        593\n",
      "    macro avg                                               80.25      77.47      76.52        593\n",
      "    weighted avg                                            88.74      83.14      84.52        593\n",
      "    \n",
      "Epoch 0:  83%|▊| 240/288 [00:30<00:06,  7.92it/s, loss=0.15, val_loss=0.622, lr=\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 0:  84%|▊| 242/288 [00:30<00:05,  7.95it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0:  85%|▊| 245/288 [00:30<00:05,  8.02it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0:  86%|▊| 248/288 [00:30<00:04,  8.09it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0:  87%|▊| 251/288 [00:30<00:04,  8.16it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0:  88%|▉| 254/288 [00:30<00:04,  8.23it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0:  89%|▉| 257/288 [00:30<00:03,  8.30it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0:  90%|▉| 260/288 [00:31<00:03,  8.36it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0:  91%|▉| 263/288 [00:31<00:02,  8.43it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0:  92%|▉| 266/288 [00:31<00:02,  8.50it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0:  93%|▉| 269/288 [00:31<00:02,  8.56it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0:  94%|▉| 272/288 [00:31<00:01,  8.63it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0:  95%|▉| 275/288 [00:31<00:01,  8.70it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0:  97%|▉| 278/288 [00:31<00:01,  8.76it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0:  98%|▉| 281/288 [00:31<00:00,  8.82it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0:  99%|▉| 284/288 [00:31<00:00,  8.89it/s, loss=0.15, val_loss=0.622, lr=\u001b[A\n",
      "Epoch 0: 100%|▉| 287/288 [00:32<00:00,  8.95it/s, loss=0.15, val_loss=0.622, lr=\u001b[A[NeMo I 2022-04-27 08:12:55 token_classification_model:178] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         97.13      94.72      95.91       8659\n",
      "    B-Amenity (label_id: 1)                                 73.45      77.86      75.59        533\n",
      "    B-Cuisine (label_id: 2)                                  0.00       0.00       0.00          0\n",
      "    B-Dish (label_id: 3)                                    91.58      92.80      92.19        820\n",
      "    B-Hours (label_id: 4)                                   67.38      74.06      70.56        212\n",
      "    B-Location (label_id: 5)                                89.25      91.01      90.12        812\n",
      "    B-Price (label_id: 6)                                   84.66      87.13      85.88        171\n",
      "    B-Rating (label_id: 7)                                  74.79      88.56      81.09        201\n",
      "    B-Restaurant_Name (label_id: 8)                         95.61      92.04      93.79        402\n",
      "    I-Amenity (label_id: 9)                                 75.96      83.21      79.42        524\n",
      "    I-Cuisine (label_id: 10)                                 0.00       0.00       0.00          0\n",
      "    I-Dish (label_id: 11)                                   77.29      82.42      79.77        256\n",
      "    I-Hours (label_id: 12)                                  83.54      91.19      87.20        295\n",
      "    I-Location (label_id: 13)                               86.48      90.10      88.25        788\n",
      "    I-Price (label_id: 14)                                  72.97      81.82      77.14         66\n",
      "    I-Rating (label_id: 15)                                 82.50      79.20      80.82        125\n",
      "    I-Restaurant_Name (label_id: 16)                        91.62      86.48      88.98        392\n",
      "    -------------------\n",
      "    micro avg                                               91.81      91.81      91.81      14256\n",
      "    macro avg                                               82.95      86.17      84.45      14256\n",
      "    weighted avg                                            92.13      91.81      91.93      14256\n",
      "    \n",
      "Epoch 0: 100%|█| 288/288 [00:32<00:00,  8.95it/s, loss=0.15, val_loss=0.257, lr=\n",
      "                                                                                \u001b[AEpoch 0, global step 239: val_loss reached 0.25750 (best 0.25750), saving model to \"/workspace/mount/results/bert-base-finetuned_ner/checkpoints/finetuned-model---val_loss=0.26-epoch=0.ckpt\" as top 3\n",
      "Epoch 0, global step 239: val_loss reached 0.25750 (best 0.25750), saving model to \"/workspace/mount/results/bert-base-finetuned_ner/checkpoints/finetuned-model---val_loss=0.26-epoch=0.ckpt\" as top 3\n",
      "Epoch 1:  83%|▊| 240/288 [00:30<00:06,  7.88it/s, loss=0.137, val_loss=0.257, lr\n",
      "Validating: 0it [00:00, ?it/s]\u001b[A\n",
      "Epoch 1:  84%|▊| 242/288 [00:30<00:05,  7.90it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1:  85%|▊| 245/288 [00:30<00:05,  7.97it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1:  86%|▊| 248/288 [00:30<00:04,  8.04it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1:  87%|▊| 251/288 [00:30<00:04,  8.11it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1:  88%|▉| 254/288 [00:31<00:04,  8.18it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1:  89%|▉| 257/288 [00:31<00:03,  8.25it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1:  90%|▉| 260/288 [00:31<00:03,  8.32it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1:  91%|▉| 263/288 [00:31<00:02,  8.39it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1:  92%|▉| 266/288 [00:31<00:02,  8.45it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1:  93%|▉| 269/288 [00:31<00:02,  8.52it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1:  94%|▉| 272/288 [00:31<00:01,  8.59it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1:  95%|▉| 275/288 [00:31<00:01,  8.65it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1:  97%|▉| 278/288 [00:31<00:01,  8.72it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1:  98%|▉| 281/288 [00:31<00:00,  8.78it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1:  99%|▉| 284/288 [00:32<00:00,  8.85it/s, loss=0.137, val_loss=0.257, lr\u001b[A\n",
      "Epoch 1: 100%|▉| 287/288 [00:32<00:00,  8.91it/s, loss=0.137, val_loss=0.257, lr\u001b[A[NeMo I 2022-04-27 08:13:51 token_classification_model:178] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         97.15      94.85      95.99       8659\n",
      "    B-Amenity (label_id: 1)                                 69.31      80.49      74.48        533\n",
      "    B-Cuisine (label_id: 2)                                  0.00       0.00       0.00          0\n",
      "    B-Dish (label_id: 3)                                    92.96      91.83      92.39        820\n",
      "    B-Hours (label_id: 4)                                   67.78      76.42      71.84        212\n",
      "    B-Location (label_id: 5)                                89.14      88.92      89.03        812\n",
      "    B-Price (label_id: 6)                                   84.07      89.47      86.69        171\n",
      "    B-Rating (label_id: 7)                                  78.44      85.07      81.62        201\n",
      "    B-Restaurant_Name (label_id: 8)                         95.62      92.29      93.92        402\n",
      "    I-Amenity (label_id: 9)                                 75.73      83.97      79.64        524\n",
      "    I-Cuisine (label_id: 10)                                 0.00       0.00       0.00          0\n",
      "    I-Dish (label_id: 11)                                   73.53      87.89      80.07        256\n",
      "    I-Hours (label_id: 12)                                  84.26      92.54      88.21        295\n",
      "    I-Location (label_id: 13)                               89.87      87.82      88.83        788\n",
      "    I-Price (label_id: 14)                                  75.00      77.27      76.12         66\n",
      "    I-Rating (label_id: 15)                                 86.61      77.60      81.86        125\n",
      "    I-Restaurant_Name (label_id: 16)                        91.47      87.50      89.44        392\n",
      "    -------------------\n",
      "    micro avg                                               91.86      91.86      91.86      14256\n",
      "    macro avg                                               83.39      86.26      84.67      14256\n",
      "    weighted avg                                            92.28      91.86      92.01      14256\n",
      "    \n",
      "Epoch 1: 100%|█| 288/288 [00:32<00:00,  8.91it/s, loss=0.137, val_loss=0.271, lr\n",
      "                                                                                \u001b[AEpoch 1, global step 479: val_loss reached 0.27140 (best 0.25750), saving model to \"/workspace/mount/results/bert-base-finetuned_ner/checkpoints/finetuned-model---val_loss=0.27-epoch=1.ckpt\" as top 3\n",
      "Epoch 1, global step 479: val_loss reached 0.27140 (best 0.25750), saving model to \"/workspace/mount/results/bert-base-finetuned_ner/checkpoints/finetuned-model---val_loss=0.27-epoch=1.ckpt\" as top 3\n",
      "Epoch 1: 100%|█| 288/288 [00:52<00:00,  5.53it/s, loss=0.137, val_loss=0.271, lrSaving latest checkpoint...\n",
      "Saving latest checkpoint...\n",
      "Epoch 1: 100%|█| 288/288 [01:01<00:00,  4.71it/s, loss=0.137, val_loss=0.271, lr\n",
      "[NeMo I 2022-04-27 08:14:42 finetune:125] Experiment logs saved to '/workspace/mount/results/bert-base-finetuned_ner'\n",
      "[NeMo I 2022-04-27 08:14:42 finetune:126] Fine-tuned model saved to '/workspace/mount/results/bert-base-finetuned_ner/checkpoints/finetuned-model.tlt'\n",
      "2022-04-27 08:14:44,227 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# TAO NER model finetuning\n",
    "!tao token_classification finetune \\\n",
    "   -e $SPECS_DIR/token_classification/finetune.yaml \\\n",
    "   -r $RESULTS_DIR/bert-base-finetuned_ner/ \\\n",
    "   -m $RESULTS_DIR/bert-base_ner/checkpoints/trained-model.tlt \\\n",
    "   -g 1 \\\n",
    "   data_dir={destination_mount}/data/restaurant_finetune \\\n",
    "   trainer.max_epochs=2 \\\n",
    "   trainer.amp_level=\"O1\" \\\n",
    "   trainer.precision=16 \\\n",
    "   -k $KEY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5.1 Exercise: Evaluate the Fine-Tuned Model\n",
    "\n",
    "Based on what you've learned, evaluate the performance of the fine-tuned NER model. If you get stuck, you can look at the [solution](solutions/ex7.5.1.ipynb).  If you are unsure of the location of the fine-tuned model, check the outputs from the fine-tuning or the logs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 08:18:18,441 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-04-27 08:18:18,564 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-04-27 08:18:22 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-04-27 08:18:26 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-04-27 08:18:27 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: /workspace/mount/results/bert-base-finetuned_ner/checkpoints/finetuned-model.tlt\n",
      "    data_dir: /workspace/mount/data/restaurant_finetune\n",
      "    exp_manager:\n",
      "      explicit_log_dir: /workspace/mount/results/bert-base-finetuned_ner/evaluate\n",
      "      exp_dir: null\n",
      "      name: null\n",
      "      version: null\n",
      "      use_datetime_version: true\n",
      "      resume_if_exists: false\n",
      "      resume_past_end: false\n",
      "      resume_ignore_no_checkpoint: false\n",
      "      create_tensorboard_logger: false\n",
      "      summary_writer_kwargs: null\n",
      "      create_wandb_logger: false\n",
      "      wandb_logger_kwargs: null\n",
      "      create_checkpoint_callback: false\n",
      "      checkpoint_callback_params:\n",
      "        filepath: null\n",
      "        monitor: val_loss\n",
      "        verbose: true\n",
      "        save_last: true\n",
      "        save_top_k: 3\n",
      "        save_weights_only: false\n",
      "        mode: auto\n",
      "        period: 1\n",
      "        prefix: null\n",
      "        postfix: .nemo\n",
      "        save_best_model: false\n",
      "      files_to_copy: null\n",
      "    trainer:\n",
      "      logger: false\n",
      "      checkpoint_callback: false\n",
      "      callbacks: null\n",
      "      default_root_dir: null\n",
      "      gradient_clip_val: 0.0\n",
      "      process_position: 0\n",
      "      num_nodes: 1\n",
      "      num_processes: 1\n",
      "      gpus: 1\n",
      "      auto_select_gpus: false\n",
      "      tpu_cores: null\n",
      "      log_gpu_memory: null\n",
      "      progress_bar_refresh_rate: 1\n",
      "      overfit_batches: 0.0\n",
      "      track_grad_norm: -1\n",
      "      check_val_every_n_epoch: 1\n",
      "      fast_dev_run: false\n",
      "      accumulate_grad_batches: 1\n",
      "      max_epochs: 1000\n",
      "      min_epochs: 1\n",
      "      max_steps: null\n",
      "      min_steps: null\n",
      "      limit_train_batches: 1.0\n",
      "      limit_val_batches: 1.0\n",
      "      limit_test_batches: 1.0\n",
      "      val_check_interval: 1.0\n",
      "      flush_logs_every_n_steps: 100\n",
      "      log_every_n_steps: 50\n",
      "      accelerator: ddp\n",
      "      sync_batchnorm: false\n",
      "      precision: 32\n",
      "      weights_summary: full\n",
      "      weights_save_path: null\n",
      "      num_sanity_val_steps: 2\n",
      "      truncated_bptt_steps: null\n",
      "      resume_from_checkpoint: null\n",
      "      profiler: null\n",
      "      benchmark: false\n",
      "      deterministic: false\n",
      "      reload_dataloaders_every_epoch: false\n",
      "      auto_lr_find: false\n",
      "      replace_sampler_ddp: true\n",
      "      terminate_on_nan: false\n",
      "      auto_scale_batch_size: false\n",
      "      prepare_data_per_node: true\n",
      "      amp_backend: native\n",
      "      amp_level: O2\n",
      "    test_ds:\n",
      "      batch_size: 1\n",
      "      text_file: text_dev.txt\n",
      "      labels_file: labels_dev.txt\n",
      "      shuffle: false\n",
      "      num_samples: -1\n",
      "    encryption_key: '****'\n",
      "    \n",
      "GPU available: True, used: True\n",
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "[NeMo I 2022-04-27 08:18:27 exp_manager:194] Experiments will be logged at /workspace/mount/results/bert-base-finetuned_ner/evaluate\n",
      "[NeMo W 2022-04-27 08:18:29 modelPT:193] Using /tmp/tmp1a2qloue/tokenizer.vocab_file instead of tokenizer.vocab_file.\n",
      "Lock 140264240505520 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100%|██████████████████████████████| 570/570 [00:00<00:00, 509kB/s]\n",
      "Lock 140264240505520 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 140264238871024 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100%|███████████████████████████| 232k/232k [00:00<00:00, 50.8MB/s]\n",
      "Lock 140264238871024 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 140264238872560 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100%|███████████████████████████| 28.0/28.0 [00:00<00:00, 24.7kB/s]\n",
      "Lock 140264238872560 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 140264238874528 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100%|███████████████████████████| 466k/466k [00:00<00:00, 67.3MB/s]\n",
      "Lock 140264238874528 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-04-27 08:18:29 modelPT:1202] World size can only be set by PyTorch Lightning Trainer.\n",
      "Lock 140264240488400 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100%|███████████████████████████| 440M/440M [00:04<00:00, 92.4MB/s]\n",
      "Lock 140264240488400 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo I 2022-04-27 08:18:43 token_classification_model:105] Setting model.dataset.data_dir to /workspace/mount/data/restaurant_finetune.\n",
      "[NeMo I 2022-04-27 08:18:43 token_classification_utils:54] Processing /workspace/mount/data/restaurant_finetune/labels_dev.txt\n",
      "[NeMo I 2022-04-27 08:18:43 token_classification_utils:74] Using provided labels mapping {'O': 0, 'B-Amenity': 1, 'B-Cuisine': 2, 'B-Dish': 3, 'B-Hours': 4, 'B-Location': 5, 'B-Price': 6, 'B-Rating': 7, 'B-Restaurant_Name': 8, 'I-Amenity': 9, 'I-Cuisine': 10, 'I-Dish': 11, 'I-Hours': 12, 'I-Location': 13, 'I-Price': 14, 'I-Rating': 15, 'I-Restaurant_Name': 16}\n",
      "[NeMo I 2022-04-27 08:18:43 token_classification_utils:96] /workspace/mount/data/restaurant_finetune/labels_dev_label_stats.tsv found, skipping stats calculation.\n",
      "[NeMo I 2022-04-27 08:18:43 token_classification_dataset:272] features restored from /workspace/mount/data/restaurant_finetune/cached_text_dev.txt_BertTokenizer_128_30522_-1\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "initializing ddp: GLOBAL_RANK: 0, MEMBER: 1/1\n",
      "Added key: store_based_barrier_key:1 to store for rank: 0\n",
      "Testing: 100%|█████████████████████████████▉| 1520/1521 [00:45<00:00, 34.38it/s][NeMo I 2022-04-27 08:19:28 token_classification_model:202] \n",
      "    label                                                precision    recall       f1           support   \n",
      "    O (label_id: 0)                                         97.15      94.84      95.98       8659\n",
      "    B-Amenity (label_id: 1)                                 69.31      80.49      74.48        533\n",
      "    B-Cuisine (label_id: 2)                                  0.00       0.00       0.00          0\n",
      "    B-Dish (label_id: 3)                                    92.96      91.83      92.39        820\n",
      "    B-Hours (label_id: 4)                                   67.50      76.42      71.68        212\n",
      "    B-Location (label_id: 5)                                89.14      88.92      89.03        812\n",
      "    B-Price (label_id: 6)                                   84.07      89.47      86.69        171\n",
      "    B-Rating (label_id: 7)                                  78.44      85.07      81.62        201\n",
      "    B-Restaurant_Name (label_id: 8)                         95.62      92.29      93.92        402\n",
      "    I-Amenity (label_id: 9)                                 75.73      83.97      79.64        524\n",
      "    I-Cuisine (label_id: 10)                                 0.00       0.00       0.00          0\n",
      "    I-Dish (label_id: 11)                                   73.53      87.89      80.07        256\n",
      "    I-Hours (label_id: 12)                                  84.26      92.54      88.21        295\n",
      "    I-Location (label_id: 13)                               89.87      87.82      88.83        788\n",
      "    I-Price (label_id: 14)                                  75.00      77.27      76.12         66\n",
      "    I-Rating (label_id: 15)                                 86.61      77.60      81.86        125\n",
      "    I-Restaurant_Name (label_id: 16)                        91.47      87.50      89.44        392\n",
      "    -------------------\n",
      "    micro avg                                               91.85      91.85      91.85      14256\n",
      "    macro avg                                               83.38      86.26      84.66      14256\n",
      "    weighted avg                                            92.27      91.85      92.00      14256\n",
      "    \n",
      "Testing: 100%|██████████████████████████████| 1521/1521 [00:45<00:00, 33.70it/s]\n",
      "--------------------------------------------------------------------------------\n",
      "DATALOADER:0 TEST RESULTS\n",
      "{'f1': tensor(84.6636, device='cuda:0'),\n",
      " 'precision': tensor(83.3761, device='cuda:0'),\n",
      " 'recall': tensor(86.2610, device='cuda:0'),\n",
      " 'test_loss': tensor(0.2513, device='cuda:0')}\n",
      "--------------------------------------------------------------------------------\n",
      "[NeMo I 2022-04-27 08:19:28 evaluate:92] Experiment logs saved to '/workspace/mount/results/bert-base-finetuned_ner/evaluate'\n",
      "2022-04-27 08:19:30,203 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# TODO evaluate the fine-tuned model\n",
    "!tao token_classification evaluate  \\\n",
    "   -e $SPECS_DIR/token_classification/evaluate.yaml \\\n",
    "   -r $RESULTS_DIR/bert-base-finetuned_ner/evaluate \\\n",
    "   -g 1 \\\n",
    "   -m $RESULTS_DIR/bert-base-finetuned_ner/checkpoints/finetuned-model.tlt \\\n",
    "   -k $KEY \\\n",
    "   data_dir={destination_mount}/data/restaurant_finetune"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the evaluation results, you can either continue fine-tuning the model for more epochs, or move on to inference."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5.2 Inference on the Fine-Tuned Model\n",
    "\n",
    "Try inference on the NER fine-tuned model using a few sentences within the restaurant context. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "# Copyright (c) 2021, NVIDIA CORPORATION. All rights reserved.\n",
      "# TAO Spec file for inference using a previously pretrained BERT model for a text classification task.\n",
      "\n",
      "# \"Simulate\" user input: batch with four samples.\n",
      "input_batch:\n",
      "  - \"I would like to order a pizza for 6pm\"\n",
      "  - \"what sauce is in Pilau.\"\n",
      "  - \"mhh nice Swahili dish.\"\n",
      "  - \"any good cheap kenyan restaurants nearby\"\n",
      "  - \"any good ice cream parlors around\"\n",
      "  - \"any good place to get a pie at an affordable price\"\n"
     ]
    }
   ],
   "source": [
    "!cat /dli/task/tao/specs/token_classification/infer_restaurant.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference can be done using the command `tao token_classification infer` as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 08:20:16,124 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-04-27 08:20:16,244 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-04-27 08:20:19 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-04-27 08:20:23 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-04-27 08:20:24 tlt_logging:20] Experiment configuration:\n",
      "    exp_manager:\n",
      "      task_name: infer\n",
      "      explicit_log_dir: /workspace/mount/results/bert-base-finetuned_ner/\n",
      "    restore_from: /workspace/mount/results/bert-base-finetuned_ner/checkpoints/finetuned-model.tlt\n",
      "    input_batch:\n",
      "    - I would like to order a pizza for 6pm\n",
      "    - what sauce is in Pilau.\n",
      "    - mhh nice Swahili dish.\n",
      "    - any good cheap kenyan restaurants nearby\n",
      "    - any good ice cream parlors around\n",
      "    - any good place to get a pie at an affordable price\n",
      "    encryption_key: '****'\n",
      "    \n",
      "[NeMo W 2022-04-27 08:20:24 exp_manager:26] Exp_manager is logging to `/workspace/mount/results/bert-base-finetuned_ner/``, but it already exists.\n",
      "[NeMo W 2022-04-27 08:20:26 modelPT:193] Using /tmp/tmpt247j8z1/tokenizer.vocab_file instead of tokenizer.vocab_file.\n",
      "Lock 140307590582624 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100%|██████████████████████████████| 570/570 [00:00<00:00, 523kB/s]\n",
      "Lock 140307590582624 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 140307590582816 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100%|███████████████████████████| 232k/232k [00:00<00:00, 57.5MB/s]\n",
      "Lock 140307590582816 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 140307590558144 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100%|███████████████████████████| 28.0/28.0 [00:00<00:00, 25.0kB/s]\n",
      "Lock 140307590558144 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 140307590949808 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100%|███████████████████████████| 466k/466k [00:00<00:00, 72.6MB/s]\n",
      "Lock 140307590949808 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-04-27 08:20:26 modelPT:1202] World size can only be set by PyTorch Lightning Trainer.\n",
      "Lock 140307590538096 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100%|███████████████████████████| 440M/440M [00:05<00:00, 86.2MB/s]\n",
      "Lock 140307590538096 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo I 2022-04-27 08:20:41 token_classification_dataset:116] Setting Max Seq length to: 13\n",
      "[NeMo I 2022-04-27 08:20:41 data_preprocessing:295] Some stats of the lengths of the sequences:\n",
      "[NeMo I 2022-04-27 08:20:41 data_preprocessing:297] Min: 8 |                  Max: 13 |                  Mean: 10.166666666666666 |                  Median: 9.5\n",
      "[NeMo I 2022-04-27 08:20:41 data_preprocessing:303] 75 percentile: 11.50\n",
      "[NeMo I 2022-04-27 08:20:41 data_preprocessing:304] 99 percentile: 12.95\n",
      "[NeMo W 2022-04-27 08:20:41 token_classification_dataset:145] 0 are longer than 13\n",
      "[NeMo I 2022-04-27 08:20:41 token_classification_dataset:148] *** Example ***\n",
      "[NeMo I 2022-04-27 08:20:41 token_classification_dataset:149] i: 0\n",
      "[NeMo I 2022-04-27 08:20:41 token_classification_dataset:150] subtokens: [CLS] i would like to order a pizza for 6 ##pm [SEP]\n",
      "[NeMo I 2022-04-27 08:20:41 token_classification_dataset:151] loss_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      "[NeMo I 2022-04-27 08:20:41 token_classification_dataset:152] input_mask: 1 1 1 1 1 1 1 1 1 1 1 1 0\n",
      "[NeMo I 2022-04-27 08:20:41 token_classification_dataset:153] subtokens_mask: 0 1 1 1 1 1 1 1 1 1 0 0 0\n",
      "[NeMo I 2022-04-27 08:20:42 infer:74] Query  : I would like to order a pizza for 6pm\n",
      "[NeMo I 2022-04-27 08:20:42 infer:75] Results: I would like to order a pizza[B-Dish] for 6pm[B-Hours]\n",
      "[NeMo I 2022-04-27 08:20:42 infer:74] Query  : what sauce is in Pilau.\n",
      "[NeMo I 2022-04-27 08:20:42 infer:75] Results: what sauce[B-Dish] is in Pilau[B-Dish].\n",
      "[NeMo I 2022-04-27 08:20:42 infer:74] Query  : mhh nice Swahili dish.\n",
      "[NeMo I 2022-04-27 08:20:42 infer:75] Results: mhh nice[B-Rating] Swahili[B-Dish] dish[I-Dish].\n",
      "[NeMo I 2022-04-27 08:20:42 infer:74] Query  : any good cheap kenyan restaurants nearby\n",
      "[NeMo I 2022-04-27 08:20:42 infer:75] Results: any good[B-Rating] cheap[I-Price] kenyan[B-Dish] restaurants nearby[B-Location]\n",
      "[NeMo I 2022-04-27 08:20:42 infer:74] Query  : any good ice cream parlors around\n",
      "[NeMo I 2022-04-27 08:20:42 infer:75] Results: any good[B-Rating] ice[B-Dish] cream[I-Dish] parlors[I-Dish] around[B-Location]\n",
      "[NeMo I 2022-04-27 08:20:42 infer:74] Query  : any good place to get a pie at an affordable price\n",
      "[NeMo I 2022-04-27 08:20:42 infer:75] Results: any good[B-Rating] place to get a pie[B-Dish] at an affordable[B-Price] price\n",
      "[NeMo I 2022-04-27 08:20:42 infer:78] Experiment logs saved to '/workspace/mount/results/bert-base-finetuned_ner'\n",
      "2022-04-27 08:20:43,298 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# TAO fine-tuned NER inference \n",
    "!tao token_classification infer \\\n",
    "    -e $SPECS_DIR/token_classification/infer_restaurant.yaml \\\n",
    "    -g 1 \\\n",
    "    -m $RESULTS_DIR/bert-base-finetuned_ner/checkpoints/finetuned-model.tlt \\\n",
    "    -k $KEY \\\n",
    "    -r $RESULTS_DIR/bert-base-finetuned_ner/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NeMo I 2022-04-27 08:20:42 infer:75] Results: I would like to order a pizza[B-Dish] for 6pm[B-Hours]\n",
      "[NeMo I 2022-04-27 08:20:42 infer:75] Results: what sauce[B-Dish] is in Pilau[B-Dish].\n",
      "[NeMo I 2022-04-27 08:20:42 infer:75] Results: mhh nice[B-Rating] Swahili[B-Dish] dish[I-Dish].\n",
      "[NeMo I 2022-04-27 08:20:42 infer:75] Results: any good[B-Rating] cheap[I-Price] kenyan[B-Dish] restaurants nearby[B-Location]\n",
      "[NeMo I 2022-04-27 08:20:42 infer:75] Results: any good[B-Rating] ice[B-Dish] cream[I-Dish] parlors[I-Dish] around[B-Location]\n",
      "[NeMo I 2022-04-27 08:20:42 infer:75] Results: any good[B-Rating] place to get a pie[B-Dish] at an affordable[B-Price] price\n"
     ]
    }
   ],
   "source": [
    "!grep Results $source_mount/results/bert-base-finetuned_ner/infer.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This model should be able to recognize several useful enties with the restaurant context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 7.6 Export for Deployment\n",
    "With TAO, we can export the fine-tuned model in a format that can be deployed using NVIDIA Riva."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 08:22:11,873 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-04-27 08:22:11,991 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-04-27 08:22:15 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-04-27 08:22:19 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-04-27 08:22:19 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: /workspace/mount/results/bert-base-finetuned_ner/checkpoints/finetuned-model.tlt\n",
      "    export_to: exported-model-NER.riva\n",
      "    export_format: RIVA\n",
      "    exp_manager:\n",
      "      task_name: export\n",
      "      explicit_log_dir: /workspace/mount/results/export/\n",
      "    encryption_key: '********'\n",
      "    \n",
      "[NeMo W 2022-04-27 08:22:21 modelPT:193] Using /tmp/tmp0d6rf20q/tokenizer.vocab_file instead of tokenizer.vocab_file.\n",
      "Lock 140564201861472 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100%|██████████████████████████████| 570/570 [00:00<00:00, 499kB/s]\n",
      "Lock 140564201861472 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 140564201862960 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100%|███████████████████████████| 232k/232k [00:00<00:00, 44.4MB/s]\n",
      "Lock 140564201862960 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 140564201905936 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100%|███████████████████████████| 28.0/28.0 [00:00<00:00, 27.3kB/s]\n",
      "Lock 140564201905936 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 140564201905936 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100%|███████████████████████████| 466k/466k [00:00<00:00, 55.3MB/s]\n",
      "Lock 140564201905936 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-04-27 08:22:22 modelPT:1202] World size can only be set by PyTorch Lightning Trainer.\n",
      "Lock 140564201953408 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100%|███████████████████████████| 440M/440M [00:05<00:00, 83.7MB/s]\n",
      "Lock 140564201953408 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo I 2022-04-27 08:22:36 export:54] Model restored from '/workspace/mount/results/bert-base-finetuned_ner/checkpoints/finetuned-model.tlt'\n",
      "Could not retrieve the artifact tokenizer.vocab_file used in tokenizer.vocab_file\n",
      "[NeMo I 2022-04-27 08:22:59 export:69] Experiment logs saved to '/workspace/mount/results/export'\n",
      "[NeMo I 2022-04-27 08:22:59 export:70] Exported model to '/workspace/mount/results/export/exported-model-NER.riva'\n",
      "[NeMo I 2022-04-27 08:23:01 export:78] Exported model is compliant with Riva\n",
      "2022-04-27 08:23:02,487 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# TAO export to Riva\n",
    "!tao token_classification export \\\n",
    "     -e $SPECS_DIR/token_classification/export.yaml \\\n",
    "     -r $RESULTS_DIR/export/ \\\n",
    "     -m $RESULTS_DIR/bert-base-finetuned_ner/checkpoints/finetuned-model.tlt \\\n",
    "     -k $KEY \\\n",
    "     export_to=exported-model-NER.riva \\\n",
    "     export_format=RIVA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verify that your model was exported as expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/dli/task/tao/results/export/exported-model-NER.riva\n"
     ]
    }
   ],
   "source": [
    "!ls /dli/task/tao/results/export/exported-model-NER.riva"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.6.1 Exercise: NER Model Export to ONNX\n",
    "\n",
    "Using what you've learned, export the fine-tuned NER model to ONNX format.  Name the final model `exported-model-NER.eonnx`.  If you get stuck, you can look at the [solution](solutions/ex7.6.1.ipynb).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-04-27 08:24:15,648 [INFO] root: Registry: ['nvcr.io']\n",
      "2022-04-27 08:24:15,769 [WARNING] tlt.components.docker_handler.docker_handler: \n",
      "Docker will run the commands as root. If you would like to retain your\n",
      "local host permissions, please add the \"user\":\"UID:GID\" in the\n",
      "DockerOptions portion of the \"/root/.tao_mounts.json\" file. You can obtain your\n",
      "users UID and GID by using the \"id -u\" and \"id -g\" commands on the\n",
      "terminal.\n",
      "[NeMo W 2022-04-27 08:24:19 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "INFO: Generating new fontManager, this may take some time...\n",
      "[NeMo W 2022-04-27 08:24:22 experimental:27] Module <class 'nemo.collections.nlp.modules.common.megatron.megatron_bert.MegatronBertEncoder'> is experimental, not ready for production and is not fully supported. Use at your own risk.\n",
      "[NeMo I 2022-04-27 08:24:23 tlt_logging:20] Experiment configuration:\n",
      "    restore_from: /workspace/mount/results/bert-base-finetuned_ner/checkpoints/finetuned-model.tlt\n",
      "    export_to: exported-model-NER.eonnx\n",
      "    export_format: ONNX\n",
      "    exp_manager:\n",
      "      task_name: export\n",
      "      explicit_log_dir: /workspace/mount/results/export/\n",
      "    encryption_key: '********'\n",
      "    \n",
      "[NeMo W 2022-04-27 08:24:23 exp_manager:26] Exp_manager is logging to `/workspace/mount/results/export/``, but it already exists.\n",
      "[NeMo W 2022-04-27 08:24:25 modelPT:193] Using /tmp/tmp_70yn_08/tokenizer.vocab_file instead of tokenizer.vocab_file.\n",
      "Lock 139811070546416 acquired on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Downloading: 100%|██████████████████████████████| 570/570 [00:00<00:00, 509kB/s]\n",
      "Lock 139811070546416 released on /root/.cache/huggingface/transformers/3c61d016573b14f7f008c02c4e51a366c67ab274726fe2910691e2a761acf43e.37395cee442ab11005bcd270f3c34464dc1704b715b5d7d52b1a461abe3b9e4e.lock\n",
      "Lock 139811071158832 acquired on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Downloading: 100%|███████████████████████████| 232k/232k [00:00<00:00, 51.2MB/s]\n",
      "Lock 139811071158832 released on /root/.cache/huggingface/transformers/45c3f7a79a80e1cf0a489e5c62b43f173c15db47864303a55d623bb3c96f72a5.d789d64ebfe299b0e416afc4a169632f903f693095b4629a7ea271d5a0cf2c99.lock\n",
      "Lock 139811071194160 acquired on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Downloading: 100%|███████████████████████████| 28.0/28.0 [00:00<00:00, 27.0kB/s]\n",
      "Lock 139811071194160 released on /root/.cache/huggingface/transformers/c1d7f0a763fb63861cc08553866f1fc3e5a6f4f07621be277452d26d71303b7e.20430bd8e10ef77a7d2977accefe796051e01bc2fc4aa146bc862997a1a15e79.lock\n",
      "Lock 139811071178592 acquired on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Downloading: 100%|███████████████████████████| 466k/466k [00:00<00:00, 65.5MB/s]\n",
      "Lock 139811071178592 released on /root/.cache/huggingface/transformers/534479488c54aeaf9c3406f647aa2ec13648c06771ffe269edabebd4c412da1d.7f2721073f19841be16f41b0a70b600ca6b880c8f3df6f3535cbc704371bdfa4.lock\n",
      "Using bos_token, but it is not set yet.\n",
      "Using eos_token, but it is not set yet.\n",
      "[NeMo W 2022-04-27 08:24:25 modelPT:1202] World size can only be set by PyTorch Lightning Trainer.\n",
      "Lock 139811071041008 acquired on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "Downloading: 100%|███████████████████████████| 440M/440M [00:04<00:00, 88.9MB/s]\n",
      "Lock 139811071041008 released on /root/.cache/huggingface/transformers/a8041bf617d7f94ea26d15e218abd04afc2004805632abc0ed2066aa16d50d04.faf6ea826ae9c5867d12b22257f9877e6b8367890837bd60f7c54a29633f7f2f.lock\n",
      "[NeMo I 2022-04-27 08:24:40 export:54] Model restored from '/workspace/mount/results/bert-base-finetuned_ner/checkpoints/finetuned-model.tlt'\n",
      "Could not retrieve the artifact tokenizer.vocab_file used in tokenizer.vocab_file\n",
      "[NeMo W 2022-04-27 08:24:41 export_utils:198] Swapped 0 modules\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "[NeMo I 2022-04-27 08:24:50 exportable:205] onnx-graphsurgeon module is not instlled.That may result in suboptimal optimization of exported ONNX graph (including unneeded DOUBLE initializers).Please follow the instructions available at:https://github.com/NVIDIA/TensorRT/tree/master/tools/onnx-graphsurgeonto install onnx-graphsurgeon from source to improve exported graph.\n",
      "[NeMo W 2022-04-27 08:24:50 export_utils:198] Swapped 0 modules\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "Warning: ONNX Preprocess - Removing mutation on block inputs. This changes graph semantics.\n",
      "[NeMo I 2022-04-27 08:24:50 exportable:205] onnx-graphsurgeon module is not instlled.That may result in suboptimal optimization of exported ONNX graph (including unneeded DOUBLE initializers).Please follow the instructions available at:https://github.com/NVIDIA/TensorRT/tree/master/tools/onnx-graphsurgeonto install onnx-graphsurgeon from source to improve exported graph.\n",
      "[NeMo I 2022-04-27 08:25:12 export:69] Experiment logs saved to '/workspace/mount/results/export'\n",
      "[NeMo I 2022-04-27 08:25:12 export:70] Exported model to '/workspace/mount/results/export/exported-model-NER.eonnx'\n",
      "2022-04-27 08:25:14,031 [INFO] tlt.components.docker_handler.docker_handler: Stopping container.\n"
     ]
    }
   ],
   "source": [
    "# TODO export the fine-tuned model to \"exported-model-NER.eonnx\"\n",
    "!tao token_classification export \\\n",
    "     -e $SPECS_DIR/token_classification/export.yaml \\\n",
    "     -r $RESULTS_DIR/export/ \\\n",
    "     -m $RESULTS_DIR/bert-base-finetuned_ner/checkpoints/finetuned-model.tlt \\\n",
    "     -k $KEY \\\n",
    "     export_to=exported-model-NER.eonnx \\\n",
    "     export_format=ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You did it!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if(os.path.exists('/dli/task/tao/results/export/exported-model-NER.eonnx')):\n",
    "   print(\"You did it!\")\n",
    "else: \n",
    "   print(\"Sorry, the model isn't there.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "In this notebook, you have:\n",
    "- Gained an understanding IOB formatting for NER datasets\n",
    "- Trained and fine-tuned an NER model with TAO Toolkit\n",
    "- Launched TAO with an implicit docker container to run NER inference on text samples\n",
    "- Exported the model to both ONNX and RIVA formats\n",
    "\n",
    "Next, you'll deploy the model on NVIDIA Riva. Move on to [NLP Deployment with Riva](008_NLP_Deploy_NER.ipynb).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
