{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cf598575",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35ea851",
   "metadata": {},
   "source": [
    "# 10.0 Monitoring GPU within Kubernetes Cluster\n",
    "## (part of Lab 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0b4146",
   "metadata": {},
   "source": [
    "In this notebook, you'll learn to monitor and manage GPU resources across a K8s cluster using [NVIDIA Data Center GPU Manager (DCGM)](https://developer.nvidia.com/dcgm).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5116b4",
   "metadata": {},
   "source": [
    "**[10.1 Deploy Prometheus](#10.1-Deploy-Prometheus)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[10.1.1 Configuration File](#10.1.1-Configuration-File)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[10.1.2 Exercise: Override a Configuration Value](#10.1.2-Exercise:-Override-a-Configuration-Value)<br>\n",
    "**[10.2 Deploy `dcgm-exporter`](#10.2-Deploy-dcgm-exporter)<br>**\n",
    "**[10.3 Explore Prometheus and Grafana](#10.3-Explore-Prometheus-and-Grafana)<br>**\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[10.3.1 Exercise: Set Up a Dashboard](#10.3.1-Exercise:-Set-Up-a-Dashboard)<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;[10.3.2 Shutdown](#10.3.2-Shutdown)<br>\n",
    "\n",
    "\n",
    "Monitoring systems includes collecting/storing metrics, visualizing results, and alerting on specific observed conditions.\n",
    "DCGM is a suite of tools that includes active health monitoring, comprehensive diagnostics, system alerts, and governance policies for the GPU cluster. \n",
    "Metrics are collected with the open-source tool [Prometheus](https://prometheus.io/) and visualized with the [Grafana](https://grafana.com/) tool to create rich dashboards.  \n",
    "\n",
    "To gather GPU telemetry in Kubernetes, we will use [dcgm-exporter](https://docs.nvidia.com/datacenter/cloud-native/kubernetes/dcgme2e.html#gpu-telemetry), which exposes GPU metrics in a format that can be scraped by Prometheus and visualized using Grafana."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c371ca",
   "metadata": {},
   "source": [
    "### Notebook Dependencies\n",
    "The steps in this notebook assume that you are starting with a K8s cluster that is GPU-enabled with feature discovery.  Let's ensure that by stopping and restarting a cluster and bringing it to a known state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a51a0fd4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üôÑ  \"minikube\" profile does not exist, trying anyways.\n",
      "üíÄ  Removed all traces of the \"minikube\" cluster.\n",
      "üòÑ  minikube v1.19.0 on Ubuntu 20.04 (docker/amd64)\n",
      "‚ú®  Using the none driver based on user configuration\n",
      "üëç  Starting control plane node minikube in cluster minikube\n",
      "ü§π  Running on localhost (CPUs=4, Memory=15717MB, Disk=297738MB) ...\n",
      "‚ÑπÔ∏è  OS release is Ubuntu 20.04.1 LTS\n",
      "üê≥  Preparing Kubernetes v1.20.2 on Docker 20.10.3 ...\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\n",
      "    ‚ñ™ Generating certificates and keys ...\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\n",
      "    ‚ñ™ Booting up control plane ...\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\n",
      "    ‚ñ™ Configuring RBAC rules ...\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\u001b[K\n",
      "ü§π  Configuring local host environment ...\n",
      "\n",
      "‚ùó  The 'none' driver is designed for experts who need to integrate with an existing VM\n",
      "üí°  Most users should use the newer 'docker' driver instead, which does not require root!\n",
      "üìò  For more information, see: https://minikube.sigs.k8s.io/docs/reference/drivers/none/\n",
      "\n",
      "‚ùó  kubectl and minikube configuration will be stored in /root\n",
      "‚ùó  To use kubectl or minikube commands as your own user, you may need to relocate them. For example, to overwrite your own settings, run:\n",
      "\n",
      "    ‚ñ™ sudo mv /root/.kube /root/.minikube $HOME\n",
      "    ‚ñ™ sudo chown -R $USER $HOME/.kube $HOME/.minikube\n",
      "\n",
      "üí°  This can also be done automatically by setting the env var CHANGE_MINIKUBE_NONE_USER=true\n",
      "üîé  Verifying Kubernetes components...\n",
      "    ‚ñ™ Using image gcr.io/k8s-minikube/storage-provisioner:v5\n",
      "üåü  Enabled addons: default-storageclass, storage-provisioner\n",
      "üèÑ  Done! kubectl is now configured to use \"minikube\" cluster and \"default\" namespace by default\n",
      "\"nvdp\" already exists with the same configuration, skipping\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"nvdp\" chart repository\n",
      "...Successfully got an update from the \"nvgfd\" chart repository\n",
      "...Successfully got an update from the \"prometheus-community\" chart repository\n",
      "Update Complete. ‚éàHappy Helming!‚éà\n",
      "NAME: nvidia-device-plugin-1651062456\n",
      "LAST DEPLOYED: Wed Apr 27 12:27:36 2022\n",
      "NAMESPACE: default\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n",
      "\"nvgfd\" already exists with the same configuration, skipping\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"nvgfd\" chart repository\n",
      "...Successfully got an update from the \"nvdp\" chart repository\n",
      "...Successfully got an update from the \"prometheus-community\" chart repository\n",
      "Update Complete. ‚éàHappy Helming!‚éà\n",
      "NAME: gpu-feature-discovery-1651062458\n",
      "LAST DEPLOYED: Wed Apr 27 12:27:38 2022\n",
      "NAMESPACE: default\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "TEST SUITE: None\n"
     ]
    }
   ],
   "source": [
    "# Delete and restart K8s\n",
    "!minikube delete\n",
    "!minikube start --driver=none\n",
    "# Install the GPU device plugin with Helm\n",
    "!helm repo add nvdp https://nvidia.github.io/k8s-device-plugin \\\n",
    "    && helm repo update\n",
    "!helm install \\\n",
    "    --version=0.9.0 \\\n",
    "    --generate-name nvdp/nvidia-device-plugin\n",
    "# Install GPU feature discovery with Helm\n",
    "!helm repo add nvgfd https://nvidia.github.io/gpu-feature-discovery \\\n",
    "    && helm repo update\n",
    "!helm install \\\n",
    "    --version=0.4.1 \\\n",
    "    --generate-name nvgfd/gpu-feature-discovery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257771e3",
   "metadata": {},
   "source": [
    "Check the list of Helm charts installed with the `helm list` command (see the [Helm documentation](https://helm.sh/docs/helm/helm_list/)). The `--filter` option allows filtering by name.  Use the `--output` option to specify the output format (\"json\", \"table\", or \"yaml\").  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4b746d8b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                            \tNAMESPACE\tREVISION\tUPDATED                                \tSTATUS  \tCHART                      \tAPP VERSION\n",
      "gpu-feature-discovery-1651062458\tdefault  \t1       \t2022-04-27 12:27:38.39997003 +0000 UTC \tdeployed\tgpu-feature-discovery-0.4.1\t0.4.1      \n",
      "nvidia-device-plugin-1651062456 \tdefault  \t1       \t2022-04-27 12:27:36.307650622 +0000 UTC\tdeployed\tnvidia-device-plugin-0.9.0 \t0.9.0      \n"
     ]
    }
   ],
   "source": [
    "# check the list of charts\n",
    "!helm list -A  --output table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a64f343a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- app_version: 0.9.0\n",
      "  chart: nvidia-device-plugin-0.9.0\n",
      "  name: nvidia-device-plugin-1651062456\n",
      "  namespace: default\n",
      "  revision: \"1\"\n",
      "  status: deployed\n",
      "  updated: 2022-04-27 12:27:36.307650622 +0000 UTC\n"
     ]
    }
   ],
   "source": [
    "# Filter the list of charts\n",
    "!helm list -A --filter \"nvidia\" --output yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a20e26",
   "metadata": {},
   "source": [
    "---\n",
    "# 10.1 Deploy Prometheus\n",
    "\n",
    "The first step is to deploy Prometheus to the cluster, as `dcgm-exporter` depends on Prometheus. If we do this out of order we will get an error.  \n",
    "\n",
    "<img  src=\"images/k8s/prometheus-architecture.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d58a044f",
   "metadata": {},
   "source": [
    "In the previous notebook, our steps for deployment with Helm were simply to add the appropriate repository, then install with options itemized.  For Prometheus, we have an additional intermediate step.  We need to modify the configuration values before installation.  Our steps are:\n",
    "1. Add the Prometheus repository\n",
    "2. Get the `kube-prometheus-stack` values file and modify it for our configuration\n",
    "3. Install Prometheus with Helm using the updated values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "66bbdbb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"prometheus-community\" already exists with the same configuration, skipping\n",
      "Hang tight while we grab the latest from your chart repositories...\n",
      "...Successfully got an update from the \"nvdp\" chart repository\n",
      "...Successfully got an update from the \"nvgfd\" chart repository\n",
      "...Successfully got an update from the \"prometheus-community\" chart repository\n",
      "Update Complete. ‚éàHappy Helming!‚éà\n"
     ]
    }
   ],
   "source": [
    "# Add the prometheus-community repo\n",
    "!helm repo add prometheus-community \\\n",
    "    https://prometheus-community.github.io/helm-charts \\\n",
    "    && helm repo update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9da84664",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                      \tCHART VERSION\tAPP VERSION\tDESCRIPTION                                       \n",
      "prometheus-community/kube-prometheus-stack\t17.1.3       \t0.49.0     \tkube-prometheus-stack collects Kubernetes manif...\n"
     ]
    }
   ],
   "source": [
    "# Find the exact name\n",
    "!helm search repo kube-prometheus --version 17.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "61458244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use inspect to export the values YAML file\n",
    "!helm inspect values prometheus-community/kube-prometheus-stack --version 17.1 > ./kube-prometheus-stack.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e6c39c",
   "metadata": {},
   "source": [
    "## 10.1.1 Configuration File\n",
    "The [kube-prometheus-stack.values](kube-prometheus-stack.values) file is quite large. You can take a look to get a sense of the many configuration settings possible in deployment. Depending on your own use case, you may need to modify the file before deployment.  In this class, there is a file with modifications already preloaded.  You can see the changes \n",
    "by running a `diff` of the two files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fe1ebef2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "399c399\n",
      "<       tag: v0.22.2\n",
      "---\n",
      ">       tag: v0.21.0\n",
      "609,618d608\n",
      "<   ## ExtraSecret can be used to store various data in an extra secret\n",
      "<   ## (use it for example to store hashed basic auth credentials)\n",
      "<   extraSecret:\n",
      "<     ## if not set, name will be auto generated\n",
      "<     # name: \"\"\n",
      "<     annotations: {}\n",
      "<     data: {}\n",
      "<   #   auth: |\n",
      "<   #     foo:$apr1$OFG3Xybp$ckL0FHDAkoXYIlH9.cysT0\n",
      "<   #     someoneelse:$apr1$DMZX2Z4q$6SbQIfyuLQd.xmo/P0m2c.\n",
      "626,633d615\n",
      "<   ## ForceDeployDatasources Create datasource configmap even if grafana deployment has been disabled\n",
      "<   ##\n",
      "<   forceDeployDatasources: false\n",
      "< \n",
      "<   ## ForceDeployDashboard Create dashboard configmap even if grafana deployment has been disabled\n",
      "<   ##\n",
      "<   forceDeployDashboards: false\n",
      "< \n",
      "638a621,626\n",
      ">   \n",
      ">   grafana.ini:\n",
      ">     server:\n",
      ">       domain: \"\"\n",
      ">       root_url: \"\"\n",
      ">       serve_from_subpath: true\n",
      "643c631\n",
      "<     enabled: false\n",
      "---\n",
      ">     enabled: true\n",
      "659c647\n",
      "<     #   - grafana.domain.com\n",
      "---\n",
      ">     #  - \n",
      "663c651\n",
      "<     path: /\n",
      "---\n",
      ">     path: /grafana\n",
      "686,689d673\n",
      "<       ## URL of prometheus datasource\n",
      "<       ##\n",
      "<       # url: http://prometheus-stack-prometheus:9090/\n",
      "< \n",
      "766a751,763\n",
      "> \n",
      ">   ## If your API endpoint address is not reachable (as in AKS) you can replace it with the kubernetes service\n",
      ">   ##\n",
      ">   relabelings: []\n",
      ">   # - sourceLabels:\n",
      ">   #     - __meta_kubernetes_namespace\n",
      ">   #     - __meta_kubernetes_service_name\n",
      ">   #     - __meta_kubernetes_endpoint_port_name\n",
      ">   #   action: keep\n",
      ">   #   regex: default;kubernetes;https\n",
      ">   # - targetLabel: __address__\n",
      ">   #   replacement: kubernetes.default.svc:443\n",
      "> \n",
      "787,795d783\n",
      "<     relabelings: []\n",
      "<     # - sourceLabels:\n",
      "<     #     - __meta_kubernetes_namespace\n",
      "<     #     - __meta_kubernetes_service_name\n",
      "<     #     - __meta_kubernetes_endpoint_port_name\n",
      "<     #   action: keep\n",
      "<     #   regex: default;kubernetes;https\n",
      "<     # - targetLabel: __address__\n",
      "<     #   replacement: kubernetes.default.svc:443\n",
      "1271,1274d1258\n",
      "<     # Enable self metrics configuration for Service Monitor\n",
      "<     selfMonitor:\n",
      "<       enabled: false\n",
      "< \n",
      "1367c1351\n",
      "<         tag: v1.5.2\n",
      "---\n",
      ">         tag: v1.5.0\n",
      "1378,1387d1361\n",
      "< \n",
      "<       ## SecurityContext holds pod-level security attributes and common container settings.\n",
      "<       ## This defaults to non root user with uid 2000 and gid 2000.\t*v1.PodSecurityContext\tfalse\n",
      "<       ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/\n",
      "<       ##\n",
      "<       securityContext:\n",
      "<         runAsGroup: 2000\n",
      "<         runAsNonRoot: true\n",
      "<         runAsUser: 2000\n",
      "< \n",
      "1575c1549\n",
      "<     tag: v0.49.0\n",
      "---\n",
      ">     tag: v0.47.0\n",
      "1591c1565\n",
      "<     tag: v0.49.0\n",
      "---\n",
      ">     tag: v0.47.0\n",
      "1602,1608d1575\n",
      "<   ## Thanos side-car image when configured\n",
      "<   ##\n",
      "<   thanosImage:\n",
      "<     repository: quay.io/thanos/thanos\n",
      "<     tag: v0.17.2\n",
      "<     sha: \"\"\n",
      "< \n",
      "1662,1663d1628\n",
      "<     loadBalancerIP: \"\"\n",
      "<     loadBalancerSourceRanges: []\n",
      "1703c1668\n",
      "<     type: ClusterIP\n",
      "---\n",
      ">     type: NodePort\n",
      "1780,1791d1744\n",
      "<     #\n",
      "< \n",
      "<   ## ExtraSecret can be used to store various data in an extra secret\n",
      "<   ## (use it for example to store hashed basic auth credentials)\n",
      "<   extraSecret:\n",
      "<     ## if not set, name will be auto generated\n",
      "<     # name: \"\"\n",
      "<     annotations: {}\n",
      "<     data: {}\n",
      "<   #   auth: |\n",
      "<   #     foo:$apr1$OFG3Xybp$ckL0FHDAkoXYIlH9.cysT0\n",
      "<   #     someoneelse:$apr1$DMZX2Z4q$6SbQIfyuLQd.xmo/P0m2c.\n",
      "1946,1949d1898\n",
      "<     ## WebTLSConfig defines the TLS parameters for HTTPS\n",
      "<     ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/master/Documentation/api.md#webtlsconfig\n",
      "<     web: {}\n",
      "< \n",
      "1959c1908\n",
      "<       tag: v2.28.1\n",
      "---\n",
      ">       tag: v2.26.0\n",
      "2078c2027\n",
      "<     serviceMonitorSelectorNilUsesHelmValues: true\n",
      "---\n",
      ">     serviceMonitorSelectorNilUsesHelmValues: false\n",
      "2273c2222,2235\n",
      "<     additionalScrapeConfigs: []\n",
      "---\n",
      ">     additionalScrapeConfigs:\n",
      ">     - job_name: gpu-metrics\n",
      ">       scrape_interval: 1s\n",
      ">       metrics_path: /metrics\n",
      ">       scheme: http\n",
      ">       kubernetes_sd_configs:\n",
      ">       - role: endpoints\n",
      ">         namespaces:\n",
      ">           names:\n",
      ">           - gpu-operator-resources\n",
      ">       relabel_configs:\n",
      ">       - source_labels: [__meta_kubernetes_pod_node_name]\n",
      ">         action: replace\n",
      ">         target_label: kubernetes_node\n",
      "2329,2336d2290\n",
      "< \n",
      "<     ## If additional alertmanager configurations are already deployed in a single secret, or you want to manage\n",
      "<     ## them separately from the helm deployment, you can use this section.\n",
      "<     ## Expected values are the secret name and key\n",
      "<     ## Cannot be used with additionalAlertManagerConfigs\n",
      "<     additionalAlertManagerConfigsSecret: {}\n",
      "<       # name:\n",
      "<       # key:\n"
     ]
    }
   ],
   "source": [
    "CONFIG_DIR = \"/dli/task/kubernetes-config\"\n",
    "!diff kube-prometheus-stack.values $CONFIG_DIR/kube-prometheus-stack.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1b09d50",
   "metadata": {},
   "source": [
    "One area of the configuration file that is of particular interest to us, is the configuration of Grafana.  Here are the Grafana settings in the preloaded version of the values file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e6445874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grafana:\n",
      "  enabled: true\n",
      "  namespaceOverride: \"\"\n",
      "\n",
      "  ## Deploy default dashboards.\n",
      "  ##\n",
      "  defaultDashboardsEnabled: true\n",
      "\n",
      "  adminPassword: prom-operator\n",
      "  \n",
      "  grafana.ini:\n",
      "    server:\n",
      "      domain: \"\"\n",
      "      root_url: \"\"\n",
      "      serve_from_subpath: true\n",
      "\n",
      "  ingress:\n",
      "    ## If true, Grafana Ingress will be created\n",
      "    ##\n",
      "    enabled: true\n",
      "\n",
      "    ## Annotations for Grafana Ingress\n",
      "    ##\n",
      "    annotations: {}\n",
      "      # kubernetes.io/ingress.class: nginx\n",
      "      # kubernetes.io/tls-acme: \"true\"\n",
      "\n",
      "    ## Labels to be added to the Ingress\n",
      "    ##\n",
      "    labels: {}\n",
      "\n",
      "    ## Hostnames.\n",
      "    ## Must be provided if Ingress is enable.\n",
      "    ##\n",
      "    # hosts:\n",
      "    #  - \n",
      "    hosts: []\n",
      "\n",
      "    ## Path for grafana ingress\n",
      "    path: /grafana\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cat $CONFIG_DIR/kube-prometheus-stack.values | grep -A 40 grafana:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8147427e",
   "metadata": {},
   "source": [
    "There are a few more changes to the config file needed.  To access the Grafana webpage, the \"domain\", \"root_url\", and \"hosts\" parameters have to point to your particular GPU instance. Each student GPU instance has a unique URL, which we need to extract.  You could directly modify the values file, but as an exercise, you'll do this with an override to the `helm install` command instead, using the `--set` option. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15f98c3",
   "metadata": {},
   "source": [
    "## 10.1.2 Exercise: Override a Configuration Value\n",
    "To override a value in the configuration YAML file, use the `--set` option during installation. \n",
    "the reference to a particular key can be found by it's hierarchy, separated by dots, taking care to escape actual dots in the name!\n",
    "As an example, the reference to the \"Grafana server domain\" is in the hierarchy `grafana`->`grafana.ini`->`server`->`domain`. Therefore, the `--set` option is of the form:\n",
    "\n",
    "```\n",
    "--set grafana.'grafana\\.ini'.server.domain=\"your.domain.here\"\n",
    "```\n",
    "\n",
    "Using the helper cell below, determine the \"domain\", \"root_url\", and \"host\" values.  Then complete the `helm install` command with the correct values and run it to deploy Prometheus. \n",
    "\n",
    "There is no precise solution to look at because every student has a unique URL.  If you get stuck, you can look at the [example solution](solutions/ex10.1.2.ipynb), which should give you an idea of the correct pattern. <br>*Note: the example solution will not be your exact solution!*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5467fa2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "var root_url = 'http://' + window.location.hostname + '/grafana';\n",
       "element.append(root_url);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%js\n",
    "var root_url = 'http://' + window.location.hostname + '/grafana';\n",
    "element.append(root_url);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d5e8e31",
   "metadata": {},
   "source": [
    "With the configuration changes in place, go ahead and deploy the Prometheus application. Then we can verify that Prometheus is deployed with the `kubectl get pods` command using the option `--namespace prometheus`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "72728e92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME: kube-prometheus-stack-1651063011\n",
      "LAST DEPLOYED: Wed Apr 27 12:36:55 2022\n",
      "NAMESPACE: prometheus\n",
      "STATUS: deployed\n",
      "REVISION: 1\n",
      "NOTES:\n",
      "kube-prometheus-stack has been installed. Check its status by running:\n",
      "  kubectl --namespace prometheus get pods -l \"release=kube-prometheus-stack-1651063011\"\n",
      "\n",
      "Visit https://github.com/prometheus-operator/kube-prometheus for instructions on how to create & configure Alertmanager and Prometheus instances using the Operator.\n"
     ]
    }
   ],
   "source": [
    "# TODO Replace the FIXMEs with the correct setting values and deploy Prometheus\n",
    "!helm install prometheus-community/kube-prometheus-stack --version 17.1 \\\n",
    "   --create-namespace --namespace prometheus \\\n",
    "   --generate-name \\\n",
    "   --values $CONFIG_DIR/kube-prometheus-stack.values \\\n",
    "   --set grafana.'grafana\\.ini'.server.domain=\"ec2-18-212-97-167.compute-1.amazonaws.com\" \\\n",
    "   --set grafana.'grafana\\.ini'.server.root_url=\"http://ec2-18-212-97-167.compute-1.amazonaws.com/grafana\" \\\n",
    "   --set grafana.ingress.hosts[0]=\"ec2-18-212-97-167.compute-1.amazonaws.com\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d0e6d452",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                                              READY   STATUS    RESTARTS   AGE\n",
      "alertmanager-kube-prometheus-stack-1651-alertmanager-0            2/2     Running   0          23s\n",
      "kube-prometheus-stack-1651-operator-794b95b755-sp2ww              1/1     Running   0          25s\n",
      "kube-prometheus-stack-1651063011-grafana-86cd95f8f9-wn4hw         2/2     Running   0          25s\n",
      "kube-prometheus-stack-1651063011-kube-state-metrics-56f98dgqc7j   1/1     Running   0          25s\n",
      "kube-prometheus-stack-1651063011-prometheus-node-exporter-vrn9p   1/1     Running   0          25s\n",
      "prometheus-kube-prometheus-stack-1651-prometheus-0                2/2     Running   1          23s\n"
     ]
    }
   ],
   "source": [
    "# Check prometheus pods. Should be \"Running\" after a \"ContainerCreating\" status\n",
    "!kubectl get pods --namespace prometheus "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44695f35",
   "metadata": {},
   "source": [
    "---\n",
    "# 10.2 Deploy `dcgm-exporter`\n",
    "\n",
    "The `dcgm-exporter` project was built to expose DCGM GPU metrics to Prometheus. Now that Prometheus is deployed, we can deploy `dcgm-exporter`.  We'll do this directly with `kubectl create` instead of with the usual Helm chart to ensure we have no timeout limitations when we launch Grafana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8536ac46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "daemonset.apps/dcgm-exporter created\n",
      "service/dcgm-exporter created\n",
      "servicemonitor.monitoring.coreos.com/dcgm-exporter created\n"
     ]
    }
   ],
   "source": [
    "!kubectl create -f https://raw.githubusercontent.com/NVIDIA/gpu-monitoring-tools/2.0.0-rc.9/dcgm-exporter.yaml\n",
    "!kubectl create -f https://raw.githubusercontent.com/NVIDIA/gpu-monitoring-tools/2.0.0-rc.9/service-monitor.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9430a45d",
   "metadata": {},
   "source": [
    "In order to expose Grafana on the class instance, we need to patch the configuration using the [kubectl patch](https://kubernetes.io/docs/tasks/manage-kubernetes-objects/update-api-object-kubectl-patch/) command.  We need to specify the port and a password.  This patch will override the previous settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a2f0384f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "spec:\n",
      "  type: NodePort\n",
      "  ports:\n",
      "    - port: 80\n",
      "      nodePort: 31091\n",
      "      name: grafana\n"
     ]
    }
   ],
   "source": [
    "# List the Grafana patch\n",
    "!cat $CONFIG_DIR/grafana-patch.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4efe86be",
   "metadata": {},
   "source": [
    "In the next few cells, we will: \n",
    "1. Check the status of the Grafana service using the `kubectl get svc` command\n",
    "1. Make the patch using `kubectl patch svc`\n",
    "1. Check the status again to see if there is a change after applying the patch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "eeacdde0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                       TYPE        CLUSTER-IP       EXTERNAL-IP   PORT(S)   AGE\n",
      "kube-prometheus-stack-1651063011-grafana   ClusterIP   10.101.129.144   <none>        80/TCP    2m16s\n"
     ]
    }
   ],
   "source": [
    "# Check the status - note the TYPE and PORT for patching\n",
    "!kubectl get svc --namespace prometheus -l app.kubernetes.io/name=grafana "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "dc867378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "service/kube-prometheus-stack-1651063011-grafana patched\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "# get the GRAFANA_NAME\n",
    "GRAFANA_NAME=$(kubectl get svc --namespace prometheus -l app.kubernetes.io/name=grafana -o custom-columns=NAME:.metadata.name --no-headers)\n",
    "\n",
    "# Apply the patch\n",
    "kubectl patch svc $GRAFANA_NAME \\\n",
    "   -n prometheus \\\n",
    "   --patch \"$(cat /dli/task/kubernetes-config/grafana-patch.yaml)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0b5b9075",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NAME                                       TYPE       CLUSTER-IP       EXTERNAL-IP   PORT(S)        AGE\n",
      "kube-prometheus-stack-1651063011-grafana   NodePort   10.101.129.144   <none>        80:31091/TCP   2m59s\n"
     ]
    }
   ],
   "source": [
    "# Check the status again - note the TYPE and PORT changes\n",
    "!kubectl get svc --namespace prometheus -l app.kubernetes.io/name=grafana "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa0a320",
   "metadata": {},
   "source": [
    "---\n",
    "# 10.3 Explore Prometheus and Grafana"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1152f87",
   "metadata": {},
   "source": [
    "The Grafana interface to Prometheus metrics is now exposed.  Execute the following cell to create the correct link.  Then, click the link to open Grafana in a new browser tab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "915f9d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "const href = window.location.hostname +'/grafana';\n",
       "let a = document.createElement('a');\n",
       "let link = document.createTextNode('Open Grafana!');\n",
       "a.appendChild(link);\n",
       "a.href = \"http://\" + href;\n",
       "a.style.color = \"navy\"\n",
       "a.target = \"_blank\"\n",
       "element.append(a);\n"
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%%js\n",
    "const href = window.location.hostname +'/grafana';\n",
    "let a = document.createElement('a');\n",
    "let link = document.createTextNode('Open Grafana!');\n",
    "a.appendChild(link);\n",
    "a.href = \"http://\" + href;\n",
    "a.style.color = \"navy\"\n",
    "a.target = \"_blank\"\n",
    "element.append(a);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38d47ef7",
   "metadata": {},
   "source": [
    "Grafana greets you with a dark blue page. To login, use: \n",
    "- Username: `admin` \n",
    "- Password: `prom-operator` \n",
    "\n",
    "The password was originally set in the `kube-prometheus-stack.values` file. If successful, your page should look similar to this:\n",
    "\n",
    "<img src=\"images/k8s/grafana_page1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d96aa940",
   "metadata": {},
   "source": [
    "What's next?  Set up a dashboard by importing the NVIDIA DCGM Exporter Dashboard."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d43e48fe",
   "metadata": {},
   "source": [
    "## 10.3.1 Exercise: Set Up a Dashboard\n",
    "For this exercise, follow the instructions in the [GPU telemetry documentation](https://docs.nvidia.com/datacenter/cloud-native/kubernetes/dcgme2e.html#dcgm-dashboard-in-grafana) section titled \"DCGM Dashboard in Grafana\" to import and open the dashboard. Please STOP after this section and do NOT continue into the next section titled \"Viewing Metrics for Running Applications\", as this will cause errors later in the course code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b626d51",
   "metadata": {},
   "source": [
    "## 10.3.2 Shutdown\n",
    "Clean up your environment by shutting down K8s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "323b36df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ  Uninstalling Kubernetes v1.20.2 using kubeadm ...\n",
      "üî•  Deleting \"minikube\" in none ...\n",
      "üíÄ  Removed all traces of the \"minikube\" cluster.\n",
      "\"docker kill\" requires at least 1 argument.\n",
      "See 'docker kill --help'.\n",
      "\n",
      "Usage:  docker kill [OPTIONS] CONTAINER [CONTAINER...]\n",
      "\n",
      "Kill one or more running containers\n",
      "CONTAINER ID   IMAGE     COMMAND   CREATED   STATUS    PORTS     NAMES\n"
     ]
    }
   ],
   "source": [
    "# Shut down K8s\n",
    "!minikube delete\n",
    "!docker kill $(docker ps -q)\n",
    "# Check for clean environment - this should be empty\n",
    "!docker ps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40ff8732",
   "metadata": {},
   "source": [
    "---\n",
    "<h2 style=\"color:green;\">Congratulations!</h2>\n",
    "\n",
    "In this notebook, you have:\n",
    "- Deployed a Prometheus server\n",
    "- Modified initialization configurations with settings in `helm install`\n",
    "- Patched a service with K8s for your environment\n",
    "- Explored tools for monitoring activity on your production application\n",
    "\n",
    "Next, you'll deploy a conversational AI Riva application on K8s. <br>\n",
    "Move on to [Deploy Riva](011_K8s_Deploy_Riva.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6837f02e",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
