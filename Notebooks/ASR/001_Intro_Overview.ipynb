{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0 Building Conversational AI Applications - Course Overview\n",
    "Welcome to Building Conversational AI Applications!<br>\n",
    "In this course you'll learn to build, modify, and deploy conversational AI applications. \n",
    "\n",
    "<img src=\"images/intro/cai_pipeline2.png\">\n",
    "\n",
    "This instructor-led course consists of lectures and hands-on lab exercises.  You can also earn a certificate by successfully completing the optional coding and quiz-style assessments.\n",
    "\n",
    "The hands-on portion of the course consists of several notebooks divided among the following sections:\n",
    "- Introduction/Getting Started (applies to all labs; notebooks 1, 2, 3)\n",
    "- ASR - Automatic Speech Recognition (Lab 1; notebooks 4, 5, 6)\n",
    "- NLP - Natural Language Processing (Lab 2; notebooks 7, 8)\n",
    "- Deploying Conversational AI to Production (Lab 3; notebooks 9, 10, 11)\n",
    "- Coding Assessment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction/Getting Started (Applies to all labs)\n",
    "The objectives of this section are to gain an understanding of the overall course hands-on material, learn to use the JupyterLab interface, and to set up a free NGC (NVIDIA GPU Cloud) account.  You'll require the NGC account to pull docker images from the registry in later sections.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. [Course Overview](001_Intro_Overview.ipynb) (_this_ notebook)<br>\n",
    "    You'll learn:\n",
    "    - The overall layout of the hands-on portion of the course\n",
    "    - The learning objectives for each section\n",
    "    - The learning outcomes for each notebook\n",
    "<br><br>\n",
    "1. [JupyterLabs](002_Intro_JupyterLabs.ipynb)<br>\n",
    "    You'll learn:\n",
    "    - How to open a Linux terminal\n",
    "    - How to change the layout\n",
    "    - How to shut down a notebook kernel\n",
    "<br><br>\n",
    "1. [NGC Setup](003_Intro_NGC_Setup.ipynb)<br>\n",
    "    You'll learn:\n",
    "    - How to create a free NGC account\n",
    "    - How to create a personal API key on NGC\n",
    "    - How to set up a Docker login to the NGC registry\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ASR - Automatic Speech Recognition (Lab 1)\n",
    "The objective of this section is to work through an example of a speech-to-text GPU-accelerated model using NVIDIA TAO (Train, Adapt, and Optimize) Toolkit and NVIDIA Riva for inference and deployment.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "4. [ASR with NVIDIA TAO Toolkit](004_ASR_TAO_Inference.ipynb)<br>\n",
    "    You'll learn:\n",
    "    - Details about QuartzNet, and Citrinet ASR architectures\n",
    "    - How to explore a task with the TAO launcher\n",
    "    - How to run speech recognition inference on audio files\n",
    "    - How to export a model in ONNX format and run inference using the ONNX model\n",
    "    - How to export a model to Riva `.riva` format\n",
    "<br><br>\n",
    "1. [ASR Deployment with NVIDIA Riva](005_ASR_Riva_Deployment.ipynb)<br>\n",
    "    You'll learn:\n",
    "    - How to convert a TAO-exported `.riva` model to `.rmir` for deployment\n",
    "    - How to deploy a model with Riva ServiceMaker\n",
    "    - How to configure and start a Riva server\n",
    "    - How to send inference requests from a client to the server\n",
    "<br><br>\n",
    "1. [Contact Application](006_ASR_Application.ipynb)<br>\n",
    "    You'll learn:\n",
    "    - How to start the default Riva ASR and NLP services\n",
    "    - How to connect Riva services to a live web app\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## NLP - Natural Language Processing (Lab 2)\n",
    "The objective of this section is to extend your knowledge of NVIDIA TAO Toolkit and NVIDIA Riva to train, fine-tune, and deploy NLP models.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "7. [NER Fine-Tuning](007_NLP_Finetune_NER.ipynb)<br>\n",
    "    You'll learn:\n",
    "    - How to train and fine-tune an NER model with TAO Toolkit\n",
    "    - How to run NER inference on text samples\n",
    "    - How to evaluate NER performance\n",
    "<br><br>\n",
    "1. [NER Model Deployment with Riva](008_NLP_Deploy_NER.ipynb)<br>\n",
    "    You'll learn:\n",
    "    - How to configure NLP Riva services \n",
    "    - How to request an NLP service using a Python client API\n",
    "    - How to connect a new model to the Riva Contact app\n",
    "<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deploying Conversational AI to Production (Lab 3)\n",
    "The objective of this section is to step through the production deployment of conversational AI applications at scale using a Kubernetes cluster.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "9. [Enabling GPU within a Kubernetes (K8s) Cluster](009_K8s_Enable.ipynb)<br>\n",
    "    You'll learn:\n",
    "    - How to create a K8s cluster\n",
    "    - How to deploy an application to K8s\n",
    "    - How to add GPU awareness to K8s\n",
    "    - How to interact with K8s using `kubectl`\n",
    "    - How to install plugins with `helm`\n",
    "<br><br>\n",
    "1. [Monitoring GPU within Kubernetes Cluster](010_K8s_Monitor.ipynb)<br>\n",
    "    You'll learn:\n",
    "    - How to deploy a Prometheus server\n",
    "    - How to modify configurations with `helm`\n",
    "    - How to enable the Grafana graphical interface\n",
    "<br><br>\n",
    "1. [Deploying Riva Services within a Kubernetes Cluster and Further Riva API Examples](011_K8s_Deploy_Riva.ipynb)<br>\n",
    "    You'll learn:\n",
    "    - How to deploy Riva within K8s\n",
    "    - How to access the Riva server IP:Port\n",
    "    - How to query the text-to-speech (TTS) API\n",
    "    - How to query the NLP API\n",
    "<br><br>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding Assessment (Optional)\n",
    "To complete the coding assessment portion of the course certification, complete the \n",
    "[assessment.ipynb](assessment.ipynb) notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://www.nvidia.com/dli\"> <img src=\"images/DLI_Header.png\" alt=\"Header\" style=\"width: 400px;\"/> </a>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
